{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_cluster_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqZiG_T90QQ"
      },
      "source": [
        "* cluster head\n",
        "* client_ratio\n",
        "* non-IID data\n",
        "* DBSCAN\n",
        "* batch size\n",
        "* plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKvzMMr0a0t6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "from itertools import accumulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TeDIUjTbzdC"
      },
      "source": [
        "# Global variablles\n",
        "TOT_CLIENTS = 100\n",
        "learning_rate_list = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
        "NUM_ROUNDS = 10\n",
        "CLIENT_RATIO = 0.3\n",
        "DATA_DIV = 6000\n",
        "NUM_CLIENTS = int(TOT_CLIENTS * CLIENT_RATIO)\n",
        "div_list = [np.random.randint(3000,6000) for i in range(NUM_CLIENTS)]\n",
        "origin_list = [np.random.randint(0,123573) for i in range(NUM_CLIENTS)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI1zQCbjinQN",
        "outputId": "f15746a4-a7de-47ba-fa3e-e3a43d8b389d"
      },
      "source": [
        "div_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4031,\n",
              " 2570,\n",
              " 3696,\n",
              " 1208,\n",
              " 3595,\n",
              " 2210,\n",
              " 3199,\n",
              " 2292,\n",
              " 3031,\n",
              " 2393,\n",
              " 2262,\n",
              " 1159,\n",
              " 2611,\n",
              " 3218,\n",
              " 1617,\n",
              " 3740,\n",
              " 3403,\n",
              " 2359,\n",
              " 1675,\n",
              " 1706,\n",
              " 2472,\n",
              " 4063,\n",
              " 4545,\n",
              " 1962,\n",
              " 4494,\n",
              " 1978,\n",
              " 4508,\n",
              " 2134,\n",
              " 1927,\n",
              " 4009]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eBpGc2ccKW2",
        "outputId": "dd38e580-f69e-4d8f-b48f-37d0e2fe3efe"
      },
      "source": [
        "origin_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37065,\n",
              " 46004,\n",
              " 41714,\n",
              " 5856,\n",
              " 44293,\n",
              " 46109,\n",
              " 6116,\n",
              " 23312,\n",
              " 26596,\n",
              " 8594,\n",
              " 21664,\n",
              " 9524,\n",
              " 15859,\n",
              " 21763,\n",
              " 51763,\n",
              " 46010,\n",
              " 54772,\n",
              " 25264,\n",
              " 7720,\n",
              " 45888,\n",
              " 15787,\n",
              " 41824,\n",
              " 14333,\n",
              " 10803,\n",
              " 20873,\n",
              " 35498,\n",
              " 40576,\n",
              " 11949,\n",
              " 21028,\n",
              " 1697]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFG9fyvCLNL"
      },
      "source": [
        "# Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhVjh91qhM8",
        "outputId": "20f6614e-8ec0-49d1-9657-a2ec14d22476"
      },
      "source": [
        "#loading data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "\n",
        "#reshape\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalixation\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One Hot encoding\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "y_train=ohe.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test=ohe.transform(y_test.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGYxONSKQxF5"
      },
      "source": [
        "client_train_x = []\n",
        "client_train_y = []\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "  client_train_x.append(X_train[origin_list[i]:origin_list[i]+div_list[i]])\n",
        "  client_train_y.append(y_train[origin_list[i]:origin_list[i]+div_list[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SWQR4QZuGBr",
        "outputId": "272f006e-77f5-4a32-c86c-7457fa12c977"
      },
      "source": [
        "for num in range(10):\n",
        "  print(div_list[num]*num, div_list[num]*(num+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 4031\n",
            "2570 5140\n",
            "7392 11088\n",
            "3624 4832\n",
            "14380 17975\n",
            "11050 13260\n",
            "19194 22393\n",
            "16044 18336\n",
            "24248 27279\n",
            "21537 23930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8uW5AbJCQcl"
      },
      "source": [
        "# Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591IbG3Ta9iO"
      },
      "source": [
        "def create_server_model():\n",
        "\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), input_shape = (28,28,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC9cafnuCTJZ"
      },
      "source": [
        "# Model Cloner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piW-cRlDfKRw"
      },
      "source": [
        "def model_cloner(model, learning_rate, optimizer):\n",
        "    new_model = tf.keras.models.clone_model(model)\n",
        "    new_model.set_weights(model.get_weights())\n",
        "    if optimizer=='adam':\n",
        "        new_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr4FQwXh40QD"
      },
      "source": [
        "# Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUemkC0meg2M"
      },
      "source": [
        "def train_client_initial(num, model, lr_list):\n",
        "  models = []\n",
        "  losses = []\n",
        "\n",
        "  for i in range(len(lr_list)):\n",
        "    models.append(model_cloner(model, lr_list[i], 'adam'))\n",
        "    hist = models[i].fit(client_train_x[num], client_train_y[num], epochs=1, batch_size=32, validation_data=(X_test, y_test))\n",
        "    losses.append(round(hist.history['val_loss'][0], 4))\n",
        "\n",
        "  ind = losses.index(min(losses))\n",
        "\n",
        "  return models[ind], lr_list[ind], losses[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68OmWpJddDsj",
        "outputId": "d72d9792-42e5-437f-b148-03b7eeb194b0"
      },
      "source": [
        "server_model = create_server_model()\n",
        "server_model.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "server_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFGyKgX-c0eG",
        "outputId": "69bd4c4b-9d7d-492e-d2d6-8b566f785a7e"
      },
      "source": [
        "lr_init = []\n",
        "losses = []\n",
        "data = []\n",
        "client_models = []\n",
        "\n",
        "for j in range(NUM_CLIENTS):\n",
        "  print(\"----------------CLIENT \" + str(j) +\"-------------------------\")\n",
        "\n",
        "  lr_list = np.random.choice(learning_rate_list, 3, replace=False)\n",
        "  data.append(train_client_initial(j, server_model, lr_list))\n",
        "\n",
        "  client_models.append(data[j][0])\n",
        "  lr_init.append(data[j][1])\n",
        "  losses.append(data[j][2])\n",
        "\n",
        "sum=[i*0 for i in client_models[0].get_weights()]\n",
        "for i in range(NUM_CLIENTS):\n",
        "  sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "server_model.set_weights([i/NUM_CLIENTS for i in sum])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------CLIENT 0-------------------------\n",
            "126/126 [==============================] - 34s 11ms/step - loss: 2.2904 - accuracy: 0.1294 - val_loss: 2.1555 - val_accuracy: 0.3897\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 36.8076 - accuracy: 0.1493 - val_loss: 2.3107 - val_accuracy: 0.1135\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 2.3273 - accuracy: 0.0817 - val_loss: 2.3177 - val_accuracy: 0.0911\n",
            "----------------CLIENT 1-------------------------\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 69.8914 - accuracy: 0.1323 - val_loss: 2.3072 - val_accuracy: 0.0980\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 1.0216 - accuracy: 0.6695 - val_loss: 0.2814 - val_accuracy: 0.9192\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 2.3351 - accuracy: 0.0779 - val_loss: 2.3241 - val_accuracy: 0.0871\n",
            "----------------CLIENT 2-------------------------\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 2.2981 - accuracy: 0.1172 - val_loss: 2.1744 - val_accuracy: 0.3570\n",
            "116/116 [==============================] - 2s 9ms/step - loss: 1.0162 - accuracy: 0.6930 - val_loss: 0.3404 - val_accuracy: 0.8955\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.8153 - accuracy: 0.7337 - val_loss: 0.3400 - val_accuracy: 0.8932\n",
            "----------------CLIENT 3-------------------------\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 2.2012 - accuracy: 0.2696 - val_loss: 1.7650 - val_accuracy: 0.7189\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 1.4732 - accuracy: 0.5639 - val_loss: 0.5186 - val_accuracy: 0.8412\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 2.3324 - accuracy: 0.0710 - val_loss: 2.3298 - val_accuracy: 0.0824\n",
            "----------------CLIENT 4-------------------------\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 55.2739 - accuracy: 0.1158 - val_loss: 2.3067 - val_accuracy: 0.1010\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 2.3020 - accuracy: 0.1079 - val_loss: 2.1793 - val_accuracy: 0.3428\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 2.3350 - accuracy: 0.0774 - val_loss: 2.3197 - val_accuracy: 0.0906\n",
            "----------------CLIENT 5-------------------------\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 40.3692 - accuracy: 0.1778 - val_loss: 4.0845 - val_accuracy: 0.1243\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 2.3098 - accuracy: 0.0995 - val_loss: 2.2414 - val_accuracy: 0.1919\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 1.1263 - accuracy: 0.6623 - val_loss: 0.3871 - val_accuracy: 0.8850\n",
            "----------------CLIENT 6-------------------------\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9541 - accuracy: 0.6909 - val_loss: 0.3577 - val_accuracy: 0.8945\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1155 - accuracy: 0.6822 - val_loss: 0.3783 - val_accuracy: 0.8845\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 2.3075 - accuracy: 0.1053 - val_loss: 2.1987 - val_accuracy: 0.3208\n",
            "----------------CLIENT 7-------------------------\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 2.3264 - accuracy: 0.0849 - val_loss: 2.3252 - val_accuracy: 0.0865\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.2609 - accuracy: 0.6058 - val_loss: 0.3962 - val_accuracy: 0.8833\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 2.0870 - accuracy: 0.3959 - val_loss: 1.2484 - val_accuracy: 0.8019\n",
            "----------------CLIENT 8-------------------------\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 1.0727 - accuracy: 0.6824 - val_loss: 0.3425 - val_accuracy: 0.8984\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 2.2986 - accuracy: 0.1180 - val_loss: 2.2020 - val_accuracy: 0.2781\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 30.5767 - accuracy: 0.2332 - val_loss: 2.0408 - val_accuracy: 0.2054\n",
            "----------------CLIENT 9-------------------------\n",
            "75/75 [==============================] - 2s 17ms/step - loss: 1.1029 - accuracy: 0.6707 - val_loss: 0.4344 - val_accuracy: 0.8734\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 1.1649 - accuracy: 0.6590 - val_loss: 0.3834 - val_accuracy: 0.8862\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 2.3117 - accuracy: 0.1097 - val_loss: 2.2313 - val_accuracy: 0.2211\n",
            "----------------CLIENT 10-------------------------\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 2.3365 - accuracy: 0.0762 - val_loss: 2.3252 - val_accuracy: 0.0865\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.9402 - accuracy: 0.6823 - val_loss: 0.3624 - val_accuracy: 0.8908\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 1.2284 - accuracy: 0.6242 - val_loss: 0.3728 - val_accuracy: 0.8929\n",
            "----------------CLIENT 11-------------------------\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 2.1950 - accuracy: 0.2801 - val_loss: 1.7678 - val_accuracy: 0.7136\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 62.6059 - accuracy: 0.1903 - val_loss: 2.3105 - val_accuracy: 0.1142\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 1.2137 - accuracy: 0.5949 - val_loss: 0.5723 - val_accuracy: 0.8322\n",
            "----------------CLIENT 12-------------------------\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 2.3064 - accuracy: 0.1085 - val_loss: 2.2259 - val_accuracy: 0.2320\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 40.2796 - accuracy: 0.1315 - val_loss: 2.3047 - val_accuracy: 0.1135\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 1.1750 - accuracy: 0.6564 - val_loss: 0.4147 - val_accuracy: 0.8682\n",
            "----------------CLIENT 13-------------------------\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 65.3235 - accuracy: 0.2070 - val_loss: 2.1678 - val_accuracy: 0.1640\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 1.0795 - accuracy: 0.6809 - val_loss: 0.3527 - val_accuracy: 0.8988\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 1.9853 - accuracy: 0.4655 - val_loss: 0.9523 - val_accuracy: 0.8414\n",
            "----------------CLIENT 14-------------------------\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 2.3187 - accuracy: 0.1046 - val_loss: 2.2664 - val_accuracy: 0.1385\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 1.2246 - accuracy: 0.6107 - val_loss: 0.4291 - val_accuracy: 0.8748\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 2.3355 - accuracy: 0.0894 - val_loss: 2.3280 - val_accuracy: 0.0842\n",
            "----------------CLIENT 15-------------------------\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 1.0683 - accuracy: 0.6778 - val_loss: 0.3413 - val_accuracy: 0.9024\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 2.3309 - accuracy: 0.0851 - val_loss: 2.3193 - val_accuracy: 0.0907\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 24.7089 - accuracy: 0.1383 - val_loss: 2.3081 - val_accuracy: 0.0974\n",
            "----------------CLIENT 16-------------------------\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 85.9530 - accuracy: 0.1586 - val_loss: 2.4146 - val_accuracy: 0.1619\n",
            "107/107 [==============================] - 2s 12ms/step - loss: 2.3318 - accuracy: 0.0839 - val_loss: 2.3202 - val_accuracy: 0.0905\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8610 - accuracy: 0.7109 - val_loss: 0.3268 - val_accuracy: 0.9042\n",
            "----------------CLIENT 17-------------------------\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 40.5448 - accuracy: 0.1504 - val_loss: 2.3059 - val_accuracy: 0.1035\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 2.3349 - accuracy: 0.0803 - val_loss: 2.3248 - val_accuracy: 0.0862\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 1.2014 - accuracy: 0.6340 - val_loss: 0.4784 - val_accuracy: 0.8570\n",
            "----------------CLIENT 18-------------------------\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 1.4234 - accuracy: 0.5529 - val_loss: 0.4659 - val_accuracy: 0.8514\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 2.3389 - accuracy: 0.0735 - val_loss: 2.3279 - val_accuracy: 0.0837\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 60.2057 - accuracy: 0.1292 - val_loss: 2.3033 - val_accuracy: 0.1135\n",
            "----------------CLIENT 19-------------------------\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.1584 - accuracy: 0.3544 - val_loss: 1.5079 - val_accuracy: 0.7433\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0908 - accuracy: 0.6513 - val_loss: 0.3755 - val_accuracy: 0.8892\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3878 - accuracy: 0.5811 - val_loss: 0.4027 - val_accuracy: 0.8783\n",
            "----------------CLIENT 20-------------------------\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 2.3049 - accuracy: 0.1008 - val_loss: 2.2303 - val_accuracy: 0.2236\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 1.1775 - accuracy: 0.6388 - val_loss: 0.3592 - val_accuracy: 0.8930\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 1.0196 - accuracy: 0.6720 - val_loss: 0.3293 - val_accuracy: 0.8968\n",
            "----------------CLIENT 21-------------------------\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8339 - accuracy: 0.7319 - val_loss: 0.2420 - val_accuracy: 0.9252\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 2.2953 - accuracy: 0.1208 - val_loss: 2.1595 - val_accuracy: 0.3868\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0088 - accuracy: 0.6934 - val_loss: 0.2992 - val_accuracy: 0.9129\n",
            "----------------CLIENT 22-------------------------\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.9484 - accuracy: 0.7020 - val_loss: 0.2985 - val_accuracy: 0.9086\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 1.8437 - accuracy: 0.4993 - val_loss: 0.6849 - val_accuracy: 0.8618\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 2.2866 - accuracy: 0.1304 - val_loss: 2.1327 - val_accuracy: 0.4711\n",
            "----------------CLIENT 23-------------------------\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.3643 - accuracy: 0.5889 - val_loss: 0.4399 - val_accuracy: 0.8624\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.2156 - accuracy: 0.6293 - val_loss: 0.3668 - val_accuracy: 0.8865\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.3222 - accuracy: 0.0713 - val_loss: 2.2538 - val_accuracy: 0.1802\n",
            "----------------CLIENT 24-------------------------\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 39.5684 - accuracy: 0.1347 - val_loss: 2.3071 - val_accuracy: 0.1010\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.8436 - accuracy: 0.5091 - val_loss: 0.7032 - val_accuracy: 0.8514\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 2.2865 - accuracy: 0.1256 - val_loss: 2.1349 - val_accuracy: 0.4503\n",
            "----------------CLIENT 25-------------------------\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.1083 - accuracy: 0.6553 - val_loss: 0.3820 - val_accuracy: 0.8819\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.3154 - accuracy: 0.0942 - val_loss: 2.2524 - val_accuracy: 0.1756\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.3338 - accuracy: 0.0715 - val_loss: 2.3266 - val_accuracy: 0.0845\n",
            "----------------CLIENT 26-------------------------\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.8411 - accuracy: 0.5590 - val_loss: 0.6833 - val_accuracy: 0.8645\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 46.8341 - accuracy: 0.1332 - val_loss: 2.3079 - val_accuracy: 0.1028\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 2.3322 - accuracy: 0.0733 - val_loss: 2.3162 - val_accuracy: 0.0937\n",
            "----------------CLIENT 27-------------------------\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 2.3129 - accuracy: 0.1040 - val_loss: 2.2466 - val_accuracy: 0.1802\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 1.1301 - accuracy: 0.6390 - val_loss: 0.3015 - val_accuracy: 0.9093\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 2.1175 - accuracy: 0.3324 - val_loss: 1.3599 - val_accuracy: 0.8124\n",
            "----------------CLIENT 28-------------------------\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3188 - accuracy: 0.0903 - val_loss: 2.2536 - val_accuracy: 0.1639\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.9787 - accuracy: 0.6874 - val_loss: 0.4520 - val_accuracy: 0.8533\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 72.4045 - accuracy: 0.1937 - val_loss: 2.3115 - val_accuracy: 0.0986\n",
            "----------------CLIENT 29-------------------------\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.9432 - accuracy: 0.7059 - val_loss: 0.3308 - val_accuracy: 0.9033\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.7756 - accuracy: 0.7573 - val_loss: 0.2776 - val_accuracy: 0.9151\n",
            "126/126 [==============================] - 2s 11ms/step - loss: 39.2668 - accuracy: 0.2357 - val_loss: 2.2966 - val_accuracy: 0.2328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB6ZV6dDWsu",
        "outputId": "993df0fe-5d3b-4e88-d727-8262a09e7222"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7891 - accuracy: 0.8330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7496039271354675, 0.848800003528595]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKNPHQV5Aj1"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI01x0RMlj9r",
        "outputId": "06e6c074-bcd9-4c24-8f03-2b95a1f05dea"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "#lr_init = [0.01, 0.1, 0.00001, 0.001, 0.001, 0.0001, 0.1, 0.001, 0.00001, 0.000001]\n",
        "lr_init1 = np.reshape(lr_init, (-1,1))\n",
        "#print(lr_init)\n",
        "\n",
        "model = DBSCAN(eps=0.0001, min_samples=2)\n",
        "yhat = model.fit_predict(lr_init1)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 2 0 1 1 2 2 2 1 1 2 2 1 2 1 2 2 1 1 1 2 1 0 1 0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRe2H2yw5E-4"
      },
      "source": [
        "# Genetic Mutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQaytgH0m14"
      },
      "source": [
        "def mutate(lr):\n",
        "\n",
        "    num = random.randint(-1,1)\n",
        "    lr += (lr/10)*num\n",
        "\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5XwnJgL5HYC"
      },
      "source": [
        "# Genetic Mating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqZ5ySE815Ku"
      },
      "source": [
        "def crossover(lrs):\n",
        "  new_lrs = []\n",
        "\n",
        "  new_lrs.append(lrs[0])\n",
        "  if(len(lrs) >1):\n",
        "    new_lrs.append(lrs[1])\n",
        "\n",
        "  if(len(lrs) > 2):\n",
        "    for i in range(2, len(lrs)):\n",
        "      parentA = random.randint(0, len(lrs)-1)\n",
        "      parentB = random.randint(0, len(lrs)-1)\n",
        "\n",
        "      new_lrs.append(mutate((lrs[parentA]+lrs[parentB])/2))\n",
        "\n",
        "  return new_lrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26iigDPI5KwA"
      },
      "source": [
        "# Genetic Evolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDdAywv0nHM"
      },
      "source": [
        "def evolve(losses, lrs):\n",
        "    sorted_y_idx_list = sorted(range(len(losses)),key=lambda x:losses[x])\n",
        "    lrs = [lrs[i] for i in sorted_y_idx_list]\n",
        "    lrs = crossover(lrs)\n",
        "\n",
        "    return lrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK_QwKuA5PIv"
      },
      "source": [
        "# Edge Device training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5wHd3GX0i-"
      },
      "source": [
        "def train_client(num, model, lr):\n",
        "\n",
        "  new_model = model_cloner(model, lr, 'adam')\n",
        "  hist = new_model.fit(client_train_x[num], client_train_y[num], epochs=2, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "  return new_model, lr, round(hist.history['val_loss'][-1], 4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X14df0oaLrN",
        "outputId": "f04d1daa-a35f-4921-99f1-a6c0ac4fd97a"
      },
      "source": [
        "losses "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1555,\n",
              " 0.2814,\n",
              " 0.34,\n",
              " 0.5186,\n",
              " 2.1793,\n",
              " 0.3871,\n",
              " 0.3577,\n",
              " 0.3962,\n",
              " 0.3425,\n",
              " 0.3834,\n",
              " 0.3624,\n",
              " 0.5723,\n",
              " 0.4147,\n",
              " 0.3527,\n",
              " 0.4291,\n",
              " 0.3413,\n",
              " 0.3268,\n",
              " 0.4784,\n",
              " 0.4659,\n",
              " 0.3755,\n",
              " 0.3293,\n",
              " 0.242,\n",
              " 0.2985,\n",
              " 0.3668,\n",
              " 0.7032,\n",
              " 0.382,\n",
              " 0.6833,\n",
              " 0.3015,\n",
              " 0.452,\n",
              " 0.2776]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MdhJtDYkZXW",
        "outputId": "3dbe2c8e-92e8-4b25-e4d3-ee314bf8a4a3"
      },
      "source": [
        "lr_init "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1e-05,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 1e-05,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.0001,\n",
              " 0.01,\n",
              " 0.0001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSK_7dY0Tlx"
      },
      "source": [
        "yhat\n",
        "if(-1 in yhat):\n",
        "  flag=1\n",
        "else:\n",
        "  flag=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88GFprXB54KL"
      },
      "source": [
        "# Genetic Clustering FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJePiAuto7dJ",
        "outputId": "2a669b1d-02a3-4579-fdc5-6495f5ceba85"
      },
      "source": [
        "yhat = list(yhat)\n",
        "serverhist1={\n",
        "    \"loss\": list(),\n",
        "    \"accuracy\": list()\n",
        "}\n",
        "# Control loop\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"---------\"+str(i)+\"------------\")\n",
        "  lr_global = []\n",
        "  #  Genetic Optimization of Hyper-Parameters\n",
        "  for cluster in clusters:\n",
        "    ind = [k for k in range(len(yhat)) if(yhat[k]==cluster)]\n",
        "    lr_global.append(evolve([losses[k] for k in ind], [lr_init[k] for k in ind]))\n",
        "\n",
        "  lr_init = []\n",
        "  losses = []\n",
        "  data = []\n",
        "  lrid = np.zeros(len(clusters))\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    print(lrid)\n",
        "    data.append(train_client(j, server_model, lr_global[yhat[j]+flag][int(lrid[yhat[j]+flag])]))\n",
        "    lrid[yhat[j]+flag] +=1\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "\n",
        "  # Cluster head aggregation\n",
        "  n_clust = len(set(yhat))\n",
        "  a = [[i*0 for i in client_models[0].get_weights()] for i in range(n_clust)]\n",
        "  for i in range(len(yhat)):\n",
        "    a[yhat[i]] = [k+j for k, j in zip(client_models[i].get_weights(), a[yhat[i]])]\n",
        "\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(len(a)):\n",
        "    sum = [i+j for i, j in zip(a[i], sum)]\n",
        "  server_model.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "\n",
        "  # Model Evaluation\n",
        "  h=server_model.evaluate(X_test,y_test)\n",
        "  serverhist1['loss'].append(h[1])\n",
        "  serverhist1['accuracy'].append(h[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------0------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.5922 - accuracy: 0.8675 - val_loss: 0.2811 - val_accuracy: 0.9247\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2804 - accuracy: 0.9183 - val_loss: 0.2413 - val_accuracy: 0.9285\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.5271 - accuracy: 0.8484 - val_loss: 0.2994 - val_accuracy: 0.9073\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1501 - accuracy: 0.9469 - val_loss: 0.3352 - val_accuracy: 0.9110\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.4904 - accuracy: 0.8508 - val_loss: 0.3053 - val_accuracy: 0.9112\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2094 - accuracy: 0.9348 - val_loss: 0.3876 - val_accuracy: 0.9118\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.4375 - accuracy: 0.8861 - val_loss: 0.2884 - val_accuracy: 0.9138\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1300 - accuracy: 0.9650 - val_loss: 0.2580 - val_accuracy: 0.9275\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.5752 - accuracy: 0.8694 - val_loss: 0.2958 - val_accuracy: 0.9214\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2794 - accuracy: 0.9204 - val_loss: 0.2451 - val_accuracy: 0.9263\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.4970 - accuracy: 0.8371 - val_loss: 0.2976 - val_accuracy: 0.9148\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.1422 - accuracy: 0.9523 - val_loss: 0.3763 - val_accuracy: 0.8928\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5410 - accuracy: 0.8517 - val_loss: 0.2737 - val_accuracy: 0.9149\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2139 - accuracy: 0.9339 - val_loss: 0.3741 - val_accuracy: 0.9049\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.3784 - accuracy: 0.8949 - val_loss: 0.2346 - val_accuracy: 0.9301\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.1294 - accuracy: 0.9681 - val_loss: 0.2357 - val_accuracy: 0.9311\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.3777 - accuracy: 0.9069 - val_loss: 0.2185 - val_accuracy: 0.9340\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 0.1926 - val_accuracy: 0.9412\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.3600 - accuracy: 0.9133 - val_loss: 0.2378 - val_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1367 - accuracy: 0.9628 - val_loss: 0.2120 - val_accuracy: 0.9347\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4973 - accuracy: 0.8612 - val_loss: 0.3630 - val_accuracy: 0.8965\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1414 - accuracy: 0.9594 - val_loss: 0.2917 - val_accuracy: 0.9235\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.6103 - accuracy: 0.8415 - val_loss: 0.5018 - val_accuracy: 0.8743\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.2395 - accuracy: 0.9391 - val_loss: 0.4808 - val_accuracy: 0.8874\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.3779 - accuracy: 0.8999 - val_loss: 0.2175 - val_accuracy: 0.9352\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.1395 - accuracy: 0.9596 - val_loss: 0.2011 - val_accuracy: 0.9391\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.3548 - accuracy: 0.9043 - val_loss: 0.2077 - val_accuracy: 0.9388\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.1298 - accuracy: 0.9598 - val_loss: 0.1924 - val_accuracy: 0.9418\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 18ms/step - loss: 0.6159 - accuracy: 0.8437 - val_loss: 0.3884 - val_accuracy: 0.8835\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1616 - accuracy: 0.9491 - val_loss: 0.5891 - val_accuracy: 0.8588\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.3709 - accuracy: 0.8929 - val_loss: 0.2076 - val_accuracy: 0.9363\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.1425 - accuracy: 0.9586 - val_loss: 0.1885 - val_accuracy: 0.9413\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.4911 - accuracy: 0.8574 - val_loss: 0.3100 - val_accuracy: 0.9085\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1814 - accuracy: 0.9419 - val_loss: 0.4379 - val_accuracy: 0.9112\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.3802 - accuracy: 0.9025 - val_loss: 0.2239 - val_accuracy: 0.9298\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.1419 - accuracy: 0.9665 - val_loss: 0.2151 - val_accuracy: 0.9314\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.4210 - accuracy: 0.8932 - val_loss: 0.2459 - val_accuracy: 0.9259\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.1819 - accuracy: 0.9475 - val_loss: 0.2394 - val_accuracy: 0.9267\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6351 - accuracy: 0.8381 - val_loss: 0.4058 - val_accuracy: 0.8822\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2031 - accuracy: 0.9423 - val_loss: 0.3930 - val_accuracy: 0.8922\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.5030 - accuracy: 0.8572 - val_loss: 0.2969 - val_accuracy: 0.9092\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1416 - accuracy: 0.9536 - val_loss: 0.3630 - val_accuracy: 0.9032\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.8659 - val_loss: 0.2286 - val_accuracy: 0.9310\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9578 - val_loss: 0.2755 - val_accuracy: 0.9255\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.3258 - accuracy: 0.9070 - val_loss: 0.1873 - val_accuracy: 0.9425\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.1214 - accuracy: 0.9674 - val_loss: 0.1583 - val_accuracy: 0.9533\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5032 - accuracy: 0.8612 - val_loss: 0.3966 - val_accuracy: 0.8843\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1501 - accuracy: 0.9514 - val_loss: 0.3332 - val_accuracy: 0.9164\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.6284 - accuracy: 0.8624 - val_loss: 0.3475 - val_accuracy: 0.9149\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2970 - accuracy: 0.9228 - val_loss: 0.2667 - val_accuracy: 0.9258\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5254 - accuracy: 0.8501 - val_loss: 0.4062 - val_accuracy: 0.8935\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1612 - accuracy: 0.9509 - val_loss: 0.3007 - val_accuracy: 0.9175\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7369 - accuracy: 0.8641 - val_loss: 0.6193 - val_accuracy: 0.8715\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.6112 - accuracy: 0.8867 - val_loss: 0.5206 - val_accuracy: 0.8919\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.5468 - accuracy: 0.8509 - val_loss: 0.3360 - val_accuracy: 0.9072\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.1586 - accuracy: 0.9561 - val_loss: 0.3105 - val_accuracy: 0.9217\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5406 - accuracy: 0.8616 - val_loss: 0.3784 - val_accuracy: 0.8884\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.1597 - accuracy: 0.9453 - val_loss: 0.3480 - val_accuracy: 0.9096\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.3921 - accuracy: 0.8838 - val_loss: 0.2861 - val_accuracy: 0.9148\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1533 - accuracy: 0.9500 - val_loss: 0.4255 - val_accuracy: 0.8921\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1653 - accuracy: 0.9502\n",
            "---------1------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1704 - accuracy: 0.9529 - val_loss: 0.1511 - val_accuracy: 0.9552\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1502 - accuracy: 0.9517 - val_loss: 0.1475 - val_accuracy: 0.9556\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.2927 - accuracy: 0.9205 - val_loss: 0.3588 - val_accuracy: 0.8938\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1598 - accuracy: 0.9419 - val_loss: 0.2893 - val_accuracy: 0.9268\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2954 - accuracy: 0.9143 - val_loss: 0.3021 - val_accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.1370 - accuracy: 0.9541 - val_loss: 0.2463 - val_accuracy: 0.9278\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1622 - accuracy: 0.9508 - val_loss: 0.1610 - val_accuracy: 0.9518\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0728 - accuracy: 0.9834 - val_loss: 0.1650 - val_accuracy: 0.9523\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9495 - val_loss: 0.1518 - val_accuracy: 0.9544\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.1434 - accuracy: 0.9572 - val_loss: 0.1476 - val_accuracy: 0.9555\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2953 - accuracy: 0.9071 - val_loss: 0.3711 - val_accuracy: 0.8939\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.1784 - accuracy: 0.9424 - val_loss: 0.4743 - val_accuracy: 0.8912\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3555 - accuracy: 0.9007 - val_loss: 0.2765 - val_accuracy: 0.9288\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1715 - accuracy: 0.9464 - val_loss: 0.4291 - val_accuracy: 0.9088\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.1466 - accuracy: 0.9514 - val_loss: 0.1573 - val_accuracy: 0.9514\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0639 - accuracy: 0.9872 - val_loss: 0.1525 - val_accuracy: 0.9546\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1623 - accuracy: 0.9526 - val_loss: 0.1437 - val_accuracy: 0.9569\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0730 - accuracy: 0.9822 - val_loss: 0.1358 - val_accuracy: 0.9594\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.9539 - val_loss: 0.1528 - val_accuracy: 0.9526\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0695 - accuracy: 0.9827 - val_loss: 0.1466 - val_accuracy: 0.9567\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2844 - accuracy: 0.9214 - val_loss: 0.3335 - val_accuracy: 0.9026\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1780 - accuracy: 0.9502 - val_loss: 0.5735 - val_accuracy: 0.8828\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2238 - accuracy: 0.9333 - val_loss: 0.4375 - val_accuracy: 0.8839\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1269 - accuracy: 0.9622 - val_loss: 0.5724 - val_accuracy: 0.8757\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9642 - val_loss: 0.1437 - val_accuracy: 0.9561\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0741 - accuracy: 0.9803 - val_loss: 0.1374 - val_accuracy: 0.9590\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.1367 - accuracy: 0.9587 - val_loss: 0.1376 - val_accuracy: 0.9580\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0664 - accuracy: 0.9830 - val_loss: 0.1408 - val_accuracy: 0.9569\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.3147 - accuracy: 0.9039 - val_loss: 0.3161 - val_accuracy: 0.9025\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1278 - accuracy: 0.9607 - val_loss: 0.3493 - val_accuracy: 0.9021\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.1683 - accuracy: 0.9499 - val_loss: 0.1423 - val_accuracy: 0.9582\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0712 - accuracy: 0.9800 - val_loss: 0.1404 - val_accuracy: 0.9593\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2980 - accuracy: 0.9148 - val_loss: 0.3229 - val_accuracy: 0.9049\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1617 - accuracy: 0.9458 - val_loss: 0.3939 - val_accuracy: 0.9145\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.1655 - accuracy: 0.9591 - val_loss: 0.1515 - val_accuracy: 0.9533\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0890 - accuracy: 0.9770 - val_loss: 0.1463 - val_accuracy: 0.9543\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.2053 - accuracy: 0.9384 - val_loss: 0.1542 - val_accuracy: 0.9532\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 0.0865 - accuracy: 0.9733 - val_loss: 0.1485 - val_accuracy: 0.9555\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3357 - accuracy: 0.9057 - val_loss: 0.3805 - val_accuracy: 0.8885\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1528 - accuracy: 0.9468 - val_loss: 0.4378 - val_accuracy: 0.8979\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4105 - accuracy: 0.8813 - val_loss: 0.3466 - val_accuracy: 0.9090\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1629 - accuracy: 0.9521 - val_loss: 0.3919 - val_accuracy: 0.9057\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.3610 - accuracy: 0.9014 - val_loss: 0.3581 - val_accuracy: 0.8926\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1624 - accuracy: 0.9457 - val_loss: 0.5626 - val_accuracy: 0.8888\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.1461 - accuracy: 0.9554 - val_loss: 0.1352 - val_accuracy: 0.9600\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9813 - val_loss: 0.1261 - val_accuracy: 0.9615\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.4168 - accuracy: 0.8812 - val_loss: 0.4087 - val_accuracy: 0.8866\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2013 - accuracy: 0.9387 - val_loss: 0.4295 - val_accuracy: 0.9073\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9570 - val_loss: 0.1558 - val_accuracy: 0.9536\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.1370 - accuracy: 0.9591 - val_loss: 0.1513 - val_accuracy: 0.9549\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3119 - accuracy: 0.9175 - val_loss: 0.3222 - val_accuracy: 0.9027\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1166 - accuracy: 0.9566 - val_loss: 0.3497 - val_accuracy: 0.9173\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.9502 - val_loss: 0.1576 - val_accuracy: 0.9530\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9499 - val_loss: 0.1541 - val_accuracy: 0.9543\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.3999 - accuracy: 0.8870 - val_loss: 0.2826 - val_accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2272 - accuracy: 0.9225 - val_loss: 0.4567 - val_accuracy: 0.9096\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2987 - accuracy: 0.9100 - val_loss: 0.3291 - val_accuracy: 0.9070\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1026 - accuracy: 0.9670 - val_loss: 0.3252 - val_accuracy: 0.9233\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3723 - accuracy: 0.9003 - val_loss: 0.3760 - val_accuracy: 0.8871\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1457 - accuracy: 0.9521 - val_loss: 0.4587 - val_accuracy: 0.9168\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1241 - accuracy: 0.9622\n",
            "---------2------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.1397 - accuracy: 0.9572 - val_loss: 0.1181 - val_accuracy: 0.9659\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1279 - accuracy: 0.9576 - val_loss: 0.1165 - val_accuracy: 0.9664\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.2380 - accuracy: 0.9292 - val_loss: 0.3129 - val_accuracy: 0.9196\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1355 - accuracy: 0.9579 - val_loss: 0.3078 - val_accuracy: 0.9255\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2363 - accuracy: 0.9273 - val_loss: 0.4694 - val_accuracy: 0.8868\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.1605 - accuracy: 0.9537 - val_loss: 0.2997 - val_accuracy: 0.9343\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1130 - accuracy: 0.9659 - val_loss: 0.1211 - val_accuracy: 0.9645\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0532 - accuracy: 0.9883 - val_loss: 0.1294 - val_accuracy: 0.9630\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.1072 - accuracy: 0.9666 - val_loss: 0.1184 - val_accuracy: 0.9650\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.9729 - val_loss: 0.1167 - val_accuracy: 0.9651\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1955 - accuracy: 0.9462 - val_loss: 0.2502 - val_accuracy: 0.9351\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.1260 - accuracy: 0.9620 - val_loss: 0.4529 - val_accuracy: 0.9011\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2917 - accuracy: 0.9129 - val_loss: 0.3092 - val_accuracy: 0.9163\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1261 - accuracy: 0.9627 - val_loss: 0.4521 - val_accuracy: 0.9012\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.1150 - accuracy: 0.9639 - val_loss: 0.1277 - val_accuracy: 0.9629\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0392 - accuracy: 0.9914 - val_loss: 0.1293 - val_accuracy: 0.9619\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.9582 - val_loss: 0.1196 - val_accuracy: 0.9659\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0531 - accuracy: 0.9859 - val_loss: 0.1133 - val_accuracy: 0.9660\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0976 - accuracy: 0.9713 - val_loss: 0.1195 - val_accuracy: 0.9647\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0476 - accuracy: 0.9890 - val_loss: 0.1212 - val_accuracy: 0.9654\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2751 - accuracy: 0.9154 - val_loss: 0.4078 - val_accuracy: 0.9106\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2027 - accuracy: 0.9441 - val_loss: 0.4283 - val_accuracy: 0.9146\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2274 - accuracy: 0.9321 - val_loss: 0.4958 - val_accuracy: 0.8935\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1730 - accuracy: 0.9593 - val_loss: 0.7921 - val_accuracy: 0.8718\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0998 - accuracy: 0.9673 - val_loss: 0.1217 - val_accuracy: 0.9641\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0386 - accuracy: 0.9911 - val_loss: 0.1178 - val_accuracy: 0.9662\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.0914 - accuracy: 0.9724 - val_loss: 0.1183 - val_accuracy: 0.9660\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0386 - accuracy: 0.9923 - val_loss: 0.1176 - val_accuracy: 0.9675\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2646 - accuracy: 0.9273 - val_loss: 0.2895 - val_accuracy: 0.9206\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.1028 - accuracy: 0.9677 - val_loss: 0.2960 - val_accuracy: 0.9221\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 9ms/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1194 - val_accuracy: 0.9641\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.1181 - val_accuracy: 0.9676\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2810 - accuracy: 0.9294 - val_loss: 0.3347 - val_accuracy: 0.9086\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1147 - accuracy: 0.9674 - val_loss: 0.3059 - val_accuracy: 0.9326\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.1396 - accuracy: 0.9620 - val_loss: 0.1199 - val_accuracy: 0.9637\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0480 - accuracy: 0.9887 - val_loss: 0.1204 - val_accuracy: 0.9634\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.1413 - accuracy: 0.9628 - val_loss: 0.1210 - val_accuracy: 0.9652\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0567 - accuracy: 0.9880 - val_loss: 0.1307 - val_accuracy: 0.9633\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2619 - accuracy: 0.9197 - val_loss: 0.3596 - val_accuracy: 0.9026\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1399 - accuracy: 0.9501 - val_loss: 0.7874 - val_accuracy: 0.8649\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2993 - accuracy: 0.9185 - val_loss: 0.3103 - val_accuracy: 0.9269\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1819 - accuracy: 0.9434 - val_loss: 0.3088 - val_accuracy: 0.9356\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.9043 - val_loss: 0.3984 - val_accuracy: 0.8899\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2225 - accuracy: 0.9389 - val_loss: 0.4082 - val_accuracy: 0.9066\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.1220 - accuracy: 0.9638 - val_loss: 0.1108 - val_accuracy: 0.9691\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9691\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3090 - accuracy: 0.9149 - val_loss: 0.3583 - val_accuracy: 0.9026\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1621 - accuracy: 0.9556 - val_loss: 0.9122 - val_accuracy: 0.8488\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1174 - accuracy: 0.9631 - val_loss: 0.1181 - val_accuracy: 0.9644\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9701 - val_loss: 0.1154 - val_accuracy: 0.9650\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2654 - accuracy: 0.9259 - val_loss: 0.3078 - val_accuracy: 0.9092\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1241 - accuracy: 0.9563 - val_loss: 0.3821 - val_accuracy: 0.9270\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.9625 - val_loss: 0.1203 - val_accuracy: 0.9643\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0916 - accuracy: 0.9728 - val_loss: 0.1189 - val_accuracy: 0.9651\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.3172 - accuracy: 0.9101 - val_loss: 0.2517 - val_accuracy: 0.9392\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.1009 - accuracy: 0.9678 - val_loss: 0.3683 - val_accuracy: 0.9165\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2441 - accuracy: 0.9279 - val_loss: 0.3793 - val_accuracy: 0.9024\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.1360 - accuracy: 0.9617 - val_loss: 0.4850 - val_accuracy: 0.8983\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.9237 - val_loss: 0.2671 - val_accuracy: 0.9268\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.9654 - val_loss: 0.3328 - val_accuracy: 0.9199\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9691\n",
            "---------3------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.1163 - accuracy: 0.9658 - val_loss: 0.1022 - val_accuracy: 0.9706\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1069 - accuracy: 0.9693 - val_loss: 0.1012 - val_accuracy: 0.9717\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.1992 - accuracy: 0.9467 - val_loss: 0.2936 - val_accuracy: 0.9237\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1898 - accuracy: 0.9467 - val_loss: 0.4513 - val_accuracy: 0.9150\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.1995 - accuracy: 0.9429 - val_loss: 0.3457 - val_accuracy: 0.9273\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.1560 - accuracy: 0.9523 - val_loss: 0.4703 - val_accuracy: 0.9177\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1086 - accuracy: 0.9738 - val_loss: 0.1081 - val_accuracy: 0.9710\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.1127 - val_accuracy: 0.9690\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.0875 - accuracy: 0.9669 - val_loss: 0.1024 - val_accuracy: 0.9704\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.1021 - val_accuracy: 0.9707\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2834 - accuracy: 0.9270 - val_loss: 0.6234 - val_accuracy: 0.8800\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.1629 - accuracy: 0.9559 - val_loss: 0.3150 - val_accuracy: 0.9305\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2804 - accuracy: 0.9293 - val_loss: 0.4456 - val_accuracy: 0.8882\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2191 - accuracy: 0.9423 - val_loss: 0.3278 - val_accuracy: 0.9263\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.0929 - accuracy: 0.9787 - val_loss: 0.1070 - val_accuracy: 0.9685\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0304 - accuracy: 0.9921 - val_loss: 0.1104 - val_accuracy: 0.9700\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1255 - accuracy: 0.9663 - val_loss: 0.1054 - val_accuracy: 0.9706\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 9ms/step - loss: 0.0409 - accuracy: 0.9888 - val_loss: 0.1013 - val_accuracy: 0.9710\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0922 - accuracy: 0.9740 - val_loss: 0.1088 - val_accuracy: 0.9698\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0244 - accuracy: 0.9954 - val_loss: 0.1144 - val_accuracy: 0.9690\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2145 - accuracy: 0.9399 - val_loss: 0.4226 - val_accuracy: 0.9136\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2149 - accuracy: 0.9478 - val_loss: 0.4590 - val_accuracy: 0.9236\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2046 - accuracy: 0.9400 - val_loss: 0.8000 - val_accuracy: 0.8576\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1949 - accuracy: 0.9422 - val_loss: 0.4242 - val_accuracy: 0.9294\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0727 - accuracy: 0.9760 - val_loss: 0.1099 - val_accuracy: 0.9704\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.1076 - val_accuracy: 0.9700\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 0.1032 - val_accuracy: 0.9699\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.1048 - val_accuracy: 0.9708\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2179 - accuracy: 0.9485 - val_loss: 0.2843 - val_accuracy: 0.9267\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0970 - accuracy: 0.9763 - val_loss: 0.2425 - val_accuracy: 0.9459\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.1013 - accuracy: 0.9652 - val_loss: 0.1068 - val_accuracy: 0.9698\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.1072 - val_accuracy: 0.9699\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.2539 - accuracy: 0.9258 - val_loss: 0.3590 - val_accuracy: 0.9154\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2262 - accuracy: 0.9443 - val_loss: 0.5986 - val_accuracy: 0.9091\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.1233 - accuracy: 0.9675 - val_loss: 0.1064 - val_accuracy: 0.9697\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0480 - accuracy: 0.9886 - val_loss: 0.1085 - val_accuracy: 0.9699\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.1315 - accuracy: 0.9549 - val_loss: 0.1122 - val_accuracy: 0.9686\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.1187 - val_accuracy: 0.9693\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1945 - accuracy: 0.9407 - val_loss: 0.3218 - val_accuracy: 0.9276\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1623 - accuracy: 0.9589 - val_loss: 0.4871 - val_accuracy: 0.8951\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2008 - accuracy: 0.9477 - val_loss: 0.2592 - val_accuracy: 0.9362\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1553 - accuracy: 0.9621 - val_loss: 0.3998 - val_accuracy: 0.9192\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2588 - accuracy: 0.9327 - val_loss: 0.2693 - val_accuracy: 0.9325\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1591 - accuracy: 0.9572 - val_loss: 0.2641 - val_accuracy: 0.9411\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.0929 - accuracy: 0.9722 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9949 - val_loss: 0.0975 - val_accuracy: 0.9731\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2826 - accuracy: 0.9302 - val_loss: 0.4963 - val_accuracy: 0.8945\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2391 - accuracy: 0.9381 - val_loss: 0.4529 - val_accuracy: 0.9209\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0830 - accuracy: 0.9743 - val_loss: 0.1013 - val_accuracy: 0.9708\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9766 - val_loss: 0.0994 - val_accuracy: 0.9717\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2246 - accuracy: 0.9346 - val_loss: 0.2710 - val_accuracy: 0.9322\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1364 - accuracy: 0.9621 - val_loss: 0.5581 - val_accuracy: 0.8845\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0847 - accuracy: 0.9710 - val_loss: 0.1026 - val_accuracy: 0.9711\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9743 - val_loss: 0.1021 - val_accuracy: 0.9717\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.2157 - accuracy: 0.9412 - val_loss: 0.2836 - val_accuracy: 0.9333\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.1215 - accuracy: 0.9598 - val_loss: 0.4565 - val_accuracy: 0.8969\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1598 - accuracy: 0.9524 - val_loss: 0.2353 - val_accuracy: 0.9371\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.1309 - accuracy: 0.9610 - val_loss: 0.4385 - val_accuracy: 0.9140\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2663 - accuracy: 0.9333 - val_loss: 0.4359 - val_accuracy: 0.9099\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2484 - accuracy: 0.9402 - val_loss: 0.6414 - val_accuracy: 0.9039\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9722\n",
            "---------4------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.9694 - val_loss: 0.0950 - val_accuracy: 0.9741\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.0888 - accuracy: 0.9749 - val_loss: 0.0941 - val_accuracy: 0.9745\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 2s 13ms/step - loss: 0.1941 - accuracy: 0.9384 - val_loss: 0.2771 - val_accuracy: 0.9385\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1783 - accuracy: 0.9553 - val_loss: 0.6375 - val_accuracy: 0.9124\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2015 - accuracy: 0.9513 - val_loss: 0.2717 - val_accuracy: 0.9361\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2108 - accuracy: 0.9421 - val_loss: 0.6140 - val_accuracy: 0.9094\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1013 - accuracy: 0.9702 - val_loss: 0.1008 - val_accuracy: 0.9725\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0401 - accuracy: 0.9921 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.0772 - accuracy: 0.9709 - val_loss: 0.0959 - val_accuracy: 0.9735\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.0962 - val_accuracy: 0.9741\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2311 - accuracy: 0.9484 - val_loss: 0.3679 - val_accuracy: 0.9207\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.3668 - accuracy: 0.9197 - val_loss: 0.3972 - val_accuracy: 0.9288\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2609 - accuracy: 0.9384 - val_loss: 0.3659 - val_accuracy: 0.9076\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1903 - accuracy: 0.9453 - val_loss: 0.3981 - val_accuracy: 0.9310\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.1042 - accuracy: 0.9768 - val_loss: 0.1044 - val_accuracy: 0.9731\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0343 - accuracy: 0.9932 - val_loss: 0.1050 - val_accuracy: 0.9730\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1036 - accuracy: 0.9723 - val_loss: 0.1011 - val_accuracy: 0.9715\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0433 - accuracy: 0.9928 - val_loss: 0.0982 - val_accuracy: 0.9729\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0830 - accuracy: 0.9779 - val_loss: 0.1033 - val_accuracy: 0.9724\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0168 - accuracy: 0.9971 - val_loss: 0.1052 - val_accuracy: 0.9723\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2022 - accuracy: 0.9497 - val_loss: 0.4910 - val_accuracy: 0.9087\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2116 - accuracy: 0.9559 - val_loss: 0.4321 - val_accuracy: 0.9283\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1792 - accuracy: 0.9440 - val_loss: 0.4089 - val_accuracy: 0.9150\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1370 - accuracy: 0.9681 - val_loss: 0.8207 - val_accuracy: 0.9195\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0694 - accuracy: 0.9799 - val_loss: 0.0992 - val_accuracy: 0.9742\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.1072 - val_accuracy: 0.9725\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.9818 - val_loss: 0.1044 - val_accuracy: 0.9726\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9958 - val_loss: 0.1040 - val_accuracy: 0.9739\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.1822 - accuracy: 0.9563 - val_loss: 0.3598 - val_accuracy: 0.9157\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1645 - accuracy: 0.9557 - val_loss: 0.4074 - val_accuracy: 0.9168\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.0911 - accuracy: 0.9702 - val_loss: 0.0988 - val_accuracy: 0.9749\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2080 - accuracy: 0.9490 - val_loss: 0.4167 - val_accuracy: 0.9051\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1916 - accuracy: 0.9499 - val_loss: 0.3973 - val_accuracy: 0.9276\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.1116 - accuracy: 0.9733 - val_loss: 0.0975 - val_accuracy: 0.9730\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0372 - accuracy: 0.9922 - val_loss: 0.0994 - val_accuracy: 0.9717\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.0901 - accuracy: 0.9704 - val_loss: 0.1076 - val_accuracy: 0.9712\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.1114 - val_accuracy: 0.9722\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2008 - accuracy: 0.9432 - val_loss: 0.3473 - val_accuracy: 0.9238\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1284 - accuracy: 0.9599 - val_loss: 0.6098 - val_accuracy: 0.9184\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1962 - accuracy: 0.9485 - val_loss: 0.3222 - val_accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1672 - accuracy: 0.9490 - val_loss: 0.6976 - val_accuracy: 0.8986\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2367 - accuracy: 0.9481 - val_loss: 0.2997 - val_accuracy: 0.9282\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1341 - accuracy: 0.9669 - val_loss: 0.3508 - val_accuracy: 0.9285\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9771 - val_loss: 0.0903 - val_accuracy: 0.9736\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.0964 - val_accuracy: 0.9757\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1930 - accuracy: 0.9553 - val_loss: 0.3898 - val_accuracy: 0.9146\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2103 - accuracy: 0.9554 - val_loss: 0.4277 - val_accuracy: 0.9207\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0694 - accuracy: 0.9789 - val_loss: 0.0949 - val_accuracy: 0.9742\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0557 - accuracy: 0.9833 - val_loss: 0.0942 - val_accuracy: 0.9743\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2146 - accuracy: 0.9377 - val_loss: 0.7850 - val_accuracy: 0.8868\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3407 - accuracy: 0.9300 - val_loss: 1.0424 - val_accuracy: 0.8773\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0831 - accuracy: 0.9724 - val_loss: 0.0963 - val_accuracy: 0.9738\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0624 - accuracy: 0.9832 - val_loss: 0.0967 - val_accuracy: 0.9742\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.2249 - accuracy: 0.9433 - val_loss: 0.3381 - val_accuracy: 0.9375\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.1735 - accuracy: 0.9570 - val_loss: 0.4599 - val_accuracy: 0.9301\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1847 - accuracy: 0.9639 - val_loss: 0.8057 - val_accuracy: 0.8655\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.2592 - accuracy: 0.9381 - val_loss: 0.4635 - val_accuracy: 0.9187\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2619 - accuracy: 0.9391 - val_loss: 0.6609 - val_accuracy: 0.8927\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1641 - accuracy: 0.9588 - val_loss: 0.3171 - val_accuracy: 0.9380\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9743\n",
            "---------5------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.0963 - val_accuracy: 0.9750\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.0913 - accuracy: 0.9703 - val_loss: 0.0948 - val_accuracy: 0.9754\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.1602 - accuracy: 0.9583 - val_loss: 0.3867 - val_accuracy: 0.9202\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2601 - accuracy: 0.9382 - val_loss: 0.4340 - val_accuracy: 0.9172\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 10ms/step - loss: 0.1687 - accuracy: 0.9565 - val_loss: 0.5599 - val_accuracy: 0.8986\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.3040 - accuracy: 0.9388 - val_loss: 0.7222 - val_accuracy: 0.9059\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0744 - accuracy: 0.9818 - val_loss: 0.1042 - val_accuracy: 0.9738\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.1105 - val_accuracy: 0.9714\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.0983 - val_accuracy: 0.9756\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.0992 - val_accuracy: 0.9754\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1908 - accuracy: 0.9571 - val_loss: 0.4984 - val_accuracy: 0.8995\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2032 - accuracy: 0.9480 - val_loss: 0.5367 - val_accuracy: 0.9295\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2168 - accuracy: 0.9512 - val_loss: 0.2823 - val_accuracy: 0.9324\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1390 - accuracy: 0.9565 - val_loss: 0.2969 - val_accuracy: 0.9420\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.0993 - val_accuracy: 0.9747\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.1040 - val_accuracy: 0.9743\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.0913 - accuracy: 0.9786 - val_loss: 0.0958 - val_accuracy: 0.9729\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 9ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 0.0951 - val_accuracy: 0.9741\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0926 - accuracy: 0.9779 - val_loss: 0.1041 - val_accuracy: 0.9743\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.1032 - val_accuracy: 0.9746\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1478 - accuracy: 0.9614 - val_loss: 0.4788 - val_accuracy: 0.9164\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2244 - accuracy: 0.9570 - val_loss: 0.3651 - val_accuracy: 0.9415\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1321 - accuracy: 0.9704 - val_loss: 0.3594 - val_accuracy: 0.9335\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1671 - accuracy: 0.9711 - val_loss: 0.3973 - val_accuracy: 0.9337\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0657 - accuracy: 0.9821 - val_loss: 0.1079 - val_accuracy: 0.9745\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.1064 - val_accuracy: 0.9746\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 0.0970 - val_accuracy: 0.9762\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.1032 - val_accuracy: 0.9743\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2262 - accuracy: 0.9480 - val_loss: 0.4634 - val_accuracy: 0.9209\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1664 - accuracy: 0.9613 - val_loss: 0.5400 - val_accuracy: 0.9146\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.0727 - accuracy: 0.9803 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1084 - val_accuracy: 0.9749\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1911 - accuracy: 0.9584 - val_loss: 0.3386 - val_accuracy: 0.9410\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1342 - accuracy: 0.9662 - val_loss: 0.3296 - val_accuracy: 0.9313\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 2s 14ms/step - loss: 0.1279 - accuracy: 0.9732 - val_loss: 0.0980 - val_accuracy: 0.9741\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 0.0951 - val_accuracy: 0.9749\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.1194 - accuracy: 0.9690 - val_loss: 0.1004 - val_accuracy: 0.9736\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0201 - accuracy: 0.9971 - val_loss: 0.1044 - val_accuracy: 0.9745\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1589 - accuracy: 0.9613 - val_loss: 0.5123 - val_accuracy: 0.9075\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2462 - accuracy: 0.9466 - val_loss: 0.5969 - val_accuracy: 0.9170\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2342 - accuracy: 0.9401 - val_loss: 0.4130 - val_accuracy: 0.9184\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2503 - accuracy: 0.9503 - val_loss: 0.5100 - val_accuracy: 0.9172\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.1796 - accuracy: 0.9578 - val_loss: 0.2755 - val_accuracy: 0.9383\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1021 - accuracy: 0.9722 - val_loss: 0.3422 - val_accuracy: 0.9411\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.0738 - accuracy: 0.9814 - val_loss: 0.0942 - val_accuracy: 0.9752\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9940 - val_loss: 0.0980 - val_accuracy: 0.9755\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1783 - accuracy: 0.9570 - val_loss: 0.3625 - val_accuracy: 0.9223\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1941 - accuracy: 0.9569 - val_loss: 0.9074 - val_accuracy: 0.8800\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0706 - accuracy: 0.9797 - val_loss: 0.0974 - val_accuracy: 0.9754\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9808 - val_loss: 0.0962 - val_accuracy: 0.9759\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1931 - accuracy: 0.9532 - val_loss: 0.3101 - val_accuracy: 0.9316\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1604 - accuracy: 0.9604 - val_loss: 0.6384 - val_accuracy: 0.9017\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9788 - val_loss: 0.0983 - val_accuracy: 0.9750\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0575 - accuracy: 0.9831 - val_loss: 0.0987 - val_accuracy: 0.9756\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.1323 - accuracy: 0.9630 - val_loss: 0.3913 - val_accuracy: 0.9332\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.1237 - accuracy: 0.9689 - val_loss: 0.4220 - val_accuracy: 0.9391\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1376 - accuracy: 0.9658 - val_loss: 0.3090 - val_accuracy: 0.9490\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1974 - accuracy: 0.9646 - val_loss: 0.6218 - val_accuracy: 0.9166\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2839 - accuracy: 0.9439 - val_loss: 0.3349 - val_accuracy: 0.9242\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.9375 - val_loss: 0.3692 - val_accuracy: 0.9382\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9768\n",
            "---------6------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1326 - accuracy: 0.9700 - val_loss: 0.0950 - val_accuracy: 0.9773\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1039 - accuracy: 0.9758 - val_loss: 0.0939 - val_accuracy: 0.9772\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.1388 - accuracy: 0.9639 - val_loss: 0.4909 - val_accuracy: 0.9202\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2198 - accuracy: 0.9509 - val_loss: 0.5308 - val_accuracy: 0.9178\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9616 - val_loss: 0.4470 - val_accuracy: 0.9235\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.1969 - accuracy: 0.9613 - val_loss: 0.3427 - val_accuracy: 0.9439\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0932 - accuracy: 0.9840 - val_loss: 0.1030 - val_accuracy: 0.9760\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.1044 - val_accuracy: 0.9741\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 0.0972 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.0985 - val_accuracy: 0.9773\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2582 - accuracy: 0.9509 - val_loss: 0.5887 - val_accuracy: 0.9243\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.3081 - accuracy: 0.9422 - val_loss: 0.7279 - val_accuracy: 0.9255\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2824 - accuracy: 0.9425 - val_loss: 0.5274 - val_accuracy: 0.8991\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1782 - accuracy: 0.9552 - val_loss: 0.4080 - val_accuracy: 0.9345\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 0.0994 - val_accuracy: 0.9757\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0257 - accuracy: 0.9948 - val_loss: 0.1048 - val_accuracy: 0.9754\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1163 - accuracy: 0.9755 - val_loss: 0.0930 - val_accuracy: 0.9747\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.0952 - val_accuracy: 0.9745\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 14ms/step - loss: 0.0770 - accuracy: 0.9830 - val_loss: 0.1044 - val_accuracy: 0.9752\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.1060 - val_accuracy: 0.9751\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1136 - accuracy: 0.9679 - val_loss: 0.2930 - val_accuracy: 0.9484\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1494 - accuracy: 0.9637 - val_loss: 0.5151 - val_accuracy: 0.9358\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0834 - accuracy: 0.9764 - val_loss: 0.5656 - val_accuracy: 0.9046\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.2285 - accuracy: 0.9537 - val_loss: 0.9220 - val_accuracy: 0.9136\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.0981 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 0.1080 - val_accuracy: 0.9759\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0407 - accuracy: 0.9892 - val_loss: 0.0943 - val_accuracy: 0.9768\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.1042 - val_accuracy: 0.9760\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2311 - accuracy: 0.9510 - val_loss: 0.3749 - val_accuracy: 0.9088\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1705 - accuracy: 0.9466 - val_loss: 0.2609 - val_accuracy: 0.9475\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9748 - val_loss: 0.0981 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.0995 - val_accuracy: 0.9771\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2077 - accuracy: 0.9534 - val_loss: 0.3992 - val_accuracy: 0.9253\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2935 - accuracy: 0.9458 - val_loss: 0.8333 - val_accuracy: 0.9215\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.0964 - accuracy: 0.9758 - val_loss: 0.0980 - val_accuracy: 0.9755\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0415 - accuracy: 0.9896 - val_loss: 0.0976 - val_accuracy: 0.9761\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 2s 18ms/step - loss: 0.0818 - accuracy: 0.9793 - val_loss: 0.1014 - val_accuracy: 0.9744\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0347 - accuracy: 0.9922 - val_loss: 0.1042 - val_accuracy: 0.9757\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1785 - accuracy: 0.9593 - val_loss: 0.2855 - val_accuracy: 0.9471\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1678 - accuracy: 0.9571 - val_loss: 0.3762 - val_accuracy: 0.9446\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1903 - accuracy: 0.9504 - val_loss: 0.7611 - val_accuracy: 0.8908\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4550 - accuracy: 0.9252 - val_loss: 0.4234 - val_accuracy: 0.9416\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2009 - accuracy: 0.9564 - val_loss: 0.4430 - val_accuracy: 0.9435\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2801 - accuracy: 0.9508 - val_loss: 0.4432 - val_accuracy: 0.9288\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.0734 - accuracy: 0.9794 - val_loss: 0.0986 - val_accuracy: 0.9768\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0970 - val_accuracy: 0.9763\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1142 - accuracy: 0.9727 - val_loss: 0.5009 - val_accuracy: 0.9079\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1553 - accuracy: 0.9588 - val_loss: 0.4479 - val_accuracy: 0.9352\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9834 - val_loss: 0.0960 - val_accuracy: 0.9772\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0388 - accuracy: 0.9871 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1701 - accuracy: 0.9625 - val_loss: 0.4731 - val_accuracy: 0.9009\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1735 - accuracy: 0.9501 - val_loss: 0.7151 - val_accuracy: 0.9027\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 0.0969 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0677 - accuracy: 0.9806 - val_loss: 0.0973 - val_accuracy: 0.9765\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.1632 - accuracy: 0.9574 - val_loss: 0.6691 - val_accuracy: 0.9165\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.3359 - accuracy: 0.9462 - val_loss: 0.5188 - val_accuracy: 0.9318\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1084 - accuracy: 0.9664 - val_loss: 0.3627 - val_accuracy: 0.9404\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.2922 - accuracy: 0.9550 - val_loss: 0.4794 - val_accuracy: 0.9205\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2458 - accuracy: 0.9527 - val_loss: 0.4741 - val_accuracy: 0.9058\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2062 - accuracy: 0.9611 - val_loss: 0.4583 - val_accuracy: 0.9397\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9779\n",
            "---------7------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1041 - accuracy: 0.9775 - val_loss: 0.0972 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.0983 - accuracy: 0.9782 - val_loss: 0.0955 - val_accuracy: 0.9777\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.1373 - accuracy: 0.9718 - val_loss: 0.4641 - val_accuracy: 0.9224\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2073 - accuracy: 0.9549 - val_loss: 0.6495 - val_accuracy: 0.9090\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.1753 - accuracy: 0.9641 - val_loss: 0.4194 - val_accuracy: 0.9255\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.1549 - accuracy: 0.9670 - val_loss: 0.4584 - val_accuracy: 0.9399\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 2s 24ms/step - loss: 0.0570 - accuracy: 0.9875 - val_loss: 0.1028 - val_accuracy: 0.9762\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.1080 - val_accuracy: 0.9749\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.0998 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 0.1007 - val_accuracy: 0.9797\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1827 - accuracy: 0.9576 - val_loss: 0.6176 - val_accuracy: 0.9127\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.4162 - accuracy: 0.9392 - val_loss: 1.4786 - val_accuracy: 0.8887\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2473 - accuracy: 0.9512 - val_loss: 0.3231 - val_accuracy: 0.9260\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2167 - accuracy: 0.9475 - val_loss: 0.3644 - val_accuracy: 0.9466\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0915 - accuracy: 0.9838 - val_loss: 0.1080 - val_accuracy: 0.9769\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9948 - val_loss: 0.1045 - val_accuracy: 0.9760\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1184 - accuracy: 0.9739 - val_loss: 0.0947 - val_accuracy: 0.9757\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0473 - accuracy: 0.9909 - val_loss: 0.0961 - val_accuracy: 0.9764\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0973 - accuracy: 0.9809 - val_loss: 0.0995 - val_accuracy: 0.9774\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1062 - val_accuracy: 0.9761\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1110 - accuracy: 0.9635 - val_loss: 0.3132 - val_accuracy: 0.9442\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2583 - accuracy: 0.9599 - val_loss: 0.7733 - val_accuracy: 0.9250\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.1096 - accuracy: 0.9738 - val_loss: 0.3369 - val_accuracy: 0.9445\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1719 - accuracy: 0.9677 - val_loss: 0.6108 - val_accuracy: 0.9210\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 13ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 0.1025 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.1059 - val_accuracy: 0.9775\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9766\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.1060 - val_accuracy: 0.9761\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.1654 - accuracy: 0.9601 - val_loss: 0.4546 - val_accuracy: 0.9054\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.1381 - accuracy: 0.9625 - val_loss: 0.3724 - val_accuracy: 0.9350\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.0642 - accuracy: 0.9827 - val_loss: 0.1012 - val_accuracy: 0.9767\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.1168 - val_accuracy: 0.9757\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1860 - accuracy: 0.9634 - val_loss: 0.8558 - val_accuracy: 0.8730\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2896 - accuracy: 0.9380 - val_loss: 0.6726 - val_accuracy: 0.9216\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.1035 - accuracy: 0.9771 - val_loss: 0.0977 - val_accuracy: 0.9739\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0475 - accuracy: 0.9900 - val_loss: 0.0983 - val_accuracy: 0.9754\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.0679 - accuracy: 0.9828 - val_loss: 0.0992 - val_accuracy: 0.9764\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1044 - val_accuracy: 0.9765\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0836 - accuracy: 0.9797 - val_loss: 0.3956 - val_accuracy: 0.9405\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1980 - accuracy: 0.9531 - val_loss: 0.9686 - val_accuracy: 0.8944\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1917 - accuracy: 0.9642 - val_loss: 0.2935 - val_accuracy: 0.9383\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1923 - accuracy: 0.9568 - val_loss: 0.4187 - val_accuracy: 0.9382\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2699 - accuracy: 0.9476 - val_loss: 0.3751 - val_accuracy: 0.9259\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1241 - accuracy: 0.9687 - val_loss: 0.5104 - val_accuracy: 0.9228\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.0649 - accuracy: 0.9858 - val_loss: 0.1044 - val_accuracy: 0.9776\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9958 - val_loss: 0.1032 - val_accuracy: 0.9784\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1056 - accuracy: 0.9787 - val_loss: 0.4321 - val_accuracy: 0.9406\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.1464 - accuracy: 0.9692 - val_loss: 0.4337 - val_accuracy: 0.9360\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 8ms/step - loss: 0.0668 - accuracy: 0.9809 - val_loss: 0.0977 - val_accuracy: 0.9788\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 0.0966 - val_accuracy: 0.9787\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1782 - accuracy: 0.9600 - val_loss: 0.4891 - val_accuracy: 0.9237\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2140 - accuracy: 0.9608 - val_loss: 0.9867 - val_accuracy: 0.8865\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.1400 - accuracy: 0.9672 - val_loss: 0.5523 - val_accuracy: 0.9007\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.3032 - accuracy: 0.9453 - val_loss: 0.6511 - val_accuracy: 0.9234\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.3804 - val_accuracy: 0.9339\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1629 - accuracy: 0.9711 - val_loss: 0.4786 - val_accuracy: 0.9394\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3072 - accuracy: 0.9526 - val_loss: 0.5273 - val_accuracy: 0.9318\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2477 - accuracy: 0.9607 - val_loss: 0.6210 - val_accuracy: 0.9074\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9774\n",
            "---------8------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1215 - accuracy: 0.9787 - val_loss: 0.0996 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9808 - val_loss: 0.0976 - val_accuracy: 0.9782\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.1461 - accuracy: 0.9694 - val_loss: 0.5359 - val_accuracy: 0.9409\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.3130 - accuracy: 0.9567 - val_loss: 0.8682 - val_accuracy: 0.9002\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.1220 - accuracy: 0.9709 - val_loss: 0.6316 - val_accuracy: 0.9147\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.1733 - accuracy: 0.9688 - val_loss: 0.5772 - val_accuracy: 0.9326\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0426 - accuracy: 0.9832 - val_loss: 0.1077 - val_accuracy: 0.9781\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.1079 - val_accuracy: 0.9772\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 10ms/step - loss: 0.0381 - accuracy: 0.9889 - val_loss: 0.1031 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.1039 - val_accuracy: 0.9794\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.4002 - val_accuracy: 0.9472\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.1608 - accuracy: 0.9693 - val_loss: 0.7376 - val_accuracy: 0.9295\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2290 - accuracy: 0.9534 - val_loss: 0.3568 - val_accuracy: 0.9264\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2788 - accuracy: 0.9485 - val_loss: 0.7094 - val_accuracy: 0.9213\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0840 - accuracy: 0.9799 - val_loss: 0.1046 - val_accuracy: 0.9787\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9934 - val_loss: 0.1074 - val_accuracy: 0.9777\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1186 - accuracy: 0.9763 - val_loss: 0.0974 - val_accuracy: 0.9757\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0249 - accuracy: 0.9945 - val_loss: 0.0998 - val_accuracy: 0.9766\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 14ms/step - loss: 0.0698 - accuracy: 0.9844 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.1047 - val_accuracy: 0.9775\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1759 - accuracy: 0.9629 - val_loss: 0.8488 - val_accuracy: 0.9093\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6459 - accuracy: 0.9284 - val_loss: 1.0534 - val_accuracy: 0.9232\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.0942 - accuracy: 0.9855 - val_loss: 0.3303 - val_accuracy: 0.9521\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.0753 - accuracy: 0.9870 - val_loss: 0.5464 - val_accuracy: 0.9410\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0363 - accuracy: 0.9904 - val_loss: 0.1070 - val_accuracy: 0.9778\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.1118 - val_accuracy: 0.9785\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0521 - accuracy: 0.9898 - val_loss: 0.1106 - val_accuracy: 0.9785\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.1162 - val_accuracy: 0.9780\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2306 - accuracy: 0.9553 - val_loss: 0.3207 - val_accuracy: 0.9468\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3142 - accuracy: 0.9482 - val_loss: 0.5638 - val_accuracy: 0.9336\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.1071 - val_accuracy: 0.9773\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.1088 - val_accuracy: 0.9775\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1592 - accuracy: 0.9687 - val_loss: 0.6698 - val_accuracy: 0.9106\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3177 - accuracy: 0.9564 - val_loss: 0.7227 - val_accuracy: 0.9345\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.1290 - accuracy: 0.9736 - val_loss: 0.1003 - val_accuracy: 0.9764\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0479 - accuracy: 0.9910 - val_loss: 0.1014 - val_accuracy: 0.9762\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.0857 - accuracy: 0.9730 - val_loss: 0.1017 - val_accuracy: 0.9776\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.1096 - val_accuracy: 0.9768\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 18ms/step - loss: 0.1043 - accuracy: 0.9707 - val_loss: 0.3426 - val_accuracy: 0.9511\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1111 - accuracy: 0.9764 - val_loss: 0.8043 - val_accuracy: 0.9051\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1733 - accuracy: 0.9678 - val_loss: 0.4049 - val_accuracy: 0.9414\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2024 - accuracy: 0.9550 - val_loss: 0.5615 - val_accuracy: 0.9393\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.1472 - accuracy: 0.9684 - val_loss: 0.4075 - val_accuracy: 0.9428\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1957 - accuracy: 0.9603 - val_loss: 0.8934 - val_accuracy: 0.8901\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 9ms/step - loss: 0.0708 - accuracy: 0.9846 - val_loss: 0.1048 - val_accuracy: 0.9773\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.1045 - val_accuracy: 0.9780\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1610 - accuracy: 0.9635 - val_loss: 0.5174 - val_accuracy: 0.9100\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3406 - accuracy: 0.9453 - val_loss: 0.7649 - val_accuracy: 0.9142\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.0478 - accuracy: 0.9865 - val_loss: 0.1012 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9882 - val_loss: 0.1003 - val_accuracy: 0.9795\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1449 - accuracy: 0.9609 - val_loss: 0.5313 - val_accuracy: 0.9142\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.2173 - accuracy: 0.9604 - val_loss: 0.7053 - val_accuracy: 0.9249\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.0500 - accuracy: 0.9874 - val_loss: 0.1027 - val_accuracy: 0.9785\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.1022 - val_accuracy: 0.9776\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.1550 - accuracy: 0.9681 - val_loss: 0.9878 - val_accuracy: 0.8899\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2379 - accuracy: 0.9593 - val_loss: 0.7790 - val_accuracy: 0.9121\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1633 - accuracy: 0.9644 - val_loss: 0.7804 - val_accuracy: 0.9071\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.3656 - accuracy: 0.9479 - val_loss: 0.5995 - val_accuracy: 0.9349\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2985 - accuracy: 0.9510 - val_loss: 0.5449 - val_accuracy: 0.9342\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.3318 - accuracy: 0.9489 - val_loss: 1.0887 - val_accuracy: 0.9061\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9778\n",
            "---------9------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1448 - accuracy: 0.9734 - val_loss: 0.1097 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.9759 - val_loss: 0.1075 - val_accuracy: 0.9779\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.1442 - accuracy: 0.9677 - val_loss: 0.5516 - val_accuracy: 0.9295\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1737 - accuracy: 0.9679 - val_loss: 0.7779 - val_accuracy: 0.9147\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.1554 - accuracy: 0.9726 - val_loss: 0.3452 - val_accuracy: 0.9579\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.2119 - accuracy: 0.9666 - val_loss: 0.8918 - val_accuracy: 0.9201\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 0.1106 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.1106 - val_accuracy: 0.9785\n",
            "[1. 2. 1.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.0397 - accuracy: 0.9858 - val_loss: 0.1116 - val_accuracy: 0.9790\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1113 - val_accuracy: 0.9797\n",
            "[2. 2. 1.]\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.0735 - accuracy: 0.9832 - val_loss: 0.3821 - val_accuracy: 0.9473\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2064 - accuracy: 0.9618 - val_loss: 0.6494 - val_accuracy: 0.9336\n",
            "[2. 3. 1.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2918 - accuracy: 0.9502 - val_loss: 0.7487 - val_accuracy: 0.9037\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4562 - accuracy: 0.9305 - val_loss: 0.7049 - val_accuracy: 0.8926\n",
            "[2. 4. 1.]\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0939 - accuracy: 0.9862 - val_loss: 0.1105 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.1119 - val_accuracy: 0.9772\n",
            "[2. 4. 2.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.9773 - val_loss: 0.1085 - val_accuracy: 0.9755\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.0417 - accuracy: 0.9903 - val_loss: 0.1047 - val_accuracy: 0.9758\n",
            "[2. 4. 3.]\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0658 - accuracy: 0.9854 - val_loss: 0.1137 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.1113 - val_accuracy: 0.9769\n",
            "[2. 4. 4.]\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2010 - accuracy: 0.9678 - val_loss: 0.5500 - val_accuracy: 0.9431\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2196 - accuracy: 0.9634 - val_loss: 1.1751 - val_accuracy: 0.9113\n",
            "[2. 5. 4.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0688 - accuracy: 0.9828 - val_loss: 0.3285 - val_accuracy: 0.9578\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.7470 - val_accuracy: 0.9268\n",
            "[2. 6. 4.]\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.1260 - val_accuracy: 0.9773\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.1218 - val_accuracy: 0.9772\n",
            "[2. 6. 5.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.0590 - accuracy: 0.9913 - val_loss: 0.1225 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.1234 - val_accuracy: 0.9767\n",
            "[2. 6. 6.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.1987 - accuracy: 0.9582 - val_loss: 0.4230 - val_accuracy: 0.9324\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2283 - accuracy: 0.9506 - val_loss: 0.7590 - val_accuracy: 0.9095\n",
            "[2. 7. 6.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.0491 - accuracy: 0.9888 - val_loss: 0.1142 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.1176 - val_accuracy: 0.9782\n",
            "[2. 7. 7.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1648 - accuracy: 0.9679 - val_loss: 0.7296 - val_accuracy: 0.9117\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3189 - accuracy: 0.9557 - val_loss: 0.5914 - val_accuracy: 0.9356\n",
            "[2. 8. 7.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.1138 - accuracy: 0.9772 - val_loss: 0.1069 - val_accuracy: 0.9758\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0403 - accuracy: 0.9912 - val_loss: 0.1086 - val_accuracy: 0.9753\n",
            "[2. 8. 8.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.0755 - accuracy: 0.9795 - val_loss: 0.1122 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1185 - val_accuracy: 0.9773\n",
            "[2. 8. 9.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1075 - accuracy: 0.9812 - val_loss: 0.4032 - val_accuracy: 0.9402\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3808 - accuracy: 0.9474 - val_loss: 1.2775 - val_accuracy: 0.9046\n",
            "[2. 9. 9.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 2s 13ms/step - loss: 0.1041 - accuracy: 0.9772 - val_loss: 0.4168 - val_accuracy: 0.9477\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2771 - accuracy: 0.9537 - val_loss: 0.8511 - val_accuracy: 0.9243\n",
            "[ 2. 10.  9.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2106 - accuracy: 0.9633 - val_loss: 0.5207 - val_accuracy: 0.9394\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.5436 - accuracy: 0.9432 - val_loss: 0.9309 - val_accuracy: 0.9250\n",
            "[ 2. 11.  9.]\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.0670 - accuracy: 0.9861 - val_loss: 0.1120 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.1177 - val_accuracy: 0.9780\n",
            "[ 2. 11. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.1313 - accuracy: 0.9752 - val_loss: 0.9287 - val_accuracy: 0.8774\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.3024 - accuracy: 0.9463 - val_loss: 1.0025 - val_accuracy: 0.9044\n",
            "[ 2. 12. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.0526 - accuracy: 0.9845 - val_loss: 0.1111 - val_accuracy: 0.9794\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0448 - accuracy: 0.9877 - val_loss: 0.1100 - val_accuracy: 0.9799\n",
            "[ 3. 12. 10.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2507 - accuracy: 0.9623 - val_loss: 0.4512 - val_accuracy: 0.9294\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.1595 - accuracy: 0.9686 - val_loss: 1.6776 - val_accuracy: 0.8763\n",
            "[ 3. 13. 10.]\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.0619 - accuracy: 0.9842 - val_loss: 0.1117 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.0507 - accuracy: 0.9890 - val_loss: 0.1110 - val_accuracy: 0.9775\n",
            "[ 4. 13. 10.]\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.1755 - accuracy: 0.9785 - val_loss: 0.3852 - val_accuracy: 0.9318\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.1931 - accuracy: 0.9594 - val_loss: 0.5144 - val_accuracy: 0.9379\n",
            "[ 4. 14. 10.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1379 - accuracy: 0.9733 - val_loss: 0.6542 - val_accuracy: 0.9190\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5546 - accuracy: 0.9370 - val_loss: 1.0596 - val_accuracy: 0.9117\n",
            "[ 4. 15. 10.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1595 - accuracy: 0.9681 - val_loss: 0.4350 - val_accuracy: 0.9345\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1518 - accuracy: 0.9669 - val_loss: 0.5154 - val_accuracy: 0.9387\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1179 - accuracy: 0.9764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "J5gvkkJF81zS",
        "outputId": "f5956640-0248-404d-8fe9-3782ce9a8c38"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(serverhist1['accuracy'], label=\"loss\")\n",
        "ax.legend()\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(serverhist1['loss'], label=\"accuracy\")\n",
        "ax.legend()\n",
        "plt.savefig(\"Clustered Genetic FL\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5gGXFwoXzCC",
        "outputId": "1c7174ca-0620-44da-9e12-3e1fb8cda224"
      },
      "source": [
        "losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1075,\n",
              " 0.7779,\n",
              " 0.8918,\n",
              " 0.1106,\n",
              " 0.1113,\n",
              " 0.6494,\n",
              " 0.7049,\n",
              " 0.1119,\n",
              " 0.1047,\n",
              " 0.1113,\n",
              " 1.1751,\n",
              " 0.747,\n",
              " 0.1218,\n",
              " 0.1234,\n",
              " 0.759,\n",
              " 0.1176,\n",
              " 0.5914,\n",
              " 0.1086,\n",
              " 0.1185,\n",
              " 1.2775,\n",
              " 0.8511,\n",
              " 0.9309,\n",
              " 0.1177,\n",
              " 1.0025,\n",
              " 0.11,\n",
              " 1.6776,\n",
              " 0.111,\n",
              " 0.5144,\n",
              " 1.0596,\n",
              " 0.5154]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQAr-G-MXF0D",
        "outputId": "2fb01c3b-ddbc-4a3b-b116-d76eca2aa4ed"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.9764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11790527403354645, 0.9764000177383423]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp-SXeCW6DrV"
      },
      "source": [
        "# Generic FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhCR65NEqD11",
        "outputId": "84f5b42f-905e-4b44-ce92-211d93d67fb7"
      },
      "source": [
        "client_models = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "server_model_norm = create_server_model()\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "serverhist={\n",
        "    \"loss\":[],\n",
        "    \"accuracy\":[]\n",
        "}\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"-----\"+str(i)+\"---------\")\n",
        "  losses = []\n",
        "  lr_init = []\n",
        "  data= []\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    data.append(train_client(j, server_model_norm, 0.0001))\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(NUM_CLIENTS):\n",
        "    sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "  server_model_norm.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "  h=server_model_norm.evaluate(X_test,y_test)\n",
        "  serverhist['loss'].append(h[1])\n",
        "  serverhist['accuracy'].append(h[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----0---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 1.8670 - accuracy: 0.4666 - val_loss: 0.8049 - val_accuracy: 0.8213\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7000 - accuracy: 0.8381 - val_loss: 0.4888 - val_accuracy: 0.8772\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 1.9951 - accuracy: 0.4139 - val_loss: 1.1592 - val_accuracy: 0.7848\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 10ms/step - loss: 0.9596 - accuracy: 0.8103 - val_loss: 0.6576 - val_accuracy: 0.8504\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.9199 - accuracy: 0.4610 - val_loss: 0.8611 - val_accuracy: 0.8308\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.7383 - accuracy: 0.8404 - val_loss: 0.4968 - val_accuracy: 0.8802\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 2.1703 - accuracy: 0.3266 - val_loss: 1.7589 - val_accuracy: 0.6314\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 1.5468 - accuracy: 0.7399 - val_loss: 1.2183 - val_accuracy: 0.7508\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 9ms/step - loss: 1.9210 - accuracy: 0.4889 - val_loss: 0.8888 - val_accuracy: 0.8207\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.7622 - accuracy: 0.8310 - val_loss: 0.5088 - val_accuracy: 0.8774\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 2.0593 - accuracy: 0.4192 - val_loss: 1.2995 - val_accuracy: 0.7611\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0839 - accuracy: 0.7954 - val_loss: 0.7424 - val_accuracy: 0.8322\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9608 - accuracy: 0.4398 - val_loss: 0.9955 - val_accuracy: 0.8098\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8542 - accuracy: 0.8154 - val_loss: 0.5486 - val_accuracy: 0.8789\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 2.0637 - accuracy: 0.4139 - val_loss: 1.2862 - val_accuracy: 0.7806\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.0881 - accuracy: 0.7959 - val_loss: 0.7084 - val_accuracy: 0.8575\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 1.9555 - accuracy: 0.4515 - val_loss: 1.0397 - val_accuracy: 0.7828\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 9ms/step - loss: 0.8270 - accuracy: 0.8280 - val_loss: 0.5811 - val_accuracy: 0.8644\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 2.0327 - accuracy: 0.4068 - val_loss: 1.2404 - val_accuracy: 0.7584\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 1.0205 - accuracy: 0.7933 - val_loss: 0.7087 - val_accuracy: 0.8343\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 2.0615 - accuracy: 0.3953 - val_loss: 1.3090 - val_accuracy: 0.7633\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 1.1112 - accuracy: 0.7903 - val_loss: 0.7405 - val_accuracy: 0.8424\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 2.1765 - accuracy: 0.3199 - val_loss: 1.7739 - val_accuracy: 0.6344\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 1.5783 - accuracy: 0.6991 - val_loss: 1.2486 - val_accuracy: 0.7582\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 2.0383 - accuracy: 0.4048 - val_loss: 1.1595 - val_accuracy: 0.7541\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.9879 - accuracy: 0.7919 - val_loss: 0.6184 - val_accuracy: 0.8637\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 1.9642 - accuracy: 0.4710 - val_loss: 0.9739 - val_accuracy: 0.8208\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.8243 - accuracy: 0.8320 - val_loss: 0.5555 - val_accuracy: 0.8748\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 2.1420 - accuracy: 0.3747 - val_loss: 1.5761 - val_accuracy: 0.6995\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 1.3646 - accuracy: 0.7762 - val_loss: 0.9634 - val_accuracy: 0.8113\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 1.9148 - accuracy: 0.4496 - val_loss: 0.8629 - val_accuracy: 0.8176\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.7410 - accuracy: 0.8288 - val_loss: 0.4976 - val_accuracy: 0.8753\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.9185 - accuracy: 0.4612 - val_loss: 0.8973 - val_accuracy: 0.8225\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7244 - accuracy: 0.8608 - val_loss: 0.5171 - val_accuracy: 0.8713\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 2.0501 - accuracy: 0.3979 - val_loss: 1.2715 - val_accuracy: 0.7909\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0338 - accuracy: 0.8287 - val_loss: 0.7374 - val_accuracy: 0.8270\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 2.1207 - accuracy: 0.3381 - val_loss: 1.5588 - val_accuracy: 0.7014\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 1.3512 - accuracy: 0.7419 - val_loss: 0.9724 - val_accuracy: 0.8035\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.1101 - accuracy: 0.3335 - val_loss: 1.5245 - val_accuracy: 0.6918\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.3078 - accuracy: 0.7552 - val_loss: 0.9366 - val_accuracy: 0.8094\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 2.0585 - accuracy: 0.3952 - val_loss: 1.2093 - val_accuracy: 0.7781\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 1.0530 - accuracy: 0.7965 - val_loss: 0.6652 - val_accuracy: 0.8579\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.8829 - accuracy: 0.4910 - val_loss: 0.7854 - val_accuracy: 0.8347\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.6804 - accuracy: 0.8424 - val_loss: 0.4688 - val_accuracy: 0.8808\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 1.8372 - accuracy: 0.4836 - val_loss: 0.7108 - val_accuracy: 0.8507\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.6442 - accuracy: 0.8558 - val_loss: 0.4320 - val_accuracy: 0.8887\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.0965 - accuracy: 0.3410 - val_loss: 1.4410 - val_accuracy: 0.6873\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.2073 - accuracy: 0.7836 - val_loss: 0.8390 - val_accuracy: 0.8216\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.8370 - accuracy: 0.5123 - val_loss: 0.7314 - val_accuracy: 0.8559\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.6309 - accuracy: 0.8600 - val_loss: 0.4402 - val_accuracy: 0.8918\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.0876 - accuracy: 0.3946 - val_loss: 1.4170 - val_accuracy: 0.7322\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.2100 - accuracy: 0.7926 - val_loss: 0.8266 - val_accuracy: 0.8213\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.8475 - accuracy: 0.5012 - val_loss: 0.7196 - val_accuracy: 0.8573\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.8431 - val_loss: 0.4335 - val_accuracy: 0.8910\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 2.0823 - accuracy: 0.3532 - val_loss: 1.3828 - val_accuracy: 0.7321\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 1.1855 - accuracy: 0.7681 - val_loss: 0.7836 - val_accuracy: 0.8154\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.0945 - accuracy: 0.3542 - val_loss: 1.4375 - val_accuracy: 0.7467\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 1.2052 - accuracy: 0.8039 - val_loss: 0.8353 - val_accuracy: 0.8436\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 1.8492 - accuracy: 0.5255 - val_loss: 0.7810 - val_accuracy: 0.8433\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6127 - accuracy: 0.8730 - val_loss: 0.4671 - val_accuracy: 0.8827\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6993 - accuracy: 0.8470\n",
            "-----1---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.5991 - accuracy: 0.8613 - val_loss: 0.4186 - val_accuracy: 0.8913\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.4020 - accuracy: 0.8951 - val_loss: 0.3710 - val_accuracy: 0.8964\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.5944 - accuracy: 0.8567 - val_loss: 0.4656 - val_accuracy: 0.8868\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.4337 - accuracy: 0.8889 - val_loss: 0.4021 - val_accuracy: 0.8929\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.6138 - accuracy: 0.8440 - val_loss: 0.4303 - val_accuracy: 0.8927\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.4132 - accuracy: 0.8937 - val_loss: 0.3578 - val_accuracy: 0.9021\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5949 - accuracy: 0.8685 - val_loss: 0.5354 - val_accuracy: 0.8770\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.4593 - accuracy: 0.9008 - val_loss: 0.4847 - val_accuracy: 0.8806\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.6044 - accuracy: 0.8619 - val_loss: 0.4353 - val_accuracy: 0.8891\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4104 - accuracy: 0.8838 - val_loss: 0.3731 - val_accuracy: 0.8982\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.5901 - accuracy: 0.8643 - val_loss: 0.4863 - val_accuracy: 0.8807\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.4365 - accuracy: 0.8832 - val_loss: 0.4256 - val_accuracy: 0.8880\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6197 - accuracy: 0.8513 - val_loss: 0.4484 - val_accuracy: 0.8897\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8978 - val_loss: 0.3765 - val_accuracy: 0.8997\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.6333 - accuracy: 0.8502 - val_loss: 0.4855 - val_accuracy: 0.8866\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.4461 - accuracy: 0.8924 - val_loss: 0.4310 - val_accuracy: 0.8925\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.5801 - accuracy: 0.8677 - val_loss: 0.4459 - val_accuracy: 0.8870\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 9ms/step - loss: 0.3828 - accuracy: 0.9017 - val_loss: 0.3848 - val_accuracy: 0.8974\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.5567 - accuracy: 0.8814 - val_loss: 0.4807 - val_accuracy: 0.8784\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.4135 - accuracy: 0.8875 - val_loss: 0.4134 - val_accuracy: 0.8916\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5804 - accuracy: 0.8774 - val_loss: 0.4763 - val_accuracy: 0.8864\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4273 - accuracy: 0.9006 - val_loss: 0.4019 - val_accuracy: 0.8968\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 2s 24ms/step - loss: 0.5436 - accuracy: 0.8760 - val_loss: 0.5349 - val_accuracy: 0.8777\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.3916 - accuracy: 0.9276 - val_loss: 0.4773 - val_accuracy: 0.8784\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.6109 - accuracy: 0.8581 - val_loss: 0.4614 - val_accuracy: 0.8839\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.4389 - accuracy: 0.8896 - val_loss: 0.3903 - val_accuracy: 0.9001\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.5894 - accuracy: 0.8615 - val_loss: 0.4433 - val_accuracy: 0.8931\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.4229 - accuracy: 0.8979 - val_loss: 0.3846 - val_accuracy: 0.8971\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.6408 - accuracy: 0.8542 - val_loss: 0.5109 - val_accuracy: 0.8732\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.4901 - accuracy: 0.8759 - val_loss: 0.4497 - val_accuracy: 0.8807\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.6046 - accuracy: 0.8490 - val_loss: 0.4284 - val_accuracy: 0.8933\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.4056 - accuracy: 0.8941 - val_loss: 0.3762 - val_accuracy: 0.8963\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.5466 - accuracy: 0.8878 - val_loss: 0.4320 - val_accuracy: 0.8893\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3559 - accuracy: 0.9088 - val_loss: 0.3795 - val_accuracy: 0.8938\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.6006 - accuracy: 0.8680 - val_loss: 0.4891 - val_accuracy: 0.8771\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4254 - accuracy: 0.9030 - val_loss: 0.4319 - val_accuracy: 0.8794\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.6523 - accuracy: 0.8589 - val_loss: 0.5129 - val_accuracy: 0.8778\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.4849 - accuracy: 0.8933 - val_loss: 0.4563 - val_accuracy: 0.8846\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6233 - accuracy: 0.8603 - val_loss: 0.5088 - val_accuracy: 0.8775\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.4761 - accuracy: 0.8887 - val_loss: 0.4440 - val_accuracy: 0.8878\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.6585 - accuracy: 0.8385 - val_loss: 0.4828 - val_accuracy: 0.8781\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4582 - accuracy: 0.8795 - val_loss: 0.3930 - val_accuracy: 0.9015\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.5937 - accuracy: 0.8572 - val_loss: 0.4167 - val_accuracy: 0.8914\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8847 - val_loss: 0.3665 - val_accuracy: 0.8987\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.5969 - accuracy: 0.8552 - val_loss: 0.3983 - val_accuracy: 0.8983\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.3866 - accuracy: 0.8982 - val_loss: 0.3361 - val_accuracy: 0.9073\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.6012 - accuracy: 0.8588 - val_loss: 0.5044 - val_accuracy: 0.8742\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.4524 - accuracy: 0.8986 - val_loss: 0.4434 - val_accuracy: 0.8830\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5738 - accuracy: 0.8581 - val_loss: 0.4115 - val_accuracy: 0.8956\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.3846 - accuracy: 0.8951 - val_loss: 0.3411 - val_accuracy: 0.9109\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.6381 - accuracy: 0.8461 - val_loss: 0.5001 - val_accuracy: 0.8825\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.4655 - accuracy: 0.8803 - val_loss: 0.4308 - val_accuracy: 0.8898\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5921 - accuracy: 0.8546 - val_loss: 0.4058 - val_accuracy: 0.8991\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.4091 - accuracy: 0.8870 - val_loss: 0.3416 - val_accuracy: 0.9070\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.6518 - accuracy: 0.8379 - val_loss: 0.4888 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.4900 - accuracy: 0.8791 - val_loss: 0.4397 - val_accuracy: 0.8818\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5843 - accuracy: 0.8747 - val_loss: 0.4887 - val_accuracy: 0.8879\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.4226 - accuracy: 0.9072 - val_loss: 0.4350 - val_accuracy: 0.8817\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.5297 - accuracy: 0.8884 - val_loss: 0.4177 - val_accuracy: 0.8912\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.3545 - accuracy: 0.9130 - val_loss: 0.3626 - val_accuracy: 0.8988\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3784 - accuracy: 0.9040\n",
            "-----2---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3962 - accuracy: 0.8981 - val_loss: 0.3359 - val_accuracy: 0.9048\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.9028 - val_loss: 0.3181 - val_accuracy: 0.9121\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.3771 - accuracy: 0.8962 - val_loss: 0.3555 - val_accuracy: 0.9028\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.3348 - accuracy: 0.9019 - val_loss: 0.3499 - val_accuracy: 0.9013\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.4028 - accuracy: 0.8930 - val_loss: 0.3477 - val_accuracy: 0.9012\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.3173 - accuracy: 0.9105 - val_loss: 0.3238 - val_accuracy: 0.9093\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3401 - accuracy: 0.9017 - val_loss: 0.3717 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.3152 - accuracy: 0.9166 - val_loss: 0.3684 - val_accuracy: 0.8999\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4007 - accuracy: 0.8871 - val_loss: 0.3423 - val_accuracy: 0.9057\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3250 - accuracy: 0.9057 - val_loss: 0.3191 - val_accuracy: 0.9097\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3621 - accuracy: 0.9024 - val_loss: 0.3597 - val_accuracy: 0.9004\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.3268 - accuracy: 0.9059 - val_loss: 0.3538 - val_accuracy: 0.8985\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3885 - accuracy: 0.8937 - val_loss: 0.3532 - val_accuracy: 0.9034\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3285 - accuracy: 0.9093 - val_loss: 0.3218 - val_accuracy: 0.9117\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.3833 - accuracy: 0.8954 - val_loss: 0.3585 - val_accuracy: 0.9043\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.3485 - accuracy: 0.9010 - val_loss: 0.3456 - val_accuracy: 0.9053\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.3742 - accuracy: 0.8987 - val_loss: 0.3447 - val_accuracy: 0.9045\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 9ms/step - loss: 0.3134 - accuracy: 0.9146 - val_loss: 0.3334 - val_accuracy: 0.9029\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.3685 - accuracy: 0.9048 - val_loss: 0.3686 - val_accuracy: 0.8966\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.2983 - accuracy: 0.9203 - val_loss: 0.3411 - val_accuracy: 0.9051\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3834 - accuracy: 0.8938 - val_loss: 0.3605 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3531 - accuracy: 0.8975 - val_loss: 0.3325 - val_accuracy: 0.9055\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.3105 - accuracy: 0.9203 - val_loss: 0.3715 - val_accuracy: 0.8984\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.2868 - accuracy: 0.9207 - val_loss: 0.3603 - val_accuracy: 0.8980\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 2s 12ms/step - loss: 0.3876 - accuracy: 0.8968 - val_loss: 0.3525 - val_accuracy: 0.9048\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.3230 - accuracy: 0.9145 - val_loss: 0.3400 - val_accuracy: 0.9007\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.4119 - accuracy: 0.8903 - val_loss: 0.3419 - val_accuracy: 0.9084\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.3150 - accuracy: 0.9084 - val_loss: 0.3280 - val_accuracy: 0.9106\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.4134 - accuracy: 0.8862 - val_loss: 0.3600 - val_accuracy: 0.9036\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3531 - accuracy: 0.9069 - val_loss: 0.3482 - val_accuracy: 0.9041\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.4067 - accuracy: 0.8840 - val_loss: 0.3427 - val_accuracy: 0.9064\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.3338 - accuracy: 0.9090 - val_loss: 0.3120 - val_accuracy: 0.9136\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3591 - accuracy: 0.9073 - val_loss: 0.3397 - val_accuracy: 0.9053\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2828 - accuracy: 0.9228 - val_loss: 0.3234 - val_accuracy: 0.9089\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.3638 - accuracy: 0.9044 - val_loss: 0.3639 - val_accuracy: 0.8971\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.3025 - accuracy: 0.9157 - val_loss: 0.3514 - val_accuracy: 0.8997\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.4596 - accuracy: 0.8632 - val_loss: 0.3623 - val_accuracy: 0.9062\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.3553 - accuracy: 0.9090 - val_loss: 0.3696 - val_accuracy: 0.8984\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4013 - accuracy: 0.8914 - val_loss: 0.3616 - val_accuracy: 0.9010\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.3162 - accuracy: 0.9116 - val_loss: 0.3510 - val_accuracy: 0.9026\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4227 - accuracy: 0.8795 - val_loss: 0.3594 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.3624 - accuracy: 0.8936 - val_loss: 0.3382 - val_accuracy: 0.9042\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.4003 - accuracy: 0.8910 - val_loss: 0.3403 - val_accuracy: 0.9050\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3413 - accuracy: 0.9056 - val_loss: 0.3118 - val_accuracy: 0.9141\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.4037 - accuracy: 0.8785 - val_loss: 0.3278 - val_accuracy: 0.9099\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.3142 - accuracy: 0.9131 - val_loss: 0.3041 - val_accuracy: 0.9117\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3988 - accuracy: 0.8912 - val_loss: 0.3684 - val_accuracy: 0.8998\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3408 - accuracy: 0.9050 - val_loss: 0.3615 - val_accuracy: 0.8980\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3719 - accuracy: 0.9019 - val_loss: 0.3317 - val_accuracy: 0.9097\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.3000 - accuracy: 0.9181 - val_loss: 0.3124 - val_accuracy: 0.9129\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.4233 - accuracy: 0.8771 - val_loss: 0.3614 - val_accuracy: 0.9025\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3500 - accuracy: 0.9050 - val_loss: 0.3609 - val_accuracy: 0.8969\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4127 - accuracy: 0.8824 - val_loss: 0.3386 - val_accuracy: 0.9064\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.9024 - val_loss: 0.3145 - val_accuracy: 0.9129\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 2s 21ms/step - loss: 0.4330 - accuracy: 0.8824 - val_loss: 0.3624 - val_accuracy: 0.9017\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.3916 - accuracy: 0.8871 - val_loss: 0.3421 - val_accuracy: 0.9055\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.3839 - accuracy: 0.9010 - val_loss: 0.3547 - val_accuracy: 0.9023\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.3066 - accuracy: 0.9123 - val_loss: 0.3411 - val_accuracy: 0.9048\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3347 - accuracy: 0.9111 - val_loss: 0.3297 - val_accuracy: 0.9090\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2649 - accuracy: 0.9322 - val_loss: 0.3094 - val_accuracy: 0.9115\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.9148\n",
            "-----3---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3179 - accuracy: 0.9143 - val_loss: 0.3052 - val_accuracy: 0.9140\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2922 - accuracy: 0.9121 - val_loss: 0.2941 - val_accuracy: 0.9172\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.3037 - accuracy: 0.9145 - val_loss: 0.3083 - val_accuracy: 0.9129\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2895 - accuracy: 0.9140 - val_loss: 0.3077 - val_accuracy: 0.9128\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.3247 - accuracy: 0.9092 - val_loss: 0.3164 - val_accuracy: 0.9125\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2786 - accuracy: 0.9158 - val_loss: 0.2893 - val_accuracy: 0.9185\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2721 - accuracy: 0.9200 - val_loss: 0.3158 - val_accuracy: 0.9113\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2413 - accuracy: 0.9321 - val_loss: 0.3251 - val_accuracy: 0.9051\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.3365 - accuracy: 0.9015 - val_loss: 0.3123 - val_accuracy: 0.9104\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.9069 - val_loss: 0.2989 - val_accuracy: 0.9104\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3029 - accuracy: 0.9037 - val_loss: 0.3139 - val_accuracy: 0.9118\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2582 - accuracy: 0.9295 - val_loss: 0.3044 - val_accuracy: 0.9144\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3330 - accuracy: 0.9014 - val_loss: 0.3118 - val_accuracy: 0.9103\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2981 - accuracy: 0.9163 - val_loss: 0.3068 - val_accuracy: 0.9108\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.2998 - accuracy: 0.9105 - val_loss: 0.3112 - val_accuracy: 0.9156\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.2728 - accuracy: 0.9180 - val_loss: 0.3109 - val_accuracy: 0.9141\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.3102 - accuracy: 0.9110 - val_loss: 0.3091 - val_accuracy: 0.9118\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.2927 - accuracy: 0.9145 - val_loss: 0.3006 - val_accuracy: 0.9139\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.3325 - accuracy: 0.9039 - val_loss: 0.3158 - val_accuracy: 0.9100\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.2895 - accuracy: 0.9224 - val_loss: 0.3029 - val_accuracy: 0.9139\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2990 - accuracy: 0.9139 - val_loss: 0.3228 - val_accuracy: 0.9081\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2468 - accuracy: 0.9346 - val_loss: 0.2990 - val_accuracy: 0.9141\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2776 - accuracy: 0.9224 - val_loss: 0.3165 - val_accuracy: 0.9111\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1970 - accuracy: 0.9409 - val_loss: 0.3054 - val_accuracy: 0.9143\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.3140 - accuracy: 0.9118 - val_loss: 0.3024 - val_accuracy: 0.9156\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2747 - accuracy: 0.9226 - val_loss: 0.2944 - val_accuracy: 0.9156\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.3131 - accuracy: 0.9049 - val_loss: 0.3162 - val_accuracy: 0.9126\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.2716 - accuracy: 0.9231 - val_loss: 0.3008 - val_accuracy: 0.9142\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.3393 - accuracy: 0.9076 - val_loss: 0.3138 - val_accuracy: 0.9119\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.3582 - accuracy: 0.8967 - val_loss: 0.3114 - val_accuracy: 0.9087\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.3375 - accuracy: 0.8952 - val_loss: 0.3054 - val_accuracy: 0.9153\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2744 - accuracy: 0.9170 - val_loss: 0.2907 - val_accuracy: 0.9190\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2882 - accuracy: 0.9195 - val_loss: 0.3115 - val_accuracy: 0.9130\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2545 - accuracy: 0.9322 - val_loss: 0.2967 - val_accuracy: 0.9138\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.3253 - accuracy: 0.9037 - val_loss: 0.3156 - val_accuracy: 0.9114\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.2838 - accuracy: 0.9237 - val_loss: 0.3199 - val_accuracy: 0.9082\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.3532 - accuracy: 0.8948 - val_loss: 0.3112 - val_accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.3280 - accuracy: 0.9140 - val_loss: 0.3164 - val_accuracy: 0.9115\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3349 - accuracy: 0.8951 - val_loss: 0.3152 - val_accuracy: 0.9100\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3026 - accuracy: 0.9085 - val_loss: 0.3084 - val_accuracy: 0.9109\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.3297 - accuracy: 0.9115 - val_loss: 0.3117 - val_accuracy: 0.9126\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2796 - accuracy: 0.9151 - val_loss: 0.3100 - val_accuracy: 0.9106\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.3489 - accuracy: 0.9019 - val_loss: 0.3083 - val_accuracy: 0.9138\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2733 - accuracy: 0.9183 - val_loss: 0.2880 - val_accuracy: 0.9182\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.3236 - accuracy: 0.9100 - val_loss: 0.2912 - val_accuracy: 0.9176\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.2871 - accuracy: 0.9205 - val_loss: 0.2772 - val_accuracy: 0.9199\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3377 - accuracy: 0.9012 - val_loss: 0.3278 - val_accuracy: 0.9084\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3021 - accuracy: 0.9170 - val_loss: 0.3227 - val_accuracy: 0.9088\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.9099 - val_loss: 0.3050 - val_accuracy: 0.9150\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.9243 - val_loss: 0.2903 - val_accuracy: 0.9194\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3515 - accuracy: 0.8988 - val_loss: 0.3229 - val_accuracy: 0.9071\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.3011 - accuracy: 0.9024 - val_loss: 0.3114 - val_accuracy: 0.9102\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3457 - accuracy: 0.9034 - val_loss: 0.3003 - val_accuracy: 0.9155\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2816 - accuracy: 0.9155 - val_loss: 0.2882 - val_accuracy: 0.9202\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.3760 - accuracy: 0.8875 - val_loss: 0.3129 - val_accuracy: 0.9129\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.3427 - accuracy: 0.8991 - val_loss: 0.3038 - val_accuracy: 0.9124\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 2s 15ms/step - loss: 0.2938 - accuracy: 0.9227 - val_loss: 0.3121 - val_accuracy: 0.9121\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.2499 - accuracy: 0.9383 - val_loss: 0.3042 - val_accuracy: 0.9121\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2870 - accuracy: 0.9214 - val_loss: 0.2969 - val_accuracy: 0.9157\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2431 - accuracy: 0.9358 - val_loss: 0.2797 - val_accuracy: 0.9185\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.9217\n",
            "-----4---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3063 - accuracy: 0.9106 - val_loss: 0.2919 - val_accuracy: 0.9164\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2853 - accuracy: 0.9216 - val_loss: 0.2736 - val_accuracy: 0.9228\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.2816 - accuracy: 0.9130 - val_loss: 0.2826 - val_accuracy: 0.9213\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2668 - accuracy: 0.9192 - val_loss: 0.2805 - val_accuracy: 0.9196\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.3105 - accuracy: 0.9146 - val_loss: 0.2871 - val_accuracy: 0.9195\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2659 - accuracy: 0.9239 - val_loss: 0.2803 - val_accuracy: 0.9196\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2823 - accuracy: 0.9300 - val_loss: 0.2841 - val_accuracy: 0.9203\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2544 - accuracy: 0.9245 - val_loss: 0.2855 - val_accuracy: 0.9194\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.9093 - val_loss: 0.2869 - val_accuracy: 0.9165\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2555 - accuracy: 0.9245 - val_loss: 0.2824 - val_accuracy: 0.9187\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3052 - accuracy: 0.9171 - val_loss: 0.2886 - val_accuracy: 0.9185\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2541 - accuracy: 0.9216 - val_loss: 0.2942 - val_accuracy: 0.9148\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3429 - accuracy: 0.9023 - val_loss: 0.2777 - val_accuracy: 0.9215\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2910 - accuracy: 0.9181 - val_loss: 0.2845 - val_accuracy: 0.9210\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2706 - accuracy: 0.9152 - val_loss: 0.2939 - val_accuracy: 0.9188\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.2128 - accuracy: 0.9331 - val_loss: 0.2825 - val_accuracy: 0.9220\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.3068 - accuracy: 0.9173 - val_loss: 0.2839 - val_accuracy: 0.9177\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.2577 - accuracy: 0.9310 - val_loss: 0.2736 - val_accuracy: 0.9181\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.2916 - accuracy: 0.9152 - val_loss: 0.2855 - val_accuracy: 0.9196\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.2599 - accuracy: 0.9295 - val_loss: 0.2850 - val_accuracy: 0.9174\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2816 - accuracy: 0.9226 - val_loss: 0.2823 - val_accuracy: 0.9202\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2390 - accuracy: 0.9319 - val_loss: 0.2847 - val_accuracy: 0.9161\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.2316 - accuracy: 0.9375 - val_loss: 0.2881 - val_accuracy: 0.9202\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1950 - accuracy: 0.9537 - val_loss: 0.2838 - val_accuracy: 0.9177\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.2933 - accuracy: 0.9128 - val_loss: 0.2856 - val_accuracy: 0.9199\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2541 - accuracy: 0.9244 - val_loss: 0.2824 - val_accuracy: 0.9175\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 15ms/step - loss: 0.2535 - accuracy: 0.9233 - val_loss: 0.2933 - val_accuracy: 0.9178\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.2208 - accuracy: 0.9445 - val_loss: 0.2732 - val_accuracy: 0.9252\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.3529 - accuracy: 0.9108 - val_loss: 0.2856 - val_accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2527 - accuracy: 0.9254 - val_loss: 0.2849 - val_accuracy: 0.9190\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.2975 - accuracy: 0.9106 - val_loss: 0.2794 - val_accuracy: 0.9190\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2635 - accuracy: 0.9246 - val_loss: 0.2643 - val_accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2627 - accuracy: 0.9218 - val_loss: 0.2850 - val_accuracy: 0.9179\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2306 - accuracy: 0.9348 - val_loss: 0.2753 - val_accuracy: 0.9219\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.2841 - accuracy: 0.9159 - val_loss: 0.2810 - val_accuracy: 0.9196\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.2584 - accuracy: 0.9354 - val_loss: 0.2883 - val_accuracy: 0.9168\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.3453 - accuracy: 0.8996 - val_loss: 0.2872 - val_accuracy: 0.9190\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.3334 - accuracy: 0.9011 - val_loss: 0.2980 - val_accuracy: 0.9155\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2856 - accuracy: 0.9057 - val_loss: 0.2831 - val_accuracy: 0.9186\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2329 - accuracy: 0.9297 - val_loss: 0.2917 - val_accuracy: 0.9141\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2803 - accuracy: 0.9196 - val_loss: 0.2922 - val_accuracy: 0.9151\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2490 - accuracy: 0.9310 - val_loss: 0.2718 - val_accuracy: 0.9225\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2910 - accuracy: 0.9109 - val_loss: 0.2909 - val_accuracy: 0.9169\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2597 - accuracy: 0.9288 - val_loss: 0.2784 - val_accuracy: 0.9196\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.2935 - accuracy: 0.9188 - val_loss: 0.2692 - val_accuracy: 0.9218\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.2649 - accuracy: 0.9229 - val_loss: 0.2696 - val_accuracy: 0.9211\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.3096 - accuracy: 0.9153 - val_loss: 0.3128 - val_accuracy: 0.9117\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2768 - accuracy: 0.9206 - val_loss: 0.3021 - val_accuracy: 0.9159\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2660 - accuracy: 0.9209 - val_loss: 0.2817 - val_accuracy: 0.9203\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2435 - accuracy: 0.9318 - val_loss: 0.2684 - val_accuracy: 0.9246\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2998 - accuracy: 0.9135 - val_loss: 0.2839 - val_accuracy: 0.9187\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2439 - accuracy: 0.9438 - val_loss: 0.2907 - val_accuracy: 0.9166\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.3026 - accuracy: 0.9149 - val_loss: 0.2849 - val_accuracy: 0.9170\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2525 - accuracy: 0.9268 - val_loss: 0.2841 - val_accuracy: 0.9176\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.3553 - accuracy: 0.8963 - val_loss: 0.2854 - val_accuracy: 0.9203\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2820 - accuracy: 0.9190 - val_loss: 0.2801 - val_accuracy: 0.9213\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2730 - accuracy: 0.9217 - val_loss: 0.2871 - val_accuracy: 0.9179\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.2348 - accuracy: 0.9389 - val_loss: 0.2777 - val_accuracy: 0.9197\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.2678 - accuracy: 0.9222 - val_loss: 0.2734 - val_accuracy: 0.9218\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2322 - accuracy: 0.9338 - val_loss: 0.2673 - val_accuracy: 0.9227\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9256\n",
            "-----5---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.9104 - val_loss: 0.2624 - val_accuracy: 0.9269\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2632 - accuracy: 0.9197 - val_loss: 0.2695 - val_accuracy: 0.9241\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.2906 - accuracy: 0.9206 - val_loss: 0.2694 - val_accuracy: 0.9219\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2448 - accuracy: 0.9218 - val_loss: 0.2674 - val_accuracy: 0.9229\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.2666 - accuracy: 0.9248 - val_loss: 0.2754 - val_accuracy: 0.9225\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2226 - accuracy: 0.9351 - val_loss: 0.2589 - val_accuracy: 0.9265\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2577 - accuracy: 0.9247 - val_loss: 0.2690 - val_accuracy: 0.9228\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.1930 - accuracy: 0.9461 - val_loss: 0.2778 - val_accuracy: 0.9189\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.2884 - accuracy: 0.9105 - val_loss: 0.2641 - val_accuracy: 0.9232\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2288 - accuracy: 0.9314 - val_loss: 0.2579 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2916 - accuracy: 0.9159 - val_loss: 0.2682 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2220 - accuracy: 0.9338 - val_loss: 0.2753 - val_accuracy: 0.9217\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2911 - accuracy: 0.9181 - val_loss: 0.2833 - val_accuracy: 0.9188\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2781 - accuracy: 0.9204 - val_loss: 0.2635 - val_accuracy: 0.9270\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2585 - accuracy: 0.9197 - val_loss: 0.2666 - val_accuracy: 0.9254\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.2292 - accuracy: 0.9364 - val_loss: 0.2684 - val_accuracy: 0.9261\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.2718 - accuracy: 0.9266 - val_loss: 0.2688 - val_accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.2827 - accuracy: 0.9229 - val_loss: 0.2729 - val_accuracy: 0.9201\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 14ms/step - loss: 0.2555 - accuracy: 0.9236 - val_loss: 0.2713 - val_accuracy: 0.9211\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.2331 - accuracy: 0.9364 - val_loss: 0.2714 - val_accuracy: 0.9204\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2451 - accuracy: 0.9300 - val_loss: 0.2730 - val_accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1840 - accuracy: 0.9520 - val_loss: 0.2703 - val_accuracy: 0.9223\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2095 - accuracy: 0.9356 - val_loss: 0.2689 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1681 - accuracy: 0.9583 - val_loss: 0.2670 - val_accuracy: 0.9221\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.2770 - accuracy: 0.9205 - val_loss: 0.2673 - val_accuracy: 0.9234\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2446 - accuracy: 0.9285 - val_loss: 0.2611 - val_accuracy: 0.9250\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 10ms/step - loss: 0.2613 - accuracy: 0.9253 - val_loss: 0.2660 - val_accuracy: 0.9242\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.2267 - accuracy: 0.9343 - val_loss: 0.2654 - val_accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 18ms/step - loss: 0.3144 - accuracy: 0.9118 - val_loss: 0.2646 - val_accuracy: 0.9235\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.2688 - accuracy: 0.9210 - val_loss: 0.2703 - val_accuracy: 0.9247\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.2637 - accuracy: 0.9231 - val_loss: 0.2659 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2530 - accuracy: 0.9246 - val_loss: 0.2559 - val_accuracy: 0.9250\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2439 - accuracy: 0.9283 - val_loss: 0.2597 - val_accuracy: 0.9262\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2278 - accuracy: 0.9264 - val_loss: 0.2754 - val_accuracy: 0.9197\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.2734 - accuracy: 0.9283 - val_loss: 0.2714 - val_accuracy: 0.9216\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.2132 - accuracy: 0.9438 - val_loss: 0.2932 - val_accuracy: 0.9148\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.3061 - accuracy: 0.9110 - val_loss: 0.2700 - val_accuracy: 0.9232\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.2674 - accuracy: 0.9212 - val_loss: 0.2728 - val_accuracy: 0.9202\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2469 - accuracy: 0.9214 - val_loss: 0.2681 - val_accuracy: 0.9211\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2199 - accuracy: 0.9362 - val_loss: 0.2701 - val_accuracy: 0.9199\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2639 - accuracy: 0.9228 - val_loss: 0.2643 - val_accuracy: 0.9246\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2343 - accuracy: 0.9340 - val_loss: 0.2643 - val_accuracy: 0.9242\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2781 - accuracy: 0.9185 - val_loss: 0.2680 - val_accuracy: 0.9225\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2601 - accuracy: 0.9238 - val_loss: 0.2621 - val_accuracy: 0.9253\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.2642 - accuracy: 0.9273 - val_loss: 0.2597 - val_accuracy: 0.9260\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.2463 - accuracy: 0.9327 - val_loss: 0.2538 - val_accuracy: 0.9266\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2852 - accuracy: 0.9205 - val_loss: 0.2714 - val_accuracy: 0.9232\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2499 - accuracy: 0.9324 - val_loss: 0.2787 - val_accuracy: 0.9194\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2583 - accuracy: 0.9233 - val_loss: 0.2612 - val_accuracy: 0.9273\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2215 - accuracy: 0.9358 - val_loss: 0.2530 - val_accuracy: 0.9296\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2959 - accuracy: 0.9127 - val_loss: 0.2712 - val_accuracy: 0.9220\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2927 - accuracy: 0.9152 - val_loss: 0.2730 - val_accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2898 - accuracy: 0.9158 - val_loss: 0.2585 - val_accuracy: 0.9281\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2316 - accuracy: 0.9358 - val_loss: 0.2561 - val_accuracy: 0.9293\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.2775 - accuracy: 0.9172 - val_loss: 0.2735 - val_accuracy: 0.9210\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.2812 - accuracy: 0.9091 - val_loss: 0.2601 - val_accuracy: 0.9251\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2497 - accuracy: 0.9240 - val_loss: 0.2742 - val_accuracy: 0.9205\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.2162 - accuracy: 0.9428 - val_loss: 0.2641 - val_accuracy: 0.9225\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2516 - accuracy: 0.9288 - val_loss: 0.2645 - val_accuracy: 0.9214\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1975 - accuracy: 0.9468 - val_loss: 0.2609 - val_accuracy: 0.9224\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.9303\n",
            "-----6---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.9214 - val_loss: 0.2606 - val_accuracy: 0.9283\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2275 - accuracy: 0.9370 - val_loss: 0.2435 - val_accuracy: 0.9297\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.2646 - accuracy: 0.9257 - val_loss: 0.2572 - val_accuracy: 0.9253\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2400 - accuracy: 0.9260 - val_loss: 0.2469 - val_accuracy: 0.9285\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.2592 - accuracy: 0.9213 - val_loss: 0.2499 - val_accuracy: 0.9269\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2210 - accuracy: 0.9340 - val_loss: 0.2582 - val_accuracy: 0.9257\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2176 - accuracy: 0.9497 - val_loss: 0.2527 - val_accuracy: 0.9287\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2009 - accuracy: 0.9411 - val_loss: 0.2589 - val_accuracy: 0.9270\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.2678 - accuracy: 0.9179 - val_loss: 0.2564 - val_accuracy: 0.9246\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2416 - accuracy: 0.9297 - val_loss: 0.2607 - val_accuracy: 0.9221\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2586 - accuracy: 0.9256 - val_loss: 0.2613 - val_accuracy: 0.9248\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.2355 - accuracy: 0.9349 - val_loss: 0.2527 - val_accuracy: 0.9278\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2586 - accuracy: 0.9290 - val_loss: 0.2524 - val_accuracy: 0.9256\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2423 - accuracy: 0.9290 - val_loss: 0.2650 - val_accuracy: 0.9262\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2355 - accuracy: 0.9248 - val_loss: 0.2540 - val_accuracy: 0.9289\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.2098 - accuracy: 0.9441 - val_loss: 0.2642 - val_accuracy: 0.9265\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.2460 - accuracy: 0.9267 - val_loss: 0.2511 - val_accuracy: 0.9266\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.2043 - accuracy: 0.9471 - val_loss: 0.2460 - val_accuracy: 0.9288\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.2285 - accuracy: 0.9318 - val_loss: 0.2535 - val_accuracy: 0.9249\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.2228 - accuracy: 0.9340 - val_loss: 0.2530 - val_accuracy: 0.9292\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2393 - accuracy: 0.9290 - val_loss: 0.2597 - val_accuracy: 0.9251\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1884 - accuracy: 0.9436 - val_loss: 0.2621 - val_accuracy: 0.9254\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1889 - accuracy: 0.9439 - val_loss: 0.2497 - val_accuracy: 0.9284\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1708 - accuracy: 0.9519 - val_loss: 0.2550 - val_accuracy: 0.9258\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.2582 - accuracy: 0.9213 - val_loss: 0.2629 - val_accuracy: 0.9252\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2018 - accuracy: 0.9358 - val_loss: 0.2516 - val_accuracy: 0.9287\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.2254 - accuracy: 0.9272 - val_loss: 0.2500 - val_accuracy: 0.9277\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.2158 - accuracy: 0.9341 - val_loss: 0.2443 - val_accuracy: 0.9299\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.3588 - accuracy: 0.9053 - val_loss: 0.2533 - val_accuracy: 0.9256\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2729 - accuracy: 0.9266 - val_loss: 0.2570 - val_accuracy: 0.9246\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 10ms/step - loss: 0.2607 - accuracy: 0.9221 - val_loss: 0.2599 - val_accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2390 - accuracy: 0.9295 - val_loss: 0.2504 - val_accuracy: 0.9292\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2231 - accuracy: 0.9332 - val_loss: 0.2544 - val_accuracy: 0.9274\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1989 - accuracy: 0.9405 - val_loss: 0.2515 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.2381 - accuracy: 0.9314 - val_loss: 0.2585 - val_accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.2320 - accuracy: 0.9376 - val_loss: 0.2659 - val_accuracy: 0.9206\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.3168 - accuracy: 0.9072 - val_loss: 0.2626 - val_accuracy: 0.9238\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 0.2661 - accuracy: 0.9133 - val_loss: 0.2574 - val_accuracy: 0.9257\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2799 - accuracy: 0.9124 - val_loss: 0.2509 - val_accuracy: 0.9270\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2200 - accuracy: 0.9321 - val_loss: 0.2558 - val_accuracy: 0.9246\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2586 - accuracy: 0.9113 - val_loss: 0.2500 - val_accuracy: 0.9281\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2391 - accuracy: 0.9324 - val_loss: 0.2482 - val_accuracy: 0.9285\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2568 - accuracy: 0.9236 - val_loss: 0.2538 - val_accuracy: 0.9264\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2243 - accuracy: 0.9349 - val_loss: 0.2495 - val_accuracy: 0.9293\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.2655 - accuracy: 0.9246 - val_loss: 0.2476 - val_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.2370 - accuracy: 0.9312 - val_loss: 0.2391 - val_accuracy: 0.9303\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2917 - accuracy: 0.9279 - val_loss: 0.2624 - val_accuracy: 0.9255\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2437 - accuracy: 0.9399 - val_loss: 0.2569 - val_accuracy: 0.9265\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2249 - accuracy: 0.9351 - val_loss: 0.2486 - val_accuracy: 0.9292\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2195 - accuracy: 0.9339 - val_loss: 0.2482 - val_accuracy: 0.9317\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2544 - accuracy: 0.9192 - val_loss: 0.2545 - val_accuracy: 0.9261\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2448 - accuracy: 0.9288 - val_loss: 0.2585 - val_accuracy: 0.9252\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.2562 - accuracy: 0.9204 - val_loss: 0.2495 - val_accuracy: 0.9289\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.2140 - accuracy: 0.9405 - val_loss: 0.2436 - val_accuracy: 0.9323\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.3154 - accuracy: 0.9069 - val_loss: 0.2485 - val_accuracy: 0.9284\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 0.2831 - accuracy: 0.9223 - val_loss: 0.2517 - val_accuracy: 0.9288\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2371 - accuracy: 0.9288 - val_loss: 0.2634 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.2053 - accuracy: 0.9444 - val_loss: 0.2653 - val_accuracy: 0.9217\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2117 - accuracy: 0.9409 - val_loss: 0.2567 - val_accuracy: 0.9245\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2009 - accuracy: 0.9466 - val_loss: 0.2349 - val_accuracy: 0.9324\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.9335\n",
            "-----7---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.2639 - accuracy: 0.9208 - val_loss: 0.2474 - val_accuracy: 0.9320\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2499 - accuracy: 0.9246 - val_loss: 0.2454 - val_accuracy: 0.9317\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.2317 - accuracy: 0.9314 - val_loss: 0.2438 - val_accuracy: 0.9294\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.2195 - accuracy: 0.9359 - val_loss: 0.2571 - val_accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2659 - accuracy: 0.9199 - val_loss: 0.2400 - val_accuracy: 0.9306\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2006 - accuracy: 0.9394 - val_loss: 0.2380 - val_accuracy: 0.9321\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1934 - accuracy: 0.9400 - val_loss: 0.2454 - val_accuracy: 0.9311\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.1669 - accuracy: 0.9533 - val_loss: 0.2522 - val_accuracy: 0.9249\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.2607 - accuracy: 0.9269 - val_loss: 0.2428 - val_accuracy: 0.9294\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2129 - accuracy: 0.9356 - val_loss: 0.2418 - val_accuracy: 0.9274\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2235 - accuracy: 0.9331 - val_loss: 0.2424 - val_accuracy: 0.9291\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2177 - accuracy: 0.9403 - val_loss: 0.2454 - val_accuracy: 0.9285\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2551 - accuracy: 0.9202 - val_loss: 0.2547 - val_accuracy: 0.9263\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2280 - accuracy: 0.9284 - val_loss: 0.2406 - val_accuracy: 0.9327\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2235 - accuracy: 0.9335 - val_loss: 0.2455 - val_accuracy: 0.9311\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.1977 - accuracy: 0.9476 - val_loss: 0.2417 - val_accuracy: 0.9320\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.2617 - accuracy: 0.9260 - val_loss: 0.2406 - val_accuracy: 0.9297\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9342 - val_loss: 0.2363 - val_accuracy: 0.9313\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.2663 - accuracy: 0.9235 - val_loss: 0.2569 - val_accuracy: 0.9247\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1967 - accuracy: 0.9481 - val_loss: 0.2569 - val_accuracy: 0.9245\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2202 - accuracy: 0.9310 - val_loss: 0.2409 - val_accuracy: 0.9301\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1764 - accuracy: 0.9511 - val_loss: 0.2454 - val_accuracy: 0.9271\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2130 - accuracy: 0.9321 - val_loss: 0.2382 - val_accuracy: 0.9317\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1501 - accuracy: 0.9547 - val_loss: 0.2383 - val_accuracy: 0.9307\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.2324 - accuracy: 0.9297 - val_loss: 0.2449 - val_accuracy: 0.9306\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2146 - accuracy: 0.9363 - val_loss: 0.2425 - val_accuracy: 0.9305\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.2199 - accuracy: 0.9279 - val_loss: 0.2370 - val_accuracy: 0.9330\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.1958 - accuracy: 0.9448 - val_loss: 0.2521 - val_accuracy: 0.9282\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 0.3281 - accuracy: 0.9051 - val_loss: 0.2537 - val_accuracy: 0.9222\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2307 - accuracy: 0.9315 - val_loss: 0.2478 - val_accuracy: 0.9289\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.2367 - accuracy: 0.9250 - val_loss: 0.2349 - val_accuracy: 0.9311\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2234 - accuracy: 0.9371 - val_loss: 0.2354 - val_accuracy: 0.9310\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1995 - accuracy: 0.9368 - val_loss: 0.2398 - val_accuracy: 0.9294\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1783 - accuracy: 0.9538 - val_loss: 0.2329 - val_accuracy: 0.9318\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.2225 - accuracy: 0.9381 - val_loss: 0.2397 - val_accuracy: 0.9298\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.1942 - accuracy: 0.9463 - val_loss: 0.2438 - val_accuracy: 0.9290\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.2624 - accuracy: 0.9294 - val_loss: 0.2503 - val_accuracy: 0.9278\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.2261 - accuracy: 0.9361 - val_loss: 0.2475 - val_accuracy: 0.9273\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2323 - accuracy: 0.9333 - val_loss: 0.2433 - val_accuracy: 0.9299\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2331 - accuracy: 0.9368 - val_loss: 0.2424 - val_accuracy: 0.9277\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2409 - accuracy: 0.9265 - val_loss: 0.2380 - val_accuracy: 0.9319\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2021 - accuracy: 0.9422 - val_loss: 0.2429 - val_accuracy: 0.9317\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.9218 - val_loss: 0.2464 - val_accuracy: 0.9270\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2023 - accuracy: 0.9350 - val_loss: 0.2373 - val_accuracy: 0.9310\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.2491 - accuracy: 0.9320 - val_loss: 0.2334 - val_accuracy: 0.9325\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 8ms/step - loss: 0.2105 - accuracy: 0.9402 - val_loss: 0.2263 - val_accuracy: 0.9366\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2804 - accuracy: 0.9201 - val_loss: 0.2483 - val_accuracy: 0.9289\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.2442 - accuracy: 0.9457 - val_loss: 0.2458 - val_accuracy: 0.9295\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.2213 - accuracy: 0.9319 - val_loss: 0.2456 - val_accuracy: 0.9323\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1863 - accuracy: 0.9494 - val_loss: 0.2368 - val_accuracy: 0.9344\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2739 - accuracy: 0.9232 - val_loss: 0.2405 - val_accuracy: 0.9315\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.2370 - accuracy: 0.9302 - val_loss: 0.2515 - val_accuracy: 0.9262\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2243 - accuracy: 0.9330 - val_loss: 0.2393 - val_accuracy: 0.9319\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2053 - accuracy: 0.9412 - val_loss: 0.2306 - val_accuracy: 0.9350\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.2743 - accuracy: 0.9179 - val_loss: 0.2412 - val_accuracy: 0.9312\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2320 - accuracy: 0.9303 - val_loss: 0.2455 - val_accuracy: 0.9263\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2190 - accuracy: 0.9398 - val_loss: 0.2499 - val_accuracy: 0.9258\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1821 - accuracy: 0.9533 - val_loss: 0.2435 - val_accuracy: 0.9292\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2132 - accuracy: 0.9415 - val_loss: 0.2416 - val_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1900 - accuracy: 0.9495 - val_loss: 0.2285 - val_accuracy: 0.9340\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2231 - accuracy: 0.9360\n",
            "-----8---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2438 - accuracy: 0.9300 - val_loss: 0.2356 - val_accuracy: 0.9332\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2067 - accuracy: 0.9422 - val_loss: 0.2287 - val_accuracy: 0.9354\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 2s 12ms/step - loss: 0.2365 - accuracy: 0.9311 - val_loss: 0.2291 - val_accuracy: 0.9338\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1893 - accuracy: 0.9500 - val_loss: 0.2402 - val_accuracy: 0.9304\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2335 - accuracy: 0.9345 - val_loss: 0.2407 - val_accuracy: 0.9290\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2067 - accuracy: 0.9365 - val_loss: 0.2302 - val_accuracy: 0.9317\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2218 - accuracy: 0.9368 - val_loss: 0.2336 - val_accuracy: 0.9344\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.1689 - accuracy: 0.9587 - val_loss: 0.2387 - val_accuracy: 0.9313\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.2285 - accuracy: 0.9341 - val_loss: 0.2366 - val_accuracy: 0.9310\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2366 - accuracy: 0.9332 - val_loss: 0.2268 - val_accuracy: 0.9325\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2289 - accuracy: 0.9314 - val_loss: 0.2323 - val_accuracy: 0.9328\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.2098 - accuracy: 0.9487 - val_loss: 0.2297 - val_accuracy: 0.9348\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2580 - accuracy: 0.9327 - val_loss: 0.2424 - val_accuracy: 0.9293\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2041 - accuracy: 0.9418 - val_loss: 0.2296 - val_accuracy: 0.9351\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2159 - accuracy: 0.9327 - val_loss: 0.2411 - val_accuracy: 0.9322\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.1645 - accuracy: 0.9567 - val_loss: 0.2359 - val_accuracy: 0.9346\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.2595 - accuracy: 0.9262 - val_loss: 0.2309 - val_accuracy: 0.9337\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.1948 - accuracy: 0.9499 - val_loss: 0.2325 - val_accuracy: 0.9291\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 14ms/step - loss: 0.2198 - accuracy: 0.9357 - val_loss: 0.2270 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.1756 - accuracy: 0.9494 - val_loss: 0.2380 - val_accuracy: 0.9308\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9434 - val_loss: 0.2357 - val_accuracy: 0.9318\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1540 - accuracy: 0.9562 - val_loss: 0.2420 - val_accuracy: 0.9290\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1753 - accuracy: 0.9481 - val_loss: 0.2282 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.1310 - accuracy: 0.9635 - val_loss: 0.2321 - val_accuracy: 0.9311\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 12ms/step - loss: 0.1973 - accuracy: 0.9417 - val_loss: 0.2255 - val_accuracy: 0.9354\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.1975 - accuracy: 0.9474 - val_loss: 0.2299 - val_accuracy: 0.9339\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.2274 - accuracy: 0.9298 - val_loss: 0.2270 - val_accuracy: 0.9356\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.1792 - accuracy: 0.9472 - val_loss: 0.2315 - val_accuracy: 0.9339\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 0.2693 - accuracy: 0.9188 - val_loss: 0.2307 - val_accuracy: 0.9326\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.2339 - accuracy: 0.9357 - val_loss: 0.2365 - val_accuracy: 0.9291\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 9ms/step - loss: 0.2457 - accuracy: 0.9278 - val_loss: 0.2296 - val_accuracy: 0.9315\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.2221 - accuracy: 0.9319 - val_loss: 0.2247 - val_accuracy: 0.9334\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.2173 - accuracy: 0.9299 - val_loss: 0.2296 - val_accuracy: 0.9338\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1741 - accuracy: 0.9488 - val_loss: 0.2350 - val_accuracy: 0.9306\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.2187 - accuracy: 0.9428 - val_loss: 0.2285 - val_accuracy: 0.9345\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.1903 - accuracy: 0.9453 - val_loss: 0.2330 - val_accuracy: 0.9321\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.3098 - accuracy: 0.9223 - val_loss: 0.2307 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.2456 - accuracy: 0.9320 - val_loss: 0.2362 - val_accuracy: 0.9306\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2094 - accuracy: 0.9408 - val_loss: 0.2290 - val_accuracy: 0.9335\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1807 - accuracy: 0.9444 - val_loss: 0.2312 - val_accuracy: 0.9331\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2416 - accuracy: 0.9285 - val_loss: 0.2229 - val_accuracy: 0.9387\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9394 - val_loss: 0.2307 - val_accuracy: 0.9330\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2366 - accuracy: 0.9350 - val_loss: 0.2385 - val_accuracy: 0.9291\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.2009 - accuracy: 0.9425 - val_loss: 0.2250 - val_accuracy: 0.9364\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 8ms/step - loss: 0.2529 - accuracy: 0.9327 - val_loss: 0.2264 - val_accuracy: 0.9339\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.2206 - accuracy: 0.9348 - val_loss: 0.2231 - val_accuracy: 0.9349\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2592 - accuracy: 0.9379 - val_loss: 0.2304 - val_accuracy: 0.9368\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2231 - accuracy: 0.9472 - val_loss: 0.2289 - val_accuracy: 0.9346\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2175 - accuracy: 0.9440 - val_loss: 0.2337 - val_accuracy: 0.9326\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.1797 - accuracy: 0.9525 - val_loss: 0.2255 - val_accuracy: 0.9367\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2903 - accuracy: 0.9162 - val_loss: 0.2308 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2232 - accuracy: 0.9361 - val_loss: 0.2476 - val_accuracy: 0.9274\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 0.2655 - accuracy: 0.9191 - val_loss: 0.2268 - val_accuracy: 0.9356\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2078 - accuracy: 0.9407 - val_loss: 0.2333 - val_accuracy: 0.9330\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 0.3095 - accuracy: 0.9054 - val_loss: 0.2279 - val_accuracy: 0.9321\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2544 - accuracy: 0.9282 - val_loss: 0.2271 - val_accuracy: 0.9363\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2028 - accuracy: 0.9455 - val_loss: 0.2368 - val_accuracy: 0.9333\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1769 - accuracy: 0.9561 - val_loss: 0.2386 - val_accuracy: 0.9309\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1958 - accuracy: 0.9444 - val_loss: 0.2260 - val_accuracy: 0.9365\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.1731 - accuracy: 0.9540 - val_loss: 0.2197 - val_accuracy: 0.9360\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9399\n",
            "-----9---------\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2303 - accuracy: 0.9341 - val_loss: 0.2260 - val_accuracy: 0.9367\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.2087 - accuracy: 0.9353 - val_loss: 0.2134 - val_accuracy: 0.9397\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.1952 - accuracy: 0.9429 - val_loss: 0.2318 - val_accuracy: 0.9331\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.1790 - accuracy: 0.9455 - val_loss: 0.2225 - val_accuracy: 0.9359\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 10ms/step - loss: 0.2159 - accuracy: 0.9361 - val_loss: 0.2189 - val_accuracy: 0.9378\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9450 - val_loss: 0.2267 - val_accuracy: 0.9321\n",
            "Epoch 1/2\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2117 - accuracy: 0.9312 - val_loss: 0.2236 - val_accuracy: 0.9334\n",
            "Epoch 2/2\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.1464 - accuracy: 0.9557 - val_loss: 0.2291 - val_accuracy: 0.9343\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.1991 - accuracy: 0.9414 - val_loss: 0.2310 - val_accuracy: 0.9329\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1996 - accuracy: 0.9414 - val_loss: 0.2198 - val_accuracy: 0.9340\n",
            "Epoch 1/2\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1889 - accuracy: 0.9489 - val_loss: 0.2222 - val_accuracy: 0.9356\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.1745 - accuracy: 0.9533 - val_loss: 0.2262 - val_accuracy: 0.9344\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2476 - accuracy: 0.9301 - val_loss: 0.2273 - val_accuracy: 0.9359\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2151 - accuracy: 0.9361 - val_loss: 0.2347 - val_accuracy: 0.9312\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.2075 - accuracy: 0.9318 - val_loss: 0.2274 - val_accuracy: 0.9358\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.1693 - accuracy: 0.9545 - val_loss: 0.2282 - val_accuracy: 0.9344\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 1s 11ms/step - loss: 0.2269 - accuracy: 0.9388 - val_loss: 0.2173 - val_accuracy: 0.9362\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 10ms/step - loss: 0.1830 - accuracy: 0.9534 - val_loss: 0.2237 - val_accuracy: 0.9345\n",
            "Epoch 1/2\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.2097 - accuracy: 0.9397 - val_loss: 0.2241 - val_accuracy: 0.9340\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1844 - accuracy: 0.9431 - val_loss: 0.2236 - val_accuracy: 0.9329\n",
            "Epoch 1/2\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2059 - accuracy: 0.9363 - val_loss: 0.2241 - val_accuracy: 0.9355\n",
            "Epoch 2/2\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1516 - accuracy: 0.9577 - val_loss: 0.2294 - val_accuracy: 0.9328\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1789 - accuracy: 0.9505 - val_loss: 0.2184 - val_accuracy: 0.9359\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.1349 - accuracy: 0.9566 - val_loss: 0.2200 - val_accuracy: 0.9346\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 1s 13ms/step - loss: 0.2028 - accuracy: 0.9386 - val_loss: 0.2190 - val_accuracy: 0.9375\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2020 - accuracy: 0.9471 - val_loss: 0.2253 - val_accuracy: 0.9360\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 1s 11ms/step - loss: 0.2043 - accuracy: 0.9381 - val_loss: 0.2245 - val_accuracy: 0.9362\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 9ms/step - loss: 0.1661 - accuracy: 0.9517 - val_loss: 0.2233 - val_accuracy: 0.9360\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 0.2446 - accuracy: 0.9295 - val_loss: 0.2208 - val_accuracy: 0.9350\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2252 - accuracy: 0.9356 - val_loss: 0.2226 - val_accuracy: 0.9345\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.2230 - accuracy: 0.9376 - val_loss: 0.2211 - val_accuracy: 0.9357\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9528 - val_loss: 0.2216 - val_accuracy: 0.9354\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1828 - accuracy: 0.9421 - val_loss: 0.2272 - val_accuracy: 0.9336\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1707 - accuracy: 0.9474 - val_loss: 0.2174 - val_accuracy: 0.9361\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 2s 14ms/step - loss: 0.2397 - accuracy: 0.9342 - val_loss: 0.2183 - val_accuracy: 0.9350\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.1778 - accuracy: 0.9517 - val_loss: 0.2232 - val_accuracy: 0.9340\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.2520 - accuracy: 0.9245 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 0.2284 - accuracy: 0.9373 - val_loss: 0.2268 - val_accuracy: 0.9344\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2406 - accuracy: 0.9300 - val_loss: 0.2264 - val_accuracy: 0.9333\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1720 - accuracy: 0.9515 - val_loss: 0.2258 - val_accuracy: 0.9356\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2051 - accuracy: 0.9363 - val_loss: 0.2247 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1740 - accuracy: 0.9503 - val_loss: 0.2158 - val_accuracy: 0.9384\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9355 - val_loss: 0.2207 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1906 - accuracy: 0.9425 - val_loss: 0.2353 - val_accuracy: 0.9304\n",
            "Epoch 1/2\n",
            "143/143 [==============================] - 2s 9ms/step - loss: 0.2355 - accuracy: 0.9410 - val_loss: 0.2109 - val_accuracy: 0.9401\n",
            "Epoch 2/2\n",
            "143/143 [==============================] - 1s 7ms/step - loss: 0.2036 - accuracy: 0.9403 - val_loss: 0.2109 - val_accuracy: 0.9397\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2538 - accuracy: 0.9237 - val_loss: 0.2288 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2068 - accuracy: 0.9421 - val_loss: 0.2299 - val_accuracy: 0.9316\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2103 - accuracy: 0.9378 - val_loss: 0.2320 - val_accuracy: 0.9358\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1903 - accuracy: 0.9481 - val_loss: 0.2113 - val_accuracy: 0.9412\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.2407 - accuracy: 0.9301 - val_loss: 0.2292 - val_accuracy: 0.9320\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.2019 - accuracy: 0.9401 - val_loss: 0.2339 - val_accuracy: 0.9327\n",
            "Epoch 1/2\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.2291 - accuracy: 0.9326 - val_loss: 0.2287 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9480 - val_loss: 0.2235 - val_accuracy: 0.9362\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 0.2326 - accuracy: 0.9239 - val_loss: 0.2194 - val_accuracy: 0.9388\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 0.2491 - accuracy: 0.9331 - val_loss: 0.2198 - val_accuracy: 0.9366\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1855 - accuracy: 0.9429 - val_loss: 0.2261 - val_accuracy: 0.9359\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.1651 - accuracy: 0.9583 - val_loss: 0.2270 - val_accuracy: 0.9357\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.2072 - accuracy: 0.9432 - val_loss: 0.2273 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.1578 - accuracy: 0.9574 - val_loss: 0.2186 - val_accuracy: 0.9377\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "GNc8SzlO8eoB",
        "outputId": "f9698f4f-36b3-44a0-f1c3-9bb592b2b0c9"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(serverhist1['accuracy'], label=\"genetic loss\", color=\"#061080\")\n",
        "ax.plot(serverhist['accuracy'], label=\"loss\", color=\"#068006\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(serverhist1['loss'], label=\"genetic accuracy\", color=\"#061080\")\n",
        "ax.plot(serverhist['loss'], label=\"accuracy\", color=\"#068006\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Generic FL.png\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEYCAYAAABRMYxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxNd/7H8dcnm4gk1BYkQeyCKIklFEGVqn1pabXUtHTRaaej229mdJ8uOp2u044pVUUXiqoqpri0FSUhQmKpPRtiF5H9+/vjXplQS5Cbk5t8no9HHjnL95z7TsjNJ99zzvcrxhiUUkoppcoTN6sDKKWUUkqVNC1wlFJKKVXuaIGjlFJKqXJHCxyllFJKlTta4CillFKq3PGwOsC1qlmzpmnYsGGx2p49e5YqVao4N5ATuGpu0OxWKSvZY2Njjxpjalmdo6QV932nrPw7XA/Nbg3NfuMu977jcgVOw4YNiYmJKVZbm81GVFSUcwM5gavmBs1ulbKSXUQOWJ3BGYr7vlNW/h2uh2a3hma/cZd739FLVEoppZQqd7TAUUoppVS5owWOUsrliEg/EdkpIrtF5NlL7G8gIitFJF5EbCISVGTfmyKSICLbReQ9EZHSTa+UKg0udw+OUufl5uaSnJxMVlZWiZyvatWqbN++vUTOVdpKO7u3tzdBQUF4enqW2mueJyLuwIdAHyAZ2Cgii40xiUWavQXMMsZ8JiK9gNeAe0WkC9AVCHO0+xnoAdhKK79SqnRogaNcVnJyMn5+fjRs2JCS+CP8zJkz+Pn5lUCy0lea2Y0xHDt2jOTkZEJCQkrlNS/SEdhtjNkLICJfAoOBogVOKPCkY3k1sMixbABvwAsQwBM4XAqZlVKlTAsc5bKysrJKrLhRxSci1KhRg/T0dKsiBAJJRdaTgU4XtdkCDAPeBYYCfiJSwxgTLSKrgTTsBc4HxphLdn2JyARgAkBAQAA2m+2qwTIyMorVrizS7NbQ7M6jBY5yaVrcWMMFvu+TgQ9EZBywFkgB8kWkCdASOH9Pzn9FpJsx5qeLT2CMmQZMA4iIiDDFeRy2rDw2ez00uzU0u/NogaOUcjUpQHCR9SDHtkLGmFTsPTiIiC8w3BhzUkQeBNYbYzIc+34AIoHfFThKKddWLgucAycPMGXVFLp4dCGKKKvjKHXdTp48ydy5c3nkkUcASE1N5Y9//CPz588v1vHjxo1jwIABjBgxwpkxS9tGoKmIhGAvbEYBdxdtICI1gePGmALgOWCGY9dB4EEReQ37JaoewDulFVxVPMYYjp84x5EjZzl0JIPDhzM4nG7/nH40k7S0NBYsOYtPZU+qVPHCx8ezcLmKjyeViyz7VPbEx7FcxceLypU9SqQ3NS+vgHPncjmXlUdWVh7nsnLJzsqzr2fnce5cLtnZeZw7Z9+XlZVHdk4+R9MP4+a5n+CgqgTW9cfLy70EvmMlp1wWOFW8qvDl1i/xCfGxOopSN+TkyZP861//Kixw6tWrV+ziprwyxuSJyCRgOeAOzDDGJIjIS0CMMWYxEAW8JiIG+yWqRx2Hzwd6AVux33C8zBjzXWl/Dcq1GWM4fTrbXrAcySgsXo441g8fOev4nMGR9LPk5hb87hyenm4E1PIlJzebzfFnOJuZw7lzedecxcfH83fFj09lT3x8vPDycicrK4+srCsXL/n55rq/F1Pf3QGACNSt40dwUFX7R6A/wcH25fqObdVvqlyql7fLZYFT06cmzWo0I/F04tUbK3UDXn75ZWbPnk2tWrUIDg4mPDycyZMns2fPHh599FHS09Px8fHhP//5Dy1atGDcuHH4+/sTExPDoUOHePPNNwt7V6ZOncrXX39NdnY2Q4cO5cUXX+TZZ59lz5493HzzzfTp04dHH32UAQMGsG3bNvLz83nmmWdYtmwZABMnTuSxxx67bNaVK1cyefJk8vLy6NChAx999BGVKlXi2WefZfHixXh4eHDbbbfx1ltvMW/ePF588UXc3d2pWrUqa9euLZXvZ3EZY5YCSy/aNqXI8nzsxczFx+UDE50eULm8lNTTxGxKIX7bYdIOnSksWo4cyeDQkQyys/N/d4y7u1C7VhUCavtSu5YvrUMDCKhdhdq1falT25fate376gT4Uq2qNyJywX0sBQWGzMxcMs/lcjYzh8yzjs/ncjl7NpfMzBzOZuba25xfPpfL2bM5ZGbmXrDv8JEMcnPz8fb2oLK3J1WrelMnwAPvSh5UruyJt7eHY5+HY9mzcLmyd5H9lT3tx3h7UKnIPi8vd5YsWUXdwBYkJZ8q/DiYfIq4+DS+W7rjd98jHx/PwgKofpD//4qhoKrUD65GYF0/KlUqubKkXBY4AF2Cu7Bg2wKMMa5wQ6S6QX9+bhnxWw/d0Dny8vPxcP9fF2tYmzr847V+l22/ceNGvvnmG7Zs2UJubi7t27cnPDwcgAkTJvDxxx/TtGlTfv31Vx555BFWrVoFQFpaGj///DM7duxg0KBBjBgxghUrVvDbb7+xYcMGjDEMGjSItWvX8vrrr7Nt2zbi4uIA2L9/f+HrT5s2jf379xMXF8e5c+fIzc29bNasrCzGjRvHypUradasGffddx8fffQR9957LwsXLmTHjh2ICCdPngTgpZdeYvny5QQGBhZuU6q8OnHyHLGbU4mJTSFmcyoxm1JIO5QB2HsmatWsYi9cAnxp1qRG4XJALV8CAv5XvNSo7oOb2/X/vnFzE3x9vfD19QKsn8TyaoICfYiKanTJfcYY0o9mXlD4FC2Etm47xOEjZy84RgTqBPgSHFSVdm3r8t5bd9xQvnJb4HQO7szMuJnsOraL5jWbWx1HlUO//PILgwcPxtvbG29vbwYOHAjYH51ct24dI0eOLGybnZ1duDxkyBDc3NwIDQ3l8GH7ECwrVqxgxYoVtGvXrvAcv/32G/Xr17/s6//444889NBDeHjYf4yrV69+2bY7d+4kJCSEZs2aATB27Fg+/PBDJk2ahLe3N3/4wx8YMGAAAwYMAKBr166MGzeOO++8k2HDhl3Pt0epMuncuVy2bD3Exk0pxG5KZeOmFHbvOV64v1nTGvTs3oiI8HpEtAukbZs6eHuX21+VTiNi782qXasK4e3qXbJNVlYeyamnLyh8zhdDp05lX/KYa1Fu/9Ui60cCEJ0UrQVOBXClnpbiKqnB8goKCqhWrVphr8vFKlWqVLhsjCn8/NxzzzFx4oVXT4r22DiDh4cHGzZsYOXKlcyfP58PPviAVatW8fHHH/Prr7/y/fffEx4eTmxsLDVq1HBqFqVKWl5eAdt3pBOzOYWNsSnEbk5lW+IR8vLs98QE1vMjvF0gY+++mYjwQNrfXI9qVb0tTl1xeHt70KRRdZo0uvwfZzei3BY4zWo0w8/Dj/VJ6xnXbpzVcVQ51LVrVyZOnMhzzz1HXl4eS5YsYcKECfj7+xMSEsK8efMYOXIkxhji4+Np27btZc/Vt29f/va3v3HPPffg6+tLSkoKnp6e+Pn5cebMmUse06dPH/7973/Ts2dPAI4fP37ZXpzmzZuzf/9+du/eTZMmTfj888/p0aMHGRkZZGZm0r9/f7p27UqjRvbu5j179tCpUyc6derEDz/8QFJSkhY4qkwzxrDvwEliN6UU9s5s2pJGZqb90m21qt6Et6/Hn//YhYjwQCLaBVKvrmuOXK6Kp9wWOG7iRqh/KOuS1lkdRZVTHTp0YNCgQYSFhREQEECbNm2oWrUqAHPmzOHhhx/mlVdeITc3l1GjRl2xwLntttvYvn07kZH2nkdfX19mz55N48aN6dq1K61bt+b222/n0UcfLTzmgQceYNeuXYSFheHu7s7EiROZNGnSJc/v7e3Np59+ysiRIwtvMn7ooYc4fvw4gwcPJisrC2MMb7/9NgBPPfUUv/32G8YYevfufcXsSpW23Nx8ftt9jG2JR9iWeJiVqxPYd2ADx46fA6BSJXfahdVl/H3tiWhXj4jwQBqHVL+h+2OU6ym3BQ5Aq6qtmLFvBscyj1HDR//6VCVv8uTJvPDCC2RmZtK9e/fCm4xDQkIKn24qaubMmResZ2RkFC4//vjjPP744787Zu7cuResb9u2DbBfXnr77bd5++23L3t5rejr9e7dm82bN1+wv27dumzYsOF3xy1YsOB325QqbcYYklNOsy3xCAmJhx0FzRF2/naUnBz7Ezru7kL9IB8G3dGC8Hb16BAeSKuWtfH0LFtjsqjSV64LnFD/UADWJ6/njmY3dje2UpcyYcIEEhMTycrKYuzYsbRv397qSEq5pFOnsgp7ZOwFzRESth/h5KmswjZB9fxpFVqb23o3pnVoAK1Da9O8WU2io38u01MGKGuU6wKnmV8zPNw8iD4YrQWOcoqLe1eUUleWk5PPzl1HCwuZ870zSSmnC9v4+1WidWhtRg5rVVjItAqtzU3VKluYXLmacl3gVHKvRLu67VifvN7qKEopVeHk5RUQuzmVn37Zz5ath9mWeJhdu48VPsXk6elG86Y16RrZoLCIaR0aQHCQv45fpm6YUwscEekHvIt9OPVPjDGvX6LNncAL2IdN32KMufviNjciMjiSaTHTyMnPwcvdqyRPrZRSqoiCAkNC4hFWrd2Lbe1+flq3nzNncgBoEFyVVqEBDLi9Oa0dhUzTJjXK3PxFqvxwWoEjIu7Ah0AfIBnYKCKLjTGJRdo0xT4RXldjzAkRqV3SOSKDI3lv/XtsObSFDoEdSvr0SilVYRlj2LPvBKvX7MX2037W/LSP9KOZADRpXJ27hrehZ/cQenRrSK2aZX9kXlW+OLMHpyOw2xizF0BEvgQGA0UniHoQ+NAYcwLAGHOkpEN0Du4MwLqD67TAUUqpG5SSehrb2n3YftrP6jV7C++dqVfXj9t6N6FnjxB63BJC/eCqFidVFZ0zC5xAIKnIejLQ6aI2zQBE5Bfsl7FeMMb8/tnaG1DPrx4NqjVgffJ6Huf3j+AqdSN8fX0veNRbqfLm+IlzrPlpH6vX2j92/XYMgOo3VaZHt4Y89adbiOoeQrMmNfS+GVWmWH2TsQfQFIgCgoC1ItLGGHPB7H4iMgGYABAQEIDNZivWyTMyMrDZbDT2aoxtt43Vq1e7xA/g+dyuqDSzV61a9bKj/F6P/Pz86zpfSWa4Xteb/UZkZWW57P9TdXkZGTn8HH0Am6Og2bL1EMZAlSqedOvSkPH3tadn9xDCWtfRgfNUmebMAicFCC6yHuTYVlQy8KsxJhfYJyK7sBc8G4s2MsZMA6YBREREmOKOd3B+GvodVXawaukqQtqF0LBaw+v5WkrV+dyuqDSzb9++vUTmjjrveuei8vPzwxjD008/zQ8//ICI8Ne//pW77rqLtLQ07rrrLk6fPk1eXh4fffQRXbp04Q9/+AMxMTGICOPHj+dPf/qTJdlvhLe3d+HkoMq17dl3nFlf7OfF12ewITaFvLwCvLzciewYzJTnouyTT7avp4PnKZfizAJnI9BUREKwFzajgIufkFoEjAY+FZGa2C9Z7S3pIF2CuwAQfTDaJQocde3+vOzPxB+Kv6Fz5OXn4eH+vx+JsDph/KPfP4p17IIFC4iLi2PLli0cPXqUDh060L17d+bOnUvfvn35y1/+Qn5+PpmZmcTFxZGSklI4IvHJkyevcnalnOP06Wxe/8da3vtoPfn5BYS3C+RPkyLp2aMRkR2D8fHxtDqiUtfNaQWOMSZPRCYBy7HfXzPDGJMgIi8BMcaYxY59t4lIIpAPPGWMOVbSWVrVboWflx/RSdGMDhtd0qdXip9//pnRo0fj7u5OQEAAPXr0YOPGjXTo0IHx48eTm5vLkCFDuPnmm2nUqBF79+7lscce44477uC2226zOr6qYAoKDLPmxjHl5ZUcPnKW++6+mX69vRk+rK/V0ZQqMU69B8cYsxRYetG2KUWWDfCk48Np3N3c6RjUkeikaGe+jLJQcXtarsQZl3m6d+/O2rVr+f777xk3bhxPPvkk9913H1u2bGH58uV8/PHHfP3118yYMaNEX1epy1m3/iB/fm4Zm+LS6NQhiAVfjCaifaDeT6XKHTerA5SWLsFd2HZkG6ezT1+9sVLXqFu3bnz11Vfk5+eTnp7O2rVr6dixIwcOHCAgIIAHH3yQBx54gE2bNnH06FEKCgoYPnw4r7zyCps2bbI6vqoAkpJPcd8D39Dz9k85dDiDmf8eyprl44loH2h1NKWcwuqnqEpN5+DOFJgCNiRv4NbGt1odR5UzQ4cOJTo6mrZt2yIivPnmm9SpU4fPPvuMqVOn4unpia+vL7NmzSIlJYX777+fggL7cPWvvfaaxelVeZaZmcs/P1jH1Hd+pqDA8Nzkbkx+/BZ8fXVkd1W+VZgCp2NQR9zEjeikaC1wVIk5PwaOiDB16lSmTp16wf6xY8cyduzY3x2nvTbK2YwxfLMokeem/JeDyacYPiSUv7/Yh4b1q1kdTalSUWEKHP9K/rSu3Vrvw1FKlXtx8Wn8+dll/Bx9kLDWAUz/eAjduza0OpZSparCFDhgn5dqbvxc8gvycXfT8RyUUuXLkfSzPP/qKj6dtYka1X348J8DuP/edri7V5jbLZUqVKH+10cGR3Im5wwJRxKsjqJKiP1BPFXa9PtetuTk5PPOh9G0Cn+fWXPieOzhziTEPsYD48K1uFEVVsXqwakfCcC6pHWE1QmzOI26Ud7e3hw7dowaNXQOnNJkjOHYsWN4e3tbHUUBP6z4jaf+spzfdh+j761NePPVvrRoVtPqWEpZrkIVOA2qNqCub13WJ63noQ4PWR1H3aCgoCCSk5NJT08vkfNlZWW57C/t0s7u7e1NUFBQqb2e+r0du47y1P8tZ8XK3TRtUoNFX93N7bc1tTqWUmVGhSpwRITI+pGsS1pndRRVAjw9PQkJCSmx89lsNpedW8mVs6trc/JUFq+8YeOj/2zEp7Inb756Gw8/0BEvL72vUKmiKlSBA9A5qDMLEheQeiaVen71rI6jlFLFkp9fwIxZm3jh1dUcO57J+Pva88JfelG7VhWroylVJlW4AqdLffvEm+uT1jMsdJjFaZRS6uqOHstkyF1z2RibQrcuDfjH6/1o26aO1bGUKtMq3O31beu0xdvDm3UH9TKVUqrsO3Y8k9uHzGJrwmE+mzaM/y4Zq8WNUsVQ4QocL3cvOgR2YH3yequjKKWuk4j0E5GdIrJbRJ69xP4GIrJSROJFxCYiQUX21ReRFSKyXUQSRaRhaWa/Fvbi5nN2/naU+XNGMWpkG31iUKliqnAFDtjHw9mctpnM3EyroyilrpGIuAMfArcDocBoEQm9qNlbwCxjTBjwElB0wq9ZwFRjTEugI3DE+amv3fET5+g/9HN27Ernm7mj6dOrsdWRlHIpFbLA6RzcmbyCPGJTY62OopS6dh2B3caYvcaYHOBLYPBFbUKBVY7l1ef3OwohD2PMfwGMMRnGmDL3l87xE+e4fcgstu9MZ/6cUVrcKHUdKtxNxmB/kgog+mA03Rp0sziNUuoaBQJJRdaTgU4XtdkCDAPeBYYCfiJSA2gGnBSRBUAI8CPwrDEm/+IXEZEJwASAgIAAbDbbVYNlZGQUq92VnD6Ty3MvxHPg4Fmef641Xu7J2GzJN3TO4iiJ7FbR7NYo69krZIFTw6cGzWs2JzpZJ95UqpyaDHwgIuOAtUAKkI/9Pa8b0A44CHwFjAOmX3wCY8w0YBpARESEiYqKuuqL2mw2itPuck6cPMftQz7nYPI55s8dTb8+pTdw341mt5Jmt0ZZz14hL1EBdAnuwvqk9RSYAqujKKWuTQoQXGQ9yLGtkDEm1RgzzBjTDviLY9tJ7L09cY7LW3nAIqB96cS+shMn7ffcJGw/wtef31WqxY1S5VGFLXA6B3fm+Lnj7Dq2y+ooSqlrsxFoKiIhIuIFjAIWF20gIjVF5Pz723PAjCLHVhORWo71XkBiKWS+opOnsrhj2Gy2JR7hq1l36pQLSpWAClvgRAbbJ96MPqiXqZRyJY6el0nAcmA78LUxJkFEXhKRQY5mUcBOEdkFBACvOo7Nx375aqWIbAUE+E8pfwkXsBc3nxO/7RBffnYn/fs2szKOUuVGhbwHB6BZjWbUqFyD9Unrub/9/VbHUUpdA2PMUmDpRdumFFmeD8y/zLH/BcKcGrCYTp3KYsDw2WzZai9u7uinxY1SJaXC9uCICJ2DO+vEm0opS5w6lcUdw2cTF5/GFzPvZMDtza2OpFS5UmELHLBfptp1bBdHM49aHUUpVYGcOpXFgBH24mbuzJEM7K/FjVIlrcIXOGCfeFMppUrD6dPZDBw5h01x9uJmUP8WVkdSqlyq0AVOeL1wPN08iU7SG42VUs53+nQ2A0fMJnZzqhY3SjlZhS5wKntWpl3ddtqDo5RyujNnshk0cg4xm1OZ++kIBt+hxY1SzlShCxywX6aKSY0hJz/H6ihKqXLqzJlsBo6Yw4bYZObMGMHgAS2tjqRUuacFTnAkWXlZxKXFWR1FKVUOne+5OV/cDBmoxY1SpaHCFzidg+0Tb+rj4kqpknbmTDaD75zLrzHJzJ4+gqGDQq2OpFSFUeELnLp+dWlYraHeh6OUKlEZGTkMvnMu6zcm8fknwxk2WIsbpUpThS9wALrU70J0UjTGGKujKKXKAXtxM4f1G5OY9Z/hDB/SyupISlU4Ti1wRKSfiOwUkd0i8uwl9o8TkXQRiXN8PODMPJfTOagzhzIOsf/kfiteXilVjpw9m8OQu+YSvSGJz6YNY8RQLW6UsoLTChwRcQc+BG4HQoHRInKpPtqvjDE3Oz4+cVaeK+lSvwuAjoejlLohWVn5DLlrLr+sP8jMfw9j5LDWVkdSqsJyZg9OR2C3MWavMSYH+BIY7MTXu26htULxr+SvBY5S6rqdPZvD317dys/RB5n576HcOVyLG6Ws5MzZxAOBpCLryUCnS7QbLiLdgV3An4wxSRc3EJEJwASAgIAAbDZbsQJkZGQUu21Tn6b8d/t/sVUpXntnupbcZY1mt4YrZy8v5n4dz7bEU3z68TDuGtHG6jhKVXjOLHCK4zvgC2NMtohMBD4Del3cyBgzDZgGEBERYaKioop1cpvNRnHb9qc/r6x5hXad21HVu2rx0jvJteQuazS7NVw5e3nxwLhwKEhj1EgtbpQqC5x5iSoFCC6yHuTYVsgYc8wYk+1Y/QQId2KeK4qsH4nBsCFlg1URlFIuTERo2tjP6hhKKQdnFjgbgaYiEiIiXsAoYHHRBiJSt8jqIGC7E/NcUcfAjriJG9EH9T4cpZRSytU57RKVMSZPRCYBywF3YIYxJkFEXgJijDGLgT+KyCAgDzgOjHNWnqvxq+RHm4A2RCdrgaOUUkq5Oqfeg2OMWQosvWjblCLLzwHPOTPDtYgMjmT2ltnkFeTh4Wb17UlKKaWUul46knERkcGRZORkkHAkweooSimllLoBWuAUERkcCcC6gzrxplJKKeXKtMApon7V+tTzq8f6ZJ14UymllHJlWuAUISJEBkfqk1RKKaWUi9MC5yKdgztz4NQBUk6nXL2xUkoppcokLXAu0iXYPvHm+iS9TKWUUkq5Ki1wLtK2Tlsqe1RmXZLeaKyUUkq5Ki1wLuLp7kmHwA7ag6OUUkq5MC1wLiEyOJK4Q3Fk5mZaHUUppZRS10GH672EzsGdySvIIyYlhu4Nu1sdRymllCr3MnIy2HZ4G/GH4zHGMLHDxBs6nxY4l9A5uDMA0UnRWuAopZRSJcgYQ9LpJOIPxbP18FbiD8cTfyiePcf3YDAAtK7dWgscZ6heuTotarYgOknHw1GqLBKRfsC72Cfy/cQY8/pF+xsAM4Ba2CfyHWOMSS6y3x9IBBYZYyaVWnClKpjsvGwS0xOJPxRP/GFHQXMonhNZJwrbNLqpEWF1wrg77G7aBLQhrE4YDao2uOHX1gLnMroEd2Hh9oUUmALcRG9VUqqsEBF34EOgD5AMbBSRxcaYxCLN3gJmGWM+E5FewGvAvUX2vwysLa3MSlUEhzMOF/bGnO+Z2ZG+g3yTD4CPpw+ta7dmWOgwwuqEERYQRuuA1vhX8ndKHi1wLqNzcGdmbJ7BzqM7aVmrpdVxlFL/0xHYbYzZCyAiXwKDsffInBcKPOlYXg0sOr9DRMKBAGAZEFEagZUqT4wx7Dq2i1WHV7HivysKi5rDZw8XtgnyD6JNQBsGNBtgL2bqhNH4psa4u7mXWk4tcC4jsr594s3opGgtcJQqWwKBpCLryUCni9psAYZhv4w1FPATkRrACeAfwBjg1iu9iIhMACYABAQEYLPZrhosIyOjWO3KIs1uDVfJboxhT8Yefjr6Ez+n/0zyOfsVX0/xpH6V+oT5htGoTiMaVWlEI99G+HsW6ZVJh9T0VFJJLdXMWuBcRtPqTanpU5P1SesZ33681XGUUtdmMvCBiIzDfikqBcgHHgGWGmOSReSKJzDGTAOmAURERJioqKirvqjNZqM47coizW6NspzdGMPGlI0s3L6QBYkL2H9yP+7iTveG3Xm65dN4HfZizO1j8HT3tDrqJWmBcxkiQufgzjqisVJlTwoQXGQ9yLGtkDEmFXsPDiLiCww3xpwUkUigm4g8AvgCXiKSYYx5tnSiK1W2FZgCopOiWZi4kEXbF5F0OglPN096NurJs92eZWCLgdT0qQnYi7OyWtyAFjhXFBkUyZKdS0g/m06tKrWsjqOUstsINBWREOyFzSjg7qINRKQmcNwYUwA8h/2JKowx9xRpMw6I0OJGVXR5BXn8fOBnFiQuYPGOxaRlpFHJvRK3Nr6VF3q9wB3N7uCmyjdZHfOaaYFzBefvw1mfvJ6BzQdanEYpBWCMyRORScBy7I+JzzDGJIjIS0CMMWYxEAW8JiIG+yWqRy0LrFQZlJufi22/jQWJC/hux3ekZ6ZT2aMy/Zr2Y2jLodze7HanPd1UWrTAuYL2ddvj6eZJ9MFoLXCUKkOMMUuBpRdtm1JkeT4w/yrnmAnMdEI8pcqk7Lxsftz7I4u2L+K7Hd9xIusEvl6+9G/Wn6Eth9K3SV+qeFWxOmaJ0QLnCip7VqZ9vfasT9aJN5VSSrmec7nnWLF7BQu2L2DprqWczj5N1UpVGdB8AENDhzFRpTIAACAASURBVNKncR+8PbytjukUWuBcRWRwJB9t+IjsvGwqeVSyOo5SSil1Wbn5uSQcSWBjykZW71vNst+WcTb3LNUrV2dYy2EMDR1Kr0a98HL3sjqq02mBcxWRwZG8E/0OcYfi6BR08VAbSimllDWMMew+vpuYlBhiUmOISYkh7lAcWXlZAARUCWB02GiGhQ6je4PuZfqJJ2fQAucqzk+8ue7gOi1wlFJKWSbtTBobUzYSmxpb+Plk1knAPg1Cu7rtmBgxkYjACCICIwipFsLVxnsqz7TAuYo6vnUIuSlE78NRSilVak5lnSI2NbawmIlJiSHljH24J3dxp3VAa4aHDiciMIIOgR1oWaslHm76K70o/W4UQ5fgLvy450eMMRW6GlZKKVXysvKyiD8UX3iZKSY1hp1Hdxbub1y9Md0adiOinr1npm2dtvh4+liY2DVogVMMnYM7Myd+DvtO7qPRTY2sjqOUUsqFnco6xZr9a1i9bzU/bv+RfT/tI7cgF7BfNYgIjODuNncTHhhOeL1wqleubnFi16QFTjF0Ce4CQPTBaC1wlCpBIjIQ+N4x4rBS5VJufi4bUjawcs9KVu5dycaUjeSbfHw8fWhWpRlPRD5ReN9MoF+gXikoIVrgFEPLWi3xr+RPdFI097S95+oHKKWK6y7gHRH5BvuIxDusDqTUjTLGsOPoDn7c8yOr9q1i7f61ZORk4CZuRNSL4OlbnqZXo172+Q5/WldmJ9t0dVrgFIO7mzudgjoRnRRtdRSlyhVjzBgR8QdGAzMdUyt8CnxhjDljbTqlii/tTBqr9q5i1b5VrNq7itQzqQA0qd6Ee8LuoXej3vQI6UE172oWJ604tMAppsjgSF62vczJrJP6H1SpEmSMOS0i84HKwBPAUOApEXnPGPO+temUurSMnAx+OvBT4WWnxPREAGr61KRnSE96N+pNr0a9aFCtgcVJKy6nFjgi0g94F/uEeJ8YY16/TLvh2OeN6WCMiXFmpusVGRyJwbAheQO3NbnN6jhKlQsiMgi4H2gCzAI6GmOOiIgPkAhogaPKhLyCPGJTY1m5ZyWr9q1ifdJ6cgty8fbwpmv9rtzT9h5ubXQrYXXCcBM3q+MqnFjgiIg78CHQB0gGNorIYmNM4kXt/IDHgV+dlaUkdAzqiJu4EZ0UrQWOUiVnOPBPY8zaohuNMZki8geLMikFQPrZdL5J/IaVe1eyZt8aTmWfQhBurnszj0c+Tu9GvelSv0u5ncvJ1TmzB6cjsNsYsxdARL4EBmP/q6yol4E3gKecmOWG+Xr5EhYQpvfhKFWyXgDSzq+ISGUgwBiz3xiz0rJUqsIqMAWs3LuSGZtm8N2O78gtyKVBtQYMbzWc3o16ExUSRU2fmlbHVMXgzAInEEgqsp4MXDDXgYi0B4KNMd+LyGULHBGZAEwACAgIwGazFStARkZGsdsWR323+qw4sIKVq1fiLu4ldt6LlXTu0qTZreHC2ecBXYqs5zu2dbAmjqqoUk6n8Nnmz5i5eSYHTh2gRuUaPNzxYe5vdz8ta7XUR7ddkGU3GYuIG/A2MO5qbY0x04BpABEREaa4j9TZbLYSffzucI3DLF6wmBotanBz3ZtL7LwXK+ncpUmzW8OFs3sYY3LOrxhjckSk/E9zrMqEvII8fvjtB2ZsmsGy35ZRYAroGdKTV299lUEtBlHJo5LVEdUNcGaBkwIEF1kPcmw7zw9oDdgclXEdYLGIDCqzNxrXjwRgXdI6pxY4SlUg6Y6f+cUAIjIYOGpxJlXO7T2xl5mbZjIrbhZpGWnU9a3LU12fYmy7sTSu3tjqeKqEOLPA2Qg0FZEQ7IXNKODu8zuNMaeAwguZImIDJpfV4gYg2D+YQL9A1iet55GOj1gdR6ny4CFgjoh8AAj2y9r3WRtJlUfZedks3rGYGZtnsGrvKtzEjb5N+vJe+/fo36y/TlRZDjntX9QYkycik4Dl2B8Tn2GMSRCRl4CY83+xuRIRIbJ+pN5orFQJMcbsATqLiK9jPcPiSKqc2Z6+nU83fcqc+DkczTxKg6oNeD7qee5rdx9B/kFWx1NOVKwCR0SqAOeMMQUi0gxoAfxgjMm90nHGmKXA0ou2TblM26hiJbZY56DOzE+YT/LpZP3hUKoEiMgdQCvA+/yNnMaYlywNpVxaZm4m3yR8w4xNM1iXtA4PNw8GtRjE+Pbj6d2ot45TU0EUtwdnLdBNRG4CVmC//HQXUOEmZupS3/7Ax/qk9YxoNcLiNEq5NhH5GPABegKfACOADZaGUi4rLi2OGZtm8OXWLzmVfYqmNZry91v/zr0330vtKrWtjqdKWXELHCky8Na/jDFvikicM4OVVWEBYfh4+rDu4DotcJS6cV2MMWEiEm+MeVFE/gH8YHUo5TpOZZ3i+9TveW7ac2xK24S3hzfDQocxvv14bql/iz7eXYEVu8ARkUjsPTbnRxd13kAwZZinuyeRwZF8ufVLHur4EM1qNLM6klKuLMvxOVNE6gHHgLoW5lEu4Pi54yzZuYSF2xfy454fycnPoU1AG/55+z8Z3WY0N1W+yeqIqgwoboHzBPAcsNBxo3AjYLXzYpVt793xHlHToxgwewBrxq+hrp++Hyt1nb4TkWrAVGATYID/WBtJlUXpZ9NZvGMxC7YvwLbPRl5BHg2qNuDhDg/TOLsxEwZO0N4adYFiFTjGmDXAGigcoO+oMeaPzgxWljWp3oRv7/mWPjP7MGjOIH4c9yNVvataHUspl+J4L1lpjDkJfCMiSwBvxxASSpF2Jo1vd3zLwsSFrD2wlgJTQKObGvFE5BMMCx1G+7rtERFsNpsWN+p3ivsU1Vzs41XkY7/B2F9E3jXGTHVmuLIsvF44X931FUPmDmHkVyNZfM9inXBNqWvgeCrzQ6CdYz0byLY2lbJa0qkkFm1fxMLtC1l3cB0GQ/OazXnmlmcYFjqMNgFttJhRxVLcS1ShxpjTInIP9hsAnwVisXcrV1h9Gvfhk8GfMG7hOO5feD+zh8/G3a1C3pqk1PVaKSLDgQXGGGN1GGWNvSf2sjBxIYu2L2JDiv0hujYBbZgSNYWhoUNpWaulxQmVKypugeMpIp7AEOADY0yuiOibETA6bDSHzx7mmRXP8GSVJ3nn9nf0rwulim8i8CSQJyJZ2EczNsYYf2tjKWfbdWwXCxMXsnD7QjanbQagfd32vNL7FYa0HELTGk0tTqhcXXELnH8D+4EtwFoRaQCcdlYoV/NE5BMcOnOIf0b/k7q+dXm2+7NWR1LKJRhj/KzOoEqHMYbt6dtZkLiABdsXkHAkAYBOQZ14vc/rDGk5hJCbQixOqcqT4t5k/B7wXpFNB0Skp3Miuaa/9/k7R84e4fnVzxPgG8D97e+3OpJSZZ6IdL/UdmPM2tLOopzjxLkTvL/+feYlzGPXsV0IQtf6XflHv38wpOUQHRFeOU1xbzKuCjwPnH8zWgO8BOjTDg5u4sa/B/2b9Mx0HlnyCLWq1GJA8wFWx1KqrHuqyLI30BH7/X29rnSQiPQD3sU+HtcnxpjXL9rfAJgB1AKOA2OMMckicjPwEeCP/aGJV40xX5XQ16KKyCvIY3rsdF5c/SLHzx2nR0gPJnWaxOCWg6njW8fqeKoCKO4lqhnANuBOx/q9wKfAMGeEclWe7p58MfIL+n7Wl3vm38Oy+5YRGRxpdSylyixjzMCi6yISDLxzpWNExB34EOgDJAMbRWSxMSaxSLO3gFnGmM9EpBfwGvb3rUzgPmPMb46BBWNFZLnjUXVVQmz7bPx52Z/ZdmQbPRr24K2+bxFWJ8zqWKqCKe6MY42NMc8bY/Y6Pl4EGjkzmKvy9fJl0d2LCPIPYujcoSQeSbz6QUqp85KBqz0y0xHY7XgvygG+BAZf1CYUWOVYXn1+vzFmlzHmN8dyKnAEey+PKgH7Tuzjrq/vou+svpzJOcOXI79k+X3LtbhRlihugXNORG45vyIiXYFzzonk+mpVqcWSMUuo5FGJgXMGknQqyepISpVJIvK+iLzn+PgA+An7iMZXEggU/aFKdmwragv/62EeCviJSI2LXrsj4AXsud78yi4jJ4MpK6fQ9sO2rNi9ghd7vsiWR7YwNHSoPlWqLFPcS1QPAbMc9+IAnADGOidS+RByUwjf3fMdvWf2ZuCcgay6fxXVK1e3OpZSZU1MkeU84AtjzC8lcN7JwAciMg5YC6Rgv+cGABGpC3wOjDXGFFzqBCIyAZgAEBAQgM1mu+qLZmRkFKtdWXQ92QtMASsPr2TGvhkczzlO74DejA8ZT82Cmvz6y6/OCXoJFe37XlaU9ezFfYpqC9BWRPwd66dF5Akg3pnhXF1YnTDmj5rPgNkDGP7FcJbeu5TKnpWtjqVUWTIfyDLG5IP9/hoR8THGZF7hmBQguMh6kGNbIcflp2GOc/oCw8/fZ+N4H/se+IsxZv3lXsQYMw2YBhAREWGioqKu+sXYbDaK064sutbsG5I38OSyJ9mYspEOgR1Y1G8RnYI6OS/gFVSk73tZUtazF/cSFWAvbIwx58e/edIJecqdHg178Nmwz4hOimbMN2PIK8izOpJSZclKoGjVXxn48SrHbASaikiIiHgBo4DFRRuISE3HXFdgnyh4hmO7F7AQ+w3I80sgf4WTeiaV8QvH0216N5JOJTF9yHTW/mGtZcWNUpdzTQXORfTCajENCx3GO/3fYcnOJTy25DF0RHqlCnkbYzLOrziWfa50gDEmD5gELAe2A18bYxJE5CURGeRoFgXsFJFdQADwqmP7ndiHuxgnInGOj5tL9Csqp7Lysnjjpzdo/X5r5iXM4+lbnmbbpG2MaTsGN7mRXyVKOUdx78G5FP0tfQ0e6vAQh84c4rWfXiPAN4AXer1gdSSlyoKzItLeGLMJQETCKcYDDMaYpcDSi7ZNKbI8H/vlr4uPmw3MvtHQFYkxhm93fMvTK57mwMkDDGk5hNf6vEajm/RBWlW2XbHAEZEzXLqQES7sVlbF8HzP5zmccZjXfnqNOn51eKjDQ1ZHUspqTwDzRCQV+/tKHeAuayOp87Ye3srkZZOx7bfRqnYrlt23jJ4hOoi9cg1XLHB0npiSJSK8P+B9jmQe4YmlT1C7Sm2GhepYiariMsZsFJEWQHPHpp3GmFwrMyk4mnmUF1a9wPRN06nmXY33+r/HH8L/gIfbjXT6K1W69MJpKfNw8+Dz4Z/TObgzYxeMZc3+NVZHUsoyIvIoUMUYs80Ysw3wFZFHrM5VUeXm5/L++vdp9X4rZmyawcMdHibhsQQmdpioxY1yOVrgWMDH04cFoxfQuHpjRnw5gvhD+rS9qrAeLDpNgjHmBPCghXkqrJjjMYR/HM7k5ZOJCIwg9uFY3r79bR2/S7ksLXAsUr1ydb675zv8K/kzcM5A9p/cb3UkpazgLkWGunXMM+VlYZ4KJ68gj4e/e5i/bP0LeQV5LBi9gCX3LKFlravNmKFU2aYFjoWCqwazZMwSsvOyGTB7AOln062OpFRpWwZ8JSK9RaQ38AXwg8WZKozM3Ezu/OpOZmyawV3Bd7H54c3c0ewOnV5BlQta4FisZa2WLLx7IUmnkhgydwgZORlXP0ip8uMZ7JNiPuT42Io+oVkqjp87Tv/P+7N011Le6/8e4xuNp5JHJatjKVVitMApAyKDI5k9Yjab0jYx6utROtqxqjAc80D9CuzHPkt4L+yD9yknSjqVRK9PexGbGsvckXOZ2GGi1ZGUKnF6W3wZMbD5QD4c8CEPf/cwBWcK6Na9m/41pcotEWkGjHZ8HAW+AjDG6CArTrY9fTsDZg/gdPZploxZQo+GPayOpJRTaA9OGTK+/Xhe7PkiK4+spM0HbZgVN0t7c1R5tQN7b80AY8wtxpj3KTLbt3KO6KRoes7oSV5BHivHrdTiRpVrWuCUMc92f5a/t/k7NavU5MFvH6T9R+1ZkLiAAlNgdTSlStIwIA1YLSL/cdxgrHe2OtGSnUvoN6sfNXxqYBtvI6xOmNWRlHIqpxY4ItJPRHaKyG4RefYS+x8Ska2OCe9+FpFQZ+ZxFeHVw/nlgV/4+s6vcRM3Rs8bTZf/dGH57uU6UacqF4wxi4wxo4AWwGrsUzbUFpGPROQ2a9OVPzM3z+TOr+6kVe1W2MbbCLkpxOpISjmd0wocx3gWHwK3A6HA6EsUMHONMW2MMTcDbwJvOyuPqxERBrccTOxDsUwfMp3j544zaM4gbp15K78c/MXqeEqVCGPMWWPMXGPMQCAI2Iz9ySpVAowxvPHTG0xcPJFejXqxYuwKalWpZXUspUqFM3twOgK7jTF7jTE5wJfA4KINjDGni6xWQWco/x13N3fGtB3DtknbeLf/u+w+vpten/Zi8NzBxKXFWR1PqRJjjDlhjJlmjOltdZbyoMAU8OSyJ5myagp3h93NgtEL8PXytTqWUqXGmQVOIJBUZD3Zse0CIvKoiOzB3oPzRyfmcWle7l481OEhtv9xO6/e+iq/Jv1Kp2mduGf+Pew8utPqeEqpMiQ7L5t7v7mXf234F09EPsH0IdPxctcBolXFYvlj4saYD4EPReRu4K/A2IvbiMgEYAJAQEAANputWOfOyMgodtuy5Gq5I4hgevh05ifNZ8H2BSxIWECfOn0Y02AMtb1rl17QS3DV7zlodlU+nM4+zcivRmLbZ+O1Pq/xZJcnrY6klCWcWeCkAMFF1oMc2y7nS+CjS+0wxkwDpgFERESYqKioYgWw2WwUt21ZUtzcd3AHb5x9g6k/T+XfG//N6vTVTIiYwNO3PE2Ab4Dzg16Cq37PQbMr13co4xCD5wxm25FtzBgyg3va3mN1JKUs48xLVBuBpiISIiJewChgcdEGItK0yOodwG9OzFMu1a5Sm6l9p5LwWAJjwsbw0YaPaPleS55f9Twns05e/QRKqXJh9/Hd9Jjeg13HdrFg9AItblSF57QCxxiTB0wClmMfev1rY0yCiLwkIoMczSaJSIKIxAFPconLU6p4gqsG89Ggj4h7NI47mt/B6z+9TvN3mzP156mczTlrdTyllBNtSt1E1PQozmSfYfl9y+nbpK/VkZSynFPHwTHGLDXGNDPGNDbGvOrYNsUYs9ix/LgxppUx5mZjTE9jTIIz81QEzWo04/Phn7Nh4ga61O/CX1f+lZbvteRfG/5FTn6O1fGUUiXsxz0/0uezPvh4+rB6/Go6BnW0OpJSZYKOZFxOta3TloWjF2Ibb6N5zeb86Yc/0fqD1nwe97lO/6BUOfH1tq8ZMncIDas1xPYH+8+6UspOC5xyLjI4khVjV7BkzBJqVK7BA98+QON/NubJH57k1+RfdWRkpVzU++vf595v7qVzcGdW3r+Sen71rI6kVJmiBU4FICL0adyHdQ+uY/6o+XQO7swnsZ/QfXp3Wr7fkikrp5BwRK8OKuUKjDH89ce/Mnn5ZIa0HMKSMUuo5l3N6lhKlTmWj4OjSo+IMLD5QAY2H8iprFN8u+Nbvtr2FVN/mcobP79Bq9qtGNV6FCNbj9S5apQqg3Lzc3lkySPMipvFg+EP8m7/d3F3c7c6llJlkvbgVFBVvaty38338f2Y79n/5H7+efs/8a/kz99W/Y0W77Wg+/TufPDrBxzKOGR1VKUUcDbnLCO+GsGsuFlMiZrC+3e8r8WNUlegBY4iwDeARzo+gm28jZ2P7+TV3q+SmZvJn5f9mZC3Q7j989uZuXmmjqujlEWMMQz7Yhgrdq/ggzs+4C89/oKIWB1LqTJNCxx1gYbVGjL5lsnEPBRD3CNxPHPLM+w/sZ+JiycS/FYwI74cwfyE+WTmZlodVakKI/5wPLb9Nv5+6995MOJBq+Mo5RL0Hhx1WS1rteSFXi/wfM/niUmN4autXzE/YT7f7fwOXy9fBjYfyJ2t76RP4z54untaHVepcmt+wnzcxZ17b77X6ihKuQwtcNRViQgdAjvQIbADb9z2Bj8d+Imvtn3FwsSFfLH1C6pXrs6w0GHc1fouCkyB1XGVKleMMcxLmEfPRj2p6VPT6jhKuQwtcNQ1cXdzJyokiqiQKN7t/y4rdq/g621fMzd+Lp/EfkJ1r+r0PdG3sE3Dag2tjqyUS9uctpl9J/bxzC3PWB1FKZeiBY66bl7uXgxoPoABzQdwNucs3+/6nulrp7Nq7yq+2PoFACE3hdCzYc/CgseqWc6VclXzEubh4ebB4JaDrY6ilEvRAkeViCpeVbiz9Z3UPlqbHj16sD19O6v2rcK2z8Y3id8wY/MMAEJrhRIVEkXPkJ50b9hdByhT10VE+gHvAu7AJ8aY1y/a3wCYAdQCjgNjjDHJjn1jgb86mr5ijPms1IJfI2MM3yR8w62Nb6V65epWx1HKpWiBo0qciBBaO5TQ2qFM6jSJ/IJ8NqdtxrbPxur9q/l006f8a8O/cBM32tdtX9i707V+V3w8fayOr8o4EXEHPgT6AMnARhFZbIxJLNLsLWCWMeYzEekFvAbcKyLVgeeBCMAAsY5jT5TuV1E8G1M2cuDUAf4W9TeroyjlcrTAUU7n7uZORGAEEYERTL5lMtl52WxI2WAvePat5p3od3jrl7fwdPOkc3BnohpG0bNRTzoEdsDL3cvq+Krs6QjsNsbsBRCRL4HBQNECJxR40rG8GljkWO4L/NcYc9xx7H+BfsAXpZD7ms1LmIeXuxcDWwy0OopSLkcLHFXqKnlUoluDbnRr0I2/Rf2Nszln+eXgL6zetxrbPhuvrHmFl9e8jI+nD13rd6VnSE96hvSkbZ22OnKrAggEkoqsJwOdLmqzBRiG/TLWUMBPRGpc5tjAS72IiEwAJgAEBARgs9muGiwjI6NY7YqjwBQwd9Nc2ldrT9z6uBI555WUZPbSptmtUdaza4GjLFfFqwq3NbmN25rcBsCJcydYu3+tveDZb+P/fvw/AKp5V6NDYAci6kXQvl57IgIjdAZldTmTgQ9EZBywFkgB8q/lBMaYacA0gIiICBMVFXXVY2w2G8VpVxzrDq7j6NqjvNX9LaLCSuacV1KS2UubZrdGWc+uBY4qc26qfBODWw4ufGok7Uwaa/avYc2+NWxM3cibP79JvrH/rqrrW5fwwHDC64bbP9cL17FCyr8UILjIepBjWyFjTCr2HhxExBcYbow5KSIpQNRFx9qcGfZ6zUuYRyX3SgxoPsDqKEq5JC1wVJlX168uo9qMYlSbUQBk5may5dAWYlNj2ZS6iZjUGL7f+T0GA0CDqg0uKHra121PVe+qVn4JqmRtBJqKSAj2wmYUcHfRBiJSEzhujCkAnsP+RBXAcuDvInKTY/02x/4yJb8gn4WJC+nXtB9+lfysjqOUS9ICR7kcH08fIoMjiQyOLNx2Ovs0m9M2E5saS2xqLDEpMSxIXFC4v2mNpoTXCy/8uLnOzVTxqmJFfHWDjDF5IjIJe7HiDswwxiSIyEtAjDFmMfZemtdExGC/RPWo49jjIvIy9iIJ4KXzNxyXJb8c/IW0jDRGthppdRSlXJYWOKpc8K/kT4+GPejRsEfhtmOZx9iUtonYlFhi02L5af9PfLn1SwDcxI2WtVr+736eehHkFORYFV9dI2PMUmDpRdumFFmeD8y/zLEz+F+PTpk0L2EelT0q079Zf6ujKOWytMBR5VYNnxr0adyHPo37FG5LO5N24aWtXd/zWZx9nDd3caflzpa0rdOWsDph9s8BYdTwqWHVl6AqoLyCPBZtX0T/Zv21l1GpG6AFjqpQ6vrVLZxeAuwjxR48dZDY1Fi+/fVbTlY6yep9q5kTP6fwmGD/4MKC53zx07BaQ9zEzaovQ5Vja/ev5cjZI3p5SqkbpAWOqtBEhAbVGtCgWgOqH6le+MjjkbNHiD8Uz5ZDW4g/HE/8oXh++O2HwtnS/Sv5ExYQdkFPT2jtULw9vC38alR5MC9hHlU8q9C3aV+royjl0rTAUeoSalepza2Nb+XWxrcWbjuXe47E9ES2HNpiL3wOxTMrbhYZORmA/RJXi1otCgue8z0+eolLFVdufi7fbv+WAc0H6LQlSt0gLXCUKqbKnpULn8I6r8AUsPfE3sLeni2HtrBm3xrmxs8tbBPkH0SbgDa0rNWSFjVb0KJWC1rUbKGPrqvfWb1vNcfOHWNEqxFWR1HK5WmBo9QNcBM3mlRvQpPqTRgWOqxwe/rZdOIP24uerYe3suXQFlbuXUlO/v+e1KrjW4cWNVvQvGbzwqKnec3m1POrh4hY8eUoi32T8A3+lfwLR/VWSl0/LXCUcoJaVWrRu1FvejfqXbgtvyCffSf3sSN9BzuO7mDn0Z3sSN/BF1u/4HT26cJ2/pX87UWPo+A5XwA1uqkRHm76I1te5eTnsGjHIgY2H6j3cilVAvTdUqlS4u7mXtjbU3T4fWMMhzIOsePojguKn5V7V/L5ls8L23m5e9GkepPC4ud8r0+zms2s+HJUCftxz4+czDrJ8FbDrY6iVLmgBY5SFhMR6vrVpa5fXXqG9Lxg36ms/2/vzqOjqtJ+j3+fjJWJkAmQOWKAABLmQWwGlQYv89TaDi3YBGkVsR1xbhtd8jq96nIiKiCo10tAEBAR0xIGAaFRRAKBgEQJAoZAQgKpjPv+UaFIGKQCVE6q8nzWyqqqU7vO+VVS2Xmyz7DzHCM9FcXPrpxd/HT4Jz5P/9x5RhdAg8AGdNjfgdZRrYmLiiMuKo7WUa1pHt5cZ2D3EAt3LKS+rX6V6zYppS6eFjhK1WLhtnB6NO1Bj6Y9qiwvKi1iz9E9zhGfdTvWcdx+nE+2fVJld1eAbwCtIludVfjERcURHRytx/rUEvZSO0vSlzAqfhQBvgFWx1HKK2iBo5QHCvQLpH2D9rRv0B6AVJNK//79Mcbw+4nfycjJYHfObjJyMsjIySD9SDrLdy+npLzEuY76tvpVCp5T91tFttIr6NawlXtWcrzouO6eUuoycmuBIyKDgddxTIj3vjFmxhnPPwBMBEqBEKWLjwAAHvlJREFUbOBOY8wv7syklDcTERqGNqRhaEOubXFtledKy0v5JfeXs4qf1Zmrq1y5GRyntp8qeuKi4pjYdaJel8WNFu5YSFRQFNfFXmd1FKW8htsKHBHxBd4CBgJZwGYRWWKM2VGp2Q9AN2PMSRH5B/AicJO7MilVl/n5+NEqshWtIlsxOG5wledOFJ9g79G9VQqfjJwM5m+fT35RPpO7T7YotfcrLClk2a5l/KXDX/D39bc6jlJew50jOD2APcaYnwFE5FNgBOAscIwxqyq13wjc5sY8SqnzCAkIoWMjx9QTlRljOFp4VI8LcaOv9nxFQXGBXtxPqcvMnQVOE2B/pcdZQM8/aP934MtzPSEik4BJAA0bNiQ1NdWlAAUFBS63rU08NTdodqt4cva6LjktmZjgGPq17Gd1FKW8Sq04yFhEbgO6Aef8DTfGJAFJAN26dTOnJkS8kNTUVFxtW5t4am7Q7Fbx5Ox12YniEyzfvZxbO96qF3FU6jJz52/UAaBZpcdNK5ZVISI3AE8A/YwxRW7Mo5RStcqXGV9ysuQk4zqMszqKUl7Hx43r3gzEiUisiAQANwNLKjcQkc7ATGC4MeZ3N2ZRSqlaJzktmUahjbi2+bUXbqyUqha3FTjGmFLgXuArYCcw3xiTJiL/FpHhFc1eAkKBZBHZKiJLzrM6pZTyKvlF+azIWMGo+FF6tWml3MCtO32NMcuB5Wcse7rS/RvcuX2llKqtvtj9BfZSu+6eUspN3LmLSiml1HkkpyXTJKwJvZv1tjqKUl5JCxyllKphefY8Vu5Zyeh2o/ER7YaVcgf9zVJKqRq2dNdSisuKdfeUUm6kBY5SStWw5LRkmoc3p0eTHhdurJS6KFrgKKVUDTpWeIyUvSmMaTcGEbE6jlJeSwscpZSqQZ+nf05peanunlLKzby2wDHGWB1BKaXOkpyWTGxELF2u6GJ1FKW8mlcWODlHT9Kj70w2bDpidRSllHI6cvIIq35exdh2Y3X3lFJu5pWzu+UdL0JE+NcLafx6IICXnh9MaGiA1bGUUnXc4p2LKTNlunvKDUpKSsjKysJut1sdpVrCw8PZuXOn1TEuSk1nt9lsNG3aFH9/f5fae2WBc2XLCNalTGTiPz5k9rwfSF2byex3R9GrR7MLv1gppdxkQdoCroq8io4NO1odxetkZWURFhZGy5YtPWp0LD8/n7CwMKtjXJSazG6MIScnh6ysLGJjY116jVfuogIICPDlztuvJGXZeMrKDANunM2/nv+GkpIyq6MppS6RiAwWkV0iskdEpp3j+eYiskpEfhCRbSLyfyqW+4vIhyLyk4jsFJHHairz4YLDrM5czbj24zzqD7CnsNvtREVF6ffWS4kIUVFR1Rqh89oC55Rrr2nBf9dO5rabE3jh5bX0GzSLXRl6bI5SnkpEfIG3gBuBdsBfRaTdGc2exDHBb2fgZuDtiuXjgEBjzNVAV+AuEWlZE7kX7VxEuSlnbPuxNbG5OkmLG+9W3Z+v1xc4APXqBfLeWyP49MNxZP5yjJ79ZvLu+5v1TCulPFMPYI8x5mdjTDHwKTDijDYGqFdxPxz4rdLyEBHxA4KAYuC4+yPDwrSFtI1uS/sG7Wtic0rVeV55DM75jBrejl49mjHp3iVMfXg5X6zYTdKbw7mikWfu/1SqjmoC7K/0OAvoeUabfwErRWQKEALcULF8AY5i6CAQDPzTGHP0XBsRkUnAJICGDRuSmpp6wWAFBQXnbJdTlMPaX9ZyW4vbWL169QXXY4XzZfcEBQUFhIeHk5+fb3WUaisrK3M5d25uLsnJySQmJgJw8OBBHnnkEebNm+fOiOdVneyXi91ud/lzWqcKHIArGoWxJPkW3n1/M9Oe/pqufd7h7deGMXJYvNXRlFKXz1+BOcaYV0SkNzBPRDrgGP0pAxoDEcBaEUkxxvx85gqMMUlAEkC3bt1M//79L7jR1NRUztXuze/exGB4cMiDxMfUzr7mfNk9QWpqKjabzSMP1q3Ogbo5OTnMmjWLBx54AICwsDAWL17sznh/6HzZS0tL8fNzT3lhs9no3LmzS23rXIEDjv14/0jswYB+VzLhrs+46W/z+dstnXjlhcHUqxdodTyl1B87AFQ+JbJpxbLK/g4MBjDGbBARGxAN3AKsMMaUAL+LyLdAN+CsAudyWpi2kA4NOtTa4sbbPPjYCrb9dOiyrrPj1Y145YXBf9hm+vTpfPTRR8TExNCsWTO6du3KQw89xN69e7nnnnvIzs4mODiY9957j7Zt2zJ+/HhsNhvbtm3j0KFDvPjii4wd6zhG66WXXmL+/PkUFRUxatQonn32WaZNm8bevXvp1KkTAwcO5J577mHo0KFs376dsrIyHn30UVasWIGPjw+JiYlMmTKlSr733nuPpKQkiouLueqqq5g3bx7BwcEcPnyYyZMn8/PPjl+Dd955h2uuuYa5c+fy8ssvIyJ07NiRefPmMX78eIYOHerMGRoa6hz9e+qpp4iIiCA9PZ3du3czcuRI9u/fj91uZ+rUqUyaNAmAFStW8Pjjj1NWVkZ0dDRff/01bdq0Yf369cTExFBeXk7r1q3ZsGEDMTExF/0zq5MFziltW0ezZuXfef7F1fzPq+tYvc5xOnmf3s2tjqaUOr/NQJyIxOIobG7GUbhU9itwPTBHROIBG5Bdsfw6HCM6IUAv4DV3ht2ft5/1+9fz7IBn3bkZZbHNmzezcOFCfvzxR0pKSujSpQtdu3YFYNKkSbz77rvExcXx3Xffcffdd/PNN98AcPjwYdatW0d6ejrDhw9n7NixrFy5koyMDDZt2oQxhuHDh7NmzRpmzJjB9u3b2bp1KwCZmZnO7SclJZGZmcnWrVvx8/Pj6NGz97yOHj3auXvrySef5IMPPmDKlCncd9999OvXj0WLFlFWVkZBQQFpaWk899xzrF+/nujo6HOu70zff/8927dvd57GPWvWLCIjIyksLKR79+6MGTOG8vJyEhMTWbNmDbGxsRw9ehQfHx9uu+02Pv74Y+6//35SUlJISEi4pOIG6niBA+Dv78u/nriOQTfEMWHyIq4fMpuHpvbh6ccGEBDga3U8pdQZjDGlInIv8BXgC8wyxqSJyL+B/xpjlgAPAu+JyD9xHFg83hhjROQtYLaIpAECzDbGbHNn3s92fAbAmPZj3LkZVcmFRlrc4dtvv2XEiBHYbDZsNhvDhg0DHMcHrV+/nnHjTl/csaioyHl/yJAh+Pj40K5dOw4fPgzAypUrWblypXNXTEFBARkZGTRvfv5/vlNSUpg8ebJz11BkZORZbbZv386TTz5Jbm4uBQUFDBo0CIBvvvmGuXPnAuDr60t4eDhz585l3LhxREdHn3d9Z+rRo0eVa9S88cYbLFq0CID9+/eTkZFBdnY2ffv2dbY7td4777yTESNGcP/99zNr1iwmTJhwwe1dSJ0vcE7p3bMZm9fcxcNPfMVLr33L19/sZc7M0cS3vbQKUil1+RljlgPLz1j2dKX7O4A+53hdAY5TxWvMgrQFdGrUibiouJrcrKolysvLqV+/vnPU5UyBgacPizh1Zq8xhscee4y77rqrStvKIzYXY/z48SxevJiEhATmzJlzUQeV+/n5UV5eDjjeW3FxsfO5kJAQ5/3U1FRSUlLYsGEDwcHB9O/f/w+vYdOsWTMaNmzIN998w6ZNm/j444+rne1MdeI0cVeFhQXy7hvDmf/RTWQdOE6vAUm8OfM7ysv1dHKlVPVl5may6cAmvfZNHdCnTx+WLl2K3W6noKCAZcuWAVCvXj1iY2NJTk4GHMXLjz/++IfrGjRoELNmzaKgoACAAwcO8PvvvxMWFnbes5YGDhzIzJkzKS0tBTjnLqX8/HyuuOIKSkpKqhQQ119/Pe+88w7gODMqLy+P6667juTkZHJycqqsr2XLlmzZsgWA5cuXU1JScs48eXl5REREEBwcTHp6Ohs3bgSgV69erFmzhn379p2Vc+LEidx2222MGzcOX99L34OiBc45jBjSli3f/oMBfWN5cNoKho79iAO/1cilMpRSXmRh2kJAd0/VBd27d2f48OF07NiRG2+8kauvvprw8HAAPv74Yz744AMSEhJo3749n3/++R+u689//jO33HILvXv35uqrr2bs2LHk5+cTFRVFnz596NChAw8//HCV10ycOJHmzZvTsWNHEhIS+OSTT85a7/Tp0+nZsyd9+vShbdu2zuWvv/46q1at4uqrr6Zr167s2LGD9u3b88QTT9CvXz8SEhKcZ24lJiayevVqEhIS2LRpU5VRm8oGDx5MaWkp8fHxTJs2jV69egEQExNDUlISo0ePJiEhgZtuusn5muHDh1NQUHBZdk8BjmrSk766du1qXLVq1SqX255LeXm5SZq12dRv/Lxp2HKGSf5s+yWtz1WXmttKmt0atSU7jmNgLO8nLveXq/3OmT+HXjN7mWuSrnHptVarLZ+hi7Fq1SqzY8cOq2OY/Px8Y4wxJ06cMF27djVbtmy54GuOHz/u7lhuc7mzb9682Vx77bV/2OZcP+fz9Ts6gvMHRITECd34bvVdtLoyklvvXMCEuxaRl+dZs9UqpWrenqN7+P7g9zp6U4dMmjSJTp060aVLF8aMGUOXLl2sjuQxZsyYwZgxY3jhhRcu2zr1IGMXtL4qitQVdzLjlbW88PIa1q3/hZdfGMTggXEEBuq3UCl1ts/SHGdP6fE3dce5dgsp10ybNo1p086aN/eS6AiOi/z9fXlqWn9SV9yJf4Avf7l9Pk3iXuL2vy9k4eI0CgqKL7wSpVSdkZyWTK+mvWgertfVUsoKOvxQTT26NWXrhrtZtWYfi5ftZOkX6cz/bDs2mx8Dr2vFyGHxDBncmoj6QVZHVeqyMMboLM3VtOvILrYd3sZLg16yOopSdZYWOBchIMCXQTdcxaAbruLNV4awfuN+Fi3dwedL01m6fBd+fj70+1NLRg6NZ/iQtjRqGGp1ZKWcyssNx3ILyT5ykiNHTnAk5yTZFbe/Z5/gyJGTZOc4bo/knODosUKOZj2On58O+LrKefZUOz3+RimraIFziXx9ffhTnxb8qU8LXnlhMFt++I3FS3eyaOlOpjz4Bfc99AW9ezRj5PB4RgyNp2Xz+lZHVl6mvNyQm1fMzvRssnNOkJ19wlG85Jy6dRQyp5YdyTlJWdm5r+1ULyyQ6OhgYqJDaN4snG5dGhMdFUxJSZkWONWQnJZMn+Z9aFKvidVRlKqztMC5jESEbl2a0K1LE6Y/fT0707NZvGwni5em88gTK3nkiZV0TriCkUPbMmJYPPFt9CrJynUlJWXs3XeM9F3Z7NyVzc50x+2ujCMUFZUBG856TUR9G9HRIcREBdPqykh69mhKg+gQRxETFeIsZqKjgomOCtaD5i+DHb/vYEf2Dv73xv+1OopSdZr2Zm4iIrSLb0C7+AY8/nA/9u47yufL0vl86U6eeX4Vzzy/ijatoxk1LJ6Rw+Lp1LGRHuegACgqKmXP3qOOIqZSMZOxN4eSknJnuxbN6xPfJobr+l9JsT2ba3onOIuZ6OgQoiKD8PfX+dRq2oK0BQjC6HajrY6ivFRpaalzzil1fvodqiGtYiN5YMo1PDDlGn47mM+SL9JZvGwnL722jhmvrKVFs3BGDItn5ND48+4+UN6lsLCE3XtynCMxp772/nzU+RkQgStjI4lvE8OQwa2JbxNDfNsY2sRFExIS4FxXamoq/ft3sOqtqArGGJLTkunbsi+NQhtZHafOenDFg2w7dHnnUO3YqCOvDH7lgu1GjhzJ/v37sdvtTJ06lUmTJrFixQoef/xxysrKiI6O5j//+Q8FBQVMmTKFTZs24evryzPPPMOYMWMIDQ11TtGwYMECli1bxpw5cxg/fjw2m40ffviBPn36cPPNNzN16lTsdjtBQUHMnj2bNm3aUFZWxqOPPsqKFSvw8fEhMTGR9u3b88Ybb7B48WIAvv76a95++23nRJjeyq0FjogMBl7HMePv+8aYGWc83xd4DegI3GyMWeDOPLVF4yvCmDyxO5Mndifn6Em+WLGbxUt3MvODzbzx9kbqhfnRod0+YltGnP5q4bht1DAUHx8d6fEExhiOHy/iWJ6d7OwT7Mo4UqWY2Zd5jIq59fD1FVpd6Shkxoxo5yhk2sQQd1UUQUH+1r4R5bJ9J/axO2c3U3pNsTqKssisWbOIjIyksLCQ7t27M2LECBITE1mzZg2xsbHOuZemT59OeHg4GzduJCwsjGPHjl1w3VlZWaxfvx5fX1+OHz/O2rVr8fPzIyUlhccff5yFCxeSlJREZmYmW7duxc/Pj6NHjxIREcHdd99NdnY2MTExzJ49mzvvvNPd3wrLua3AERFf4C1gIJAFbBaRJcYxy+8pvwLjgYfclaO2i4oM5m+3dOJvt3QiP7+Ir1L2MO+TdRTafVn77S98Mn+b848ggM3mR8sW9YltEeG4rSiArmwRQcsWEYSGBpx/Y6rajDEUFBRzLNdObm4hx/Ict0ePFZ5elmsnN9fO0dzCSo8Lyc2znzUa5+/vQ1yrKDonXMEtf+noLGSuahWpx794gdXZq/ERH0bFj7I6Sp3mykiLu7zxxhvOkZH9+/eTlJRE3759iY2NBSAyMhKAlJQUPv30U+frIiIiLrjuypNQ5uXlcccdd5CRkYGIOCe9TElJYfLkyc5dWKe2d/vtt/PRRx8xYcIENmzYwNy5cy/TO6693Nmj9gD2GGN+BhCRT4ERgLPAMcZkVjxXfq4V1DVhYYGMHdWe6Ihs+vfvDziOx/g1K499mcdOf/2Sy77MY3y74VeO5xdVWUeDmJBKIz6OAqhlC8fjJo3D8PU995kwxhiKisqwF5VSWFhCob0Ue2FJxeNSCu0lFBaWUlR0+r69yNGm0O54jb2olF9/zWJ5ShEhwQEEB/kTFOxPSLB/pfuO5cHBFV8V90OCA/D397nk45BKSso4ebKEEydLOFlYQuHJEk6cLOZkYQknTpRQWHj68ckTjjYnThZz8mQJe/bu59W3DnAst2rxUlp6/o+nr69QP9xGREQQEfWDiIgI4sqWkdSvbyOi/unlkZFBtL4qmlaxEXpcjJcyxrAmew39Y/sTE6InENRFqamppKSksGHDBoKDg+nfvz+dOnUiPT3d5XVU7gPt9qrTAlWe2PKpp55iwIABLFq0iMzMTOffjPOZMGECw4YNw2azMW7cuDpxDI8732ETYH+lx1lAz4tZkYhMAiYBNGzYkNTUVJdeV1BQ4HLb2uRcuQN8oU0raNMqAGgANMAYQ35+KQcPF3LodzuHDtk5eNjOwcMFpK49wvzP7JRX+tvs5yc0iLER4O9DUXEZxcXlFBWXU1JcTnFJeZWRouoKCPAhIMAHH4GU1MMUFVW/ZvXxAVugLzabL4EBPgQG+mKz+RAY4EtgoONxSUk5RcVl2O3lFQVZxa29jKLickpLq/cmRCAw0Mex3UAf6tUrJDTEj8aN/GjdKpzQ0CjCQvwJDfUjNNSPsFA/wkL9CQ1xPA4O8r1AUVZc8ZXHod8Ocei3an9bXOKpn3VvsvXQVn4r/I2n2j9ldRRlkby8PCIiIggODiY9PZ2NGzdit9tZs2YN+/btc+6iioyMZODAgbz11ltMnz4dgGPHjhEREUHDhg3ZuXMnbdq0YdGiRYSFhZ13W02aOC5DMGfOHOfygQMHMnPmTAYMGODcRRUZGUnjxo1p3Lgxzz33HCkpKW7/XtQGHlHCGWOSgCSAbt26mQtVqqc4Drx0rW1tcrlyl5SUsf/A8TNGf45RWlqOLdCPoCA/bDZ/gmx+2Gx+BNn8sQVV3Nr8Kpafvh8U5GgbWNE2qKJtYODpP/KnshtjsNtLHSMpFaMpJytGShz3Ty8/cbKYQuf9yiMvVUdhco+XEBjgR0hwEPXrnx4NCgnxJyioYqQo2J/g4ADnqFFISMBZz516TXCQ472dmd0TeXJ2b/Fr7q9EBUQxou0Iq6MoiwwePJh3332X+Ph42rRpQ69evYiJiSEpKYnRo0dTXl5OgwYN+Prrr3nyySe555576NmzJ/7+/jzzzDOMHj2aGTNmMHToUGJiYujWrZvzgOMzPfLII9xxxx0899xzDBkyxLl84sSJ7N69m44dO+Lv709iYiL33nsvALfeeivZ2dnEx8fXyPfDau4scA4AzSo9blqxTNUQf39frmwZwZUtL7xv93ITEUdBFOQPUTW+eaVq3Ij4EYQdCiMqWD/wdVVgYCBffvnlOZ+78cYbqzwODQ3lww8/JD8/v8oozdixYxk79uwJWiuP0gD07t2b3bt3Ox8/99xzAPj5+fHqq6/y6quvnrWOdevWkZiY6PL78XTuLHA2A3EiEoujsLkZuMWN21NKKUv5iF7tWdVOXbt2JSQkhFdese4A7JrmtgLHGFMqIvcCX+E4TXyWMSZNRP4N/NcYs0REugOLgAhgmIg8a4xp765MSimlVF20ZcsWqyPUOLceg2OMWQ4sP2PZ05Xub8ax60oppZS6JMbozPfezFTzTBgdT1VKKeXxbDYbOTk51f4jqDyDMYacnBxsNpvLr/GIs6iUUkqpP9K0aVOysrLIzs62Okq12O32av3Rrk1qOrvNZqNpU9d3+miBo5RSyuP5+/s7rxbsSVJTU+ncubPVMS5Kbc+uu6iUUkop5XW0wFFKKaWU19ECRymllFJeRzztiHMRyQZ+cbF5NHDEjXHcxVNzg2a3Sm3J3sIY43UzTVaj36ktP4eLodmtodkv3Tn7HY8rcKpDRP5rjOlmdY7q8tTcoNmt4snZvYkn/xw0uzU0u/voLiqllFJKeR0tcJRSSinldby9wEmyOsBF8tTcoNmt4snZvYkn/xw0uzU0u5t49TE4SimllKqbvH0ERymllFJ1kBY4SimllPI6XlngiMhgEdklIntEZJrVeVwlIs1EZJWI7BCRNBGZanWm6hIRXxH5QUSWWZ2lOkSkvogsEJF0EdkpIr2tzuQKEflnxWdlu4j8XxHxzFn7vID2O9bQPqfmeUq/43UFjoj4Am8BNwLtgL+KSDtrU7msFHjQGNMO6AXc40HZT5kK7LQ6xEV4HVhhjGkLJOAB70FEmgD3Ad2MMR0AX+Bma1PVTdrvWEr7nBrkSf2O1xU4QA9gjzHmZ2NMMfApMMLiTC4xxhw0xnxfcT8fxwe+ibWpXCciTYEhwPtWZ6kOEQkH+gIfABhjio0xudamcpkfECQifkAw8JvFeeoq7XcsoH2OZTyi3/HGAqcJsL/S4yw85Je1MhFpCXQGvrM2SbW8BjwClFsdpJpigWxgdsVQ9/siEmJ1qAsxxhwAXgZ+BQ4CecaYldamqrO037GG9jk1zJP6HW8scDyeiIQCC4H7jTHHrc7jChEZCvxujNlidZaL4Ad0Ad4xxnQGTgC1/hgKEYnAMUoQCzQGQkTkNmtTKU/laf2O9jnW8KR+xxsLnANAs0qPm1Ys8wgi4o+jk/nYGPOZ1XmqoQ8wXEQycQzPXyciH1kbyWVZQJYx5tR/rQtwdD613Q3APmNMtjGmBPgMuMbiTHWV9js1T/sca3hMv+ONBc5mIE5EYkUkAMfBT0sszuQSEREc+2R3GmNetTpPdRhjHjPGNDXGtMTxPf/GGFMrq/ozGWMOAftFpE3FouuBHRZGctWvQC8RCa747FyPhxyo6IW036lh2udYxmP6HT+rA1xuxphSEbkX+ArH0d2zjDFpFsdyVR/gduAnEdlasexxY8xyCzPVFVOAjyv+OP0MTLA4zwUZY74TkQXA9zjOhPmBWn7pdG+l/Y66CB7X54Bn9Ts6VYNSSimlvI437qJSSimlVB2nBY5SSimlvI4WOEoppZTyOlrgKKWUUsrraIGjlFJKKa+jBY66aCJSJiJbK2aUXSoi9d28vfEi8qY7t6GUqr20z1HVoQWOuhSFxphOFTPKHgXusTqQUsqraZ+jXKYFjrpcNlAxuaCIdBKRjSKyTUQWVcxdgoikiki3ivvRFZdYP/Vf0mciskJEMkTkxVMrFZEJIrJbRDbhuCDZqeXjKv6L+1FE1tTg+1RK1Q7a56g/pAWOumQi4ovjct2nLk0/F3jUGNMR+Al4xoXVdAJuAq4GbhKRZiJyBfAsjk7mWqBdpfZPA4OMMQnA8MvyRpRSHkH7HOUKLXDUpQiquLT7IaAh8LWIhAP1jTGrK9p8CPR1YV3/McbkGWPsOOZkaQH0BFIrJnUrBv5fpfbfAnNEJBHHpfGVUt5P+xzlMi1w1KUoNMZ0wtExCBfeH17K6c+c7YzniirdL+MC86QZYyYDT+KYwXmLiES5Glop5bG0z1Eu0wJHXTJjzEngPuBB4ARwTET+VPH07cCp/6wyga4V98e6sOrvgH4iEiUi/sC4U0+ISCtjzHfGmKeBbBydjlKqDtA+R7nC62YTV9YwxvwgItuAvwJ3AO+KSDBVZ8l9GZgvIpOAL1xY50ER+ReOgwlzga2Vnn5JROJw/Bf3H+DHy/VelFK1n/Y56kJ0NnGllFJKeR3dRaWUUkopr6MFjlJKKaW8jhY4SimllPI6WuAopZRSyutogaOUUkopr6MFjlJKKaW8jhY4SimllPI6/x97qZbxedRQXwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tTnk1_Q4jLZ-",
        "outputId": "88ad32ba-f4be-48d4-9beb-5a88faaa7cd9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"Generic FL.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3506840e-d964-4af2-91b0-93a0cf2eee9b\", \"Generic FL.png\", 150052)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q569VCEa6IQP"
      },
      "source": [
        "# Normal Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8HDTnmb0F-9",
        "outputId": "bbe662a9-b23f-4d69-a480-76daa76ee980"
      },
      "source": [
        "server_model_norm = create_server_model()\n",
        "num=0\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "n_hist=server_model_norm.fit(X_train[6000*num:6000*(num+1)], y_train[6000*num:6000*(num+1)], epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 2s 7ms/step - loss: 0.8065 - accuracy: 0.7578 - val_loss: 0.2874 - val_accuracy: 0.9135\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.2138 - accuracy: 0.9360 - val_loss: 0.2259 - val_accuracy: 0.9333\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.1237 - accuracy: 0.9630 - val_loss: 0.1942 - val_accuracy: 0.9424\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0847 - accuracy: 0.9758 - val_loss: 0.1952 - val_accuracy: 0.9406\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0550 - accuracy: 0.9871 - val_loss: 0.1982 - val_accuracy: 0.9455\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0353 - accuracy: 0.9901 - val_loss: 0.2123 - val_accuracy: 0.9425\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9970 - val_loss: 0.1875 - val_accuracy: 0.9512\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.2062 - val_accuracy: 0.9471\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1802 - val_accuracy: 0.9553\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.1977 - val_accuracy: 0.9528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7NR4Du5biETR",
        "outputId": "6c01a63a-5549-44e7-84e1-bb0ea12b0afe"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(n_hist.history['accuracy'], label=\"accuracy\")\n",
        "ax.plot(n_hist.history['val_accuracy'], label=\"val accuracy\")\n",
        "ax.legend()\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(n_hist.history['loss'], label=\"loss\")\n",
        "ax.plot(n_hist.history['val_loss'], label=\"val loss\")\n",
        "ax.legend()\n",
        "plt.savefig(\"Generic\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}