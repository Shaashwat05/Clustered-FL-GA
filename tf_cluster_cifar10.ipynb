{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_cluster_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh93W-5rTvLt"
      },
      "source": [
        "* cluster head\n",
        "* client_ratio\n",
        "* non-IID data\n",
        "* DBSCAN\n",
        "* batch size\n",
        "* plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKvzMMr0a0t6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, GlobalMaxPool2D\n",
        "from tensorflow.keras import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "from itertools import accumulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TeDIUjTbzdC"
      },
      "source": [
        "# Global variablles\n",
        "TOT_CLIENTS = 100\n",
        "learning_rate_list = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
        "batch_size_list = [16, 32, 64, 128]\n",
        "NUM_ROUNDS = 10\n",
        "CLIENT_RATIO = 0.3\n",
        "DATA_DIV = 5000\n",
        "NUM_CLIENTS = int(TOT_CLIENTS * CLIENT_RATIO)\n",
        "div_list = [np.random.randint(1000,4000) for i in range(NUM_CLIENTS)]\n",
        "origin_list = [np.random.randint(0,45000) for i in range(NUM_CLIENTS)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQUmIDC-2MKW",
        "outputId": "ae0f3f19-adb7-4233-f85a-9bdffa924e9e"
      },
      "source": [
        "print(np.sum(div_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFG9fyvCLNL"
      },
      "source": [
        "# Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuhVjh91qhM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d0d7e5-5568-4104-9cf6-e7f0417ffb80"
      },
      "source": [
        "#loading data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape)\n",
        "\n",
        "#reshape\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalixation\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One Hot encoding\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "\n",
        "y_train=ohe.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test=ohe.transform(y_test.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxtvKt8ubvMz"
      },
      "source": [
        "client_train_x = []\n",
        "client_train_y = []\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "  client_train_x.append(X_train[origin_list[i]:origin_list[i]+div_list[i]])\n",
        "  client_train_y.append(y_train[origin_list[i]:origin_list[i]+div_list[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8uW5AbJCQcl"
      },
      "source": [
        "# Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591IbG3Ta9iO"
      },
      "source": [
        "def create_server_model():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation = 'relu',input_shape = (32,32,3)))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation = 'relu'))\n",
        "  model.add(MaxPool2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "  model.add(MaxPool2D((2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same', activation = 'relu'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same', activation = 'relu'))\n",
        "  model.add(MaxPool2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "  model.add(Dense(10, activation = 'softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC9cafnuCTJZ"
      },
      "source": [
        "# Model Cloner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piW-cRlDfKRw"
      },
      "source": [
        "def model_cloner(model, learning_rate, optimizer):\n",
        "    new_model = tf.keras.models.clone_model(model)\n",
        "    new_model.set_weights(model.get_weights())\n",
        "    if optimizer=='adam':\n",
        "        new_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr4FQwXh40QD"
      },
      "source": [
        "# Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUemkC0meg2M"
      },
      "source": [
        "def train_client_initial(num, model, lr_list, batch_list):\n",
        "  models = []\n",
        "  losses = []\n",
        "\n",
        "  for j in range(len(batch_list)):\n",
        "    for i in range(len(lr_list)):\n",
        "      models.append(model_cloner(model, lr_list[i], 'adam'))\n",
        "      hist = models[i].fit(client_train_x[num], client_train_y[num], epochs=1, batch_size=batch_list[j], validation_data=(X_test, y_test))\n",
        "      losses.append(round(hist.history['val_loss'][0], 4))\n",
        "\n",
        "  ind = losses.index(min(losses))\n",
        "\n",
        "  return models[ind], lr_list[ind%3], batch_list[0 if ind < 3 else 1], losses[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68OmWpJddDsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea4fc16-5567-4cb7-cae7-cd6b7b7f2ec3"
      },
      "source": [
        "server_model = create_server_model()\n",
        "server_model.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "server_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGyKgX-c0eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87729edd-7280-45fc-d907-fbffaa82afc8"
      },
      "source": [
        "lr_init = []\n",
        "batches = []\n",
        "losses = []\n",
        "data = []\n",
        "client_models = []\n",
        "\n",
        "for j in range(NUM_CLIENTS):\n",
        "  print(\"----------------CLIENT \" + str(j) +\"-------------------------\")\n",
        "\n",
        "  lr_list = np.random.choice(learning_rate_list, 3, replace=False)\n",
        "  batch_list = np.random.choice(batch_size_list, 2, replace=False)\n",
        "  data.append(train_client_initial(j, server_model, lr_list, batch_list))\n",
        "\n",
        "  client_models.append(data[j][0])\n",
        "  lr_init.append(data[j][1])\n",
        "  batches.append(data[j][2])\n",
        "  losses.append(data[j][3])\n",
        "\n",
        "sum=[i*0 for i in client_models[0].get_weights()]\n",
        "for i in range(NUM_CLIENTS):\n",
        "  sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "server_model.set_weights([i/NUM_CLIENTS for i in sum])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------CLIENT 0-------------------------\n",
            "93/93 [==============================] - 35s 21ms/step - loss: 0.6774 - accuracy: 0.0856 - val_loss: 0.5805 - val_accuracy: 0.1000\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.5001 - accuracy: 0.0974 - val_loss: 0.3298 - val_accuracy: 0.1265\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.3893 - accuracy: 0.1206 - val_loss: 0.3282 - val_accuracy: 0.1003\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.5038 - accuracy: 0.0859 - val_loss: 0.4101 - val_accuracy: 0.1000\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.3282 - accuracy: 0.1391 - val_loss: 0.3269 - val_accuracy: 0.1811\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.3151 - accuracy: 0.1832 - val_loss: 0.2994 - val_accuracy: 0.2497\n",
            "----------------CLIENT 1-------------------------\n",
            "11/11 [==============================] - 2s 104ms/step - loss: 0.6931 - accuracy: 0.0950 - val_loss: 0.6874 - val_accuracy: 0.0999\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 1.0574 - accuracy: 0.0858 - val_loss: 0.3631 - val_accuracy: 0.1000\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 0.5385 - accuracy: 0.1026 - val_loss: 0.3374 - val_accuracy: 0.1244\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 0.6454 - accuracy: 0.0948 - val_loss: 0.5682 - val_accuracy: 0.1000\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.3365 - accuracy: 0.0998 - val_loss: 0.3295 - val_accuracy: 0.1000\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.3347 - accuracy: 0.0998 - val_loss: 0.3348 - val_accuracy: 0.1001\n",
            "----------------CLIENT 2-------------------------\n",
            "12/12 [==============================] - 2s 101ms/step - loss: 1.0375 - accuracy: 0.0949 - val_loss: 0.3559 - val_accuracy: 0.1000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 0.5332 - accuracy: 0.0971 - val_loss: 0.3409 - val_accuracy: 0.1000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 0.6945 - accuracy: 0.0897 - val_loss: 0.6939 - val_accuracy: 0.0998\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3337 - accuracy: 0.0996 - val_loss: 0.3268 - val_accuracy: 0.1000\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.3352 - accuracy: 0.1102 - val_loss: 0.3299 - val_accuracy: 0.1441\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.6923 - accuracy: 0.0950 - val_loss: 0.6906 - val_accuracy: 0.0997\n",
            "----------------CLIENT 3-------------------------\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 0.4717 - accuracy: 0.0980 - val_loss: 0.3295 - val_accuracy: 0.1079\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 0.5348 - accuracy: 0.0853 - val_loss: 0.3306 - val_accuracy: 0.1000\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 0.6926 - accuracy: 0.0963 - val_loss: 0.6865 - val_accuracy: 0.1001\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.3286 - accuracy: 0.1483 - val_loss: 0.3288 - val_accuracy: 0.1610\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3271 - accuracy: 0.1077 - val_loss: 0.3260 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.6860 - accuracy: 0.1121 - val_loss: 0.6854 - val_accuracy: 0.1000\n",
            "----------------CLIENT 4-------------------------\n",
            "13/13 [==============================] - 2s 88ms/step - loss: 1.0929 - accuracy: 0.1205 - val_loss: 0.4252 - val_accuracy: 0.1000\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.5247 - accuracy: 0.1070 - val_loss: 0.3536 - val_accuracy: 0.1003\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.6923 - accuracy: 0.1208 - val_loss: 0.6860 - val_accuracy: 0.1001\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3337 - accuracy: 0.1030 - val_loss: 0.3263 - val_accuracy: 0.1000\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3329 - accuracy: 0.1090 - val_loss: 0.3286 - val_accuracy: 0.1000\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6257 - accuracy: 0.1132 - val_loss: 0.5082 - val_accuracy: 0.1000\n",
            "----------------CLIENT 5-------------------------\n",
            "31/31 [==============================] - 2s 40ms/step - loss: 0.4518 - accuracy: 0.1017 - val_loss: 0.3294 - val_accuracy: 0.1311\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 861260.9036 - accuracy: 0.0910 - val_loss: 1.6914 - val_accuracy: 0.1000\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 0.6175 - accuracy: 0.0977 - val_loss: 0.3675 - val_accuracy: 0.0996\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3283 - accuracy: 0.1105 - val_loss: 0.3213 - val_accuracy: 0.1520\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3540 - accuracy: 0.1027 - val_loss: 0.3257 - val_accuracy: 0.1000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3350 - accuracy: 0.1296 - val_loss: 0.3299 - val_accuracy: 0.1378\n",
            "----------------CLIENT 6-------------------------\n",
            "111/111 [==============================] - 3s 19ms/step - loss: 0.6929 - accuracy: 0.0962 - val_loss: 0.6875 - val_accuracy: 0.1000\n",
            "111/111 [==============================] - 3s 18ms/step - loss: 0.6732 - accuracy: 0.0987 - val_loss: 0.5340 - val_accuracy: 0.1000\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4639 - accuracy: 0.1005 - val_loss: 0.3268 - val_accuracy: 0.1000\n",
            "28/28 [==============================] - 1s 44ms/step - loss: 0.6867 - accuracy: 0.1019 - val_loss: 0.6856 - val_accuracy: 0.1001\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 0.4867 - accuracy: 0.1008 - val_loss: 0.4317 - val_accuracy: 0.1000\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 0.3269 - accuracy: 0.0934 - val_loss: 0.3255 - val_accuracy: 0.1000\n",
            "----------------CLIENT 7-------------------------\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.6925 - accuracy: 0.1009 - val_loss: 0.6859 - val_accuracy: 0.1001\n",
            "136/136 [==============================] - 3s 15ms/step - loss: 0.3800 - accuracy: 0.0958 - val_loss: 0.3251 - val_accuracy: 0.1283\n",
            "136/136 [==============================] - 3s 15ms/step - loss: 0.4748 - accuracy: 0.0944 - val_loss: 0.3274 - val_accuracy: 0.1000\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.6849 - accuracy: 0.0980 - val_loss: 0.6836 - val_accuracy: 0.1001\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 0.3170 - accuracy: 0.1715 - val_loss: 0.3074 - val_accuracy: 0.2124\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 0.3268 - accuracy: 0.0985 - val_loss: 0.3258 - val_accuracy: 0.1000\n",
            "----------------CLIENT 8-------------------------\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 0.6870 - accuracy: 0.0986 - val_loss: 0.6612 - val_accuracy: 0.1000\n",
            "46/46 [==============================] - 2s 28ms/step - loss: 592607.3845 - accuracy: 0.1083 - val_loss: 0.3269 - val_accuracy: 0.1000\n",
            "46/46 [==============================] - 2s 26ms/step - loss: 0.4311 - accuracy: 0.1036 - val_loss: 0.3297 - val_accuracy: 0.1033\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 0.6556 - accuracy: 0.1033 - val_loss: 0.6474 - val_accuracy: 0.1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 11.8939 - accuracy: 0.1189 - val_loss: 0.3482 - val_accuracy: 0.1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 0.3318 - accuracy: 0.1209 - val_loss: 0.3299 - val_accuracy: 0.1000\n",
            "----------------CLIENT 9-------------------------\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 86006.8653 - accuracy: 0.0861 - val_loss: 0.3261 - val_accuracy: 0.1000\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 0.4316 - accuracy: 0.1158 - val_loss: 0.3265 - val_accuracy: 0.1762\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 0.6914 - accuracy: 0.0924 - val_loss: 0.6807 - val_accuracy: 0.1000\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.3261 - accuracy: 0.0891 - val_loss: 0.3253 - val_accuracy: 0.1000\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.3149 - accuracy: 0.1909 - val_loss: 0.3079 - val_accuracy: 0.2066\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.6766 - accuracy: 0.0945 - val_loss: 0.6717 - val_accuracy: 0.1000\n",
            "----------------CLIENT 10-------------------------\n",
            "56/56 [==============================] - 2s 25ms/step - loss: 0.6937 - accuracy: 0.0980 - val_loss: 0.6909 - val_accuracy: 0.0997\n",
            "56/56 [==============================] - 2s 20ms/step - loss: 0.5521 - accuracy: 0.0917 - val_loss: 0.3328 - val_accuracy: 0.1375\n",
            "56/56 [==============================] - 2s 20ms/step - loss: 0.4141 - accuracy: 0.1007 - val_loss: 0.3278 - val_accuracy: 0.1317\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.6832 - accuracy: 0.0964 - val_loss: 0.6743 - val_accuracy: 0.1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.3269 - accuracy: 0.1356 - val_loss: 0.3117 - val_accuracy: 0.1861\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.3152 - accuracy: 0.1750 - val_loss: 0.2810 - val_accuracy: 0.2898\n",
            "----------------CLIENT 11-------------------------\n",
            "124/124 [==============================] - 3s 19ms/step - loss: 0.3820 - accuracy: 0.1050 - val_loss: 0.3275 - val_accuracy: 0.1271\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.4741 - accuracy: 0.1018 - val_loss: 0.3297 - val_accuracy: 0.1510\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 195868.8898 - accuracy: 0.1108 - val_loss: 0.3263 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.3243 - accuracy: 0.1490 - val_loss: 0.3198 - val_accuracy: 0.1818\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3292 - accuracy: 0.1247 - val_loss: 0.3282 - val_accuracy: 0.1127\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3261 - accuracy: 0.1024 - val_loss: 0.3258 - val_accuracy: 0.1000\n",
            "----------------CLIENT 12-------------------------\n",
            "207/207 [==============================] - 3s 12ms/step - loss: 0.6915 - accuracy: 0.0994 - val_loss: 0.6809 - val_accuracy: 0.1001\n",
            "207/207 [==============================] - 3s 12ms/step - loss: 0.6318 - accuracy: 0.0961 - val_loss: 0.3373 - val_accuracy: 0.1173\n",
            "207/207 [==============================] - 3s 11ms/step - loss: 0.4177 - accuracy: 0.0894 - val_loss: 0.3315 - val_accuracy: 0.1000\n",
            "104/104 [==============================] - 2s 15ms/step - loss: 0.6769 - accuracy: 0.0955 - val_loss: 0.6721 - val_accuracy: 0.1000\n",
            "104/104 [==============================] - 2s 15ms/step - loss: 0.3335 - accuracy: 0.1228 - val_loss: 0.3312 - val_accuracy: 0.1254\n",
            "104/104 [==============================] - 2s 15ms/step - loss: 0.3275 - accuracy: 0.0894 - val_loss: 0.3265 - val_accuracy: 0.1000\n",
            "----------------CLIENT 13-------------------------\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 0.6932 - accuracy: 0.0979 - val_loss: 0.6884 - val_accuracy: 0.0999\n",
            "98/98 [==============================] - 3s 20ms/step - loss: 269877.5332 - accuracy: 0.1111 - val_loss: 0.3364 - val_accuracy: 0.1002\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 0.6771 - accuracy: 0.0955 - val_loss: 0.5751 - val_accuracy: 0.1000\n",
            "49/49 [==============================] - 2s 33ms/step - loss: 0.6870 - accuracy: 0.0938 - val_loss: 0.6852 - val_accuracy: 0.1001\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.3666 - accuracy: 0.0970 - val_loss: 0.3260 - val_accuracy: 0.1000\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.4971 - accuracy: 0.0938 - val_loss: 0.4047 - val_accuracy: 0.1000\n",
            "----------------CLIENT 14-------------------------\n",
            "122/122 [==============================] - 2s 15ms/step - loss: 0.4725 - accuracy: 0.1104 - val_loss: 0.3277 - val_accuracy: 0.1365\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6930 - accuracy: 0.0878 - val_loss: 0.6866 - val_accuracy: 0.1000\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.4782 - accuracy: 0.0956 - val_loss: 0.3274 - val_accuracy: 0.1000\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3260 - accuracy: 0.1564 - val_loss: 0.3224 - val_accuracy: 0.1390\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.6846 - accuracy: 0.0941 - val_loss: 0.6822 - val_accuracy: 0.1001\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.3264 - accuracy: 0.0933 - val_loss: 0.3257 - val_accuracy: 0.1000\n",
            "----------------CLIENT 15-------------------------\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4636 - accuracy: 0.0987 - val_loss: 0.3305 - val_accuracy: 0.1343\n",
            "27/27 [==============================] - 2s 33ms/step - loss: 0.6901 - accuracy: 0.0988 - val_loss: 0.6767 - val_accuracy: 0.1000\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 1140803.6353 - accuracy: 0.0964 - val_loss: 0.3391 - val_accuracy: 0.1000\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3288 - accuracy: 0.1187 - val_loss: 0.3252 - val_accuracy: 0.1369\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6483 - accuracy: 0.1010 - val_loss: 0.6050 - val_accuracy: 0.1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 7.2688 - accuracy: 0.1013 - val_loss: 0.6599 - val_accuracy: 0.1000\n",
            "----------------CLIENT 16-------------------------\n",
            "119/119 [==============================] - 3s 18ms/step - loss: 0.3847 - accuracy: 0.1133 - val_loss: 0.3281 - val_accuracy: 0.1021\n",
            "119/119 [==============================] - 3s 17ms/step - loss: 0.5091 - accuracy: 0.0966 - val_loss: 0.3286 - val_accuracy: 0.1000\n",
            "119/119 [==============================] - 3s 17ms/step - loss: 0.6929 - accuracy: 0.0838 - val_loss: 0.6871 - val_accuracy: 0.1000\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.3263 - accuracy: 0.1071 - val_loss: 0.3236 - val_accuracy: 0.1253\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.3266 - accuracy: 0.0992 - val_loss: 0.3264 - val_accuracy: 0.1000\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.6862 - accuracy: 0.0902 - val_loss: 0.6851 - val_accuracy: 0.1002\n",
            "----------------CLIENT 17-------------------------\n",
            "221/221 [==============================] - 3s 12ms/step - loss: 0.4288 - accuracy: 0.1047 - val_loss: 0.3274 - val_accuracy: 0.1590\n",
            "221/221 [==============================] - 3s 11ms/step - loss: 0.4145 - accuracy: 0.1046 - val_loss: 0.3272 - val_accuracy: 0.1000\n",
            "221/221 [==============================] - 3s 11ms/step - loss: 0.6912 - accuracy: 0.0989 - val_loss: 0.6798 - val_accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 21ms/step - loss: 0.3202 - accuracy: 0.1859 - val_loss: 0.3076 - val_accuracy: 0.2312\n",
            "56/56 [==============================] - 1s 20ms/step - loss: 0.3257 - accuracy: 0.1001 - val_loss: 0.3260 - val_accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 21ms/step - loss: 0.6778 - accuracy: 0.0950 - val_loss: 0.6752 - val_accuracy: 0.1000\n",
            "----------------CLIENT 18-------------------------\n",
            "27/27 [==============================] - 2s 41ms/step - loss: 0.6943 - accuracy: 0.1068 - val_loss: 0.6928 - val_accuracy: 0.0997\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 1244397.7112 - accuracy: 0.0962 - val_loss: 0.3323 - val_accuracy: 0.1000\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.6298 - accuracy: 0.0992 - val_loss: 0.3642 - val_accuracy: 0.0993\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.6911 - accuracy: 0.1079 - val_loss: 0.6893 - val_accuracy: 0.0998\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.3259 - accuracy: 0.1046 - val_loss: 0.3254 - val_accuracy: 0.1000\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 0.3377 - accuracy: 0.1097 - val_loss: 0.3305 - val_accuracy: 0.1042\n",
            "----------------CLIENT 19-------------------------\n",
            "16/16 [==============================] - 2s 65ms/step - loss: 0.9576 - accuracy: 0.1028 - val_loss: 0.3387 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 1398641.7100 - accuracy: 0.1079 - val_loss: 0.3849 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.6920 - accuracy: 0.1150 - val_loss: 0.6841 - val_accuracy: 0.1000\n",
            "124/124 [==============================] - 2s 18ms/step - loss: 0.3311 - accuracy: 0.0950 - val_loss: 0.3277 - val_accuracy: 0.1000\n",
            "124/124 [==============================] - 2s 18ms/step - loss: 0.3339 - accuracy: 0.0980 - val_loss: 0.3255 - val_accuracy: 0.1000\n",
            "124/124 [==============================] - 2s 18ms/step - loss: 0.5939 - accuracy: 0.1066 - val_loss: 0.4231 - val_accuracy: 0.1000\n",
            "----------------CLIENT 20-------------------------\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 0.4316 - accuracy: 0.1011 - val_loss: 0.3268 - val_accuracy: 0.1374\n",
            "209/209 [==============================] - 3s 12ms/step - loss: 187093.5091 - accuracy: 0.0978 - val_loss: 0.3351 - val_accuracy: 0.1000\n",
            "209/209 [==============================] - 3s 11ms/step - loss: 0.6912 - accuracy: 0.1066 - val_loss: 0.6807 - val_accuracy: 0.1000\n",
            "53/53 [==============================] - 1s 22ms/step - loss: 0.3228 - accuracy: 0.1930 - val_loss: 0.3197 - val_accuracy: 0.2191\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 0.3302 - accuracy: 0.1048 - val_loss: 0.3257 - val_accuracy: 0.1000\n",
            "53/53 [==============================] - 1s 21ms/step - loss: 0.6788 - accuracy: 0.1057 - val_loss: 0.6765 - val_accuracy: 0.1000\n",
            "----------------CLIENT 21-------------------------\n",
            "40/40 [==============================] - 2s 31ms/step - loss: 0.5900 - accuracy: 0.1081 - val_loss: 0.3364 - val_accuracy: 0.1200\n",
            "40/40 [==============================] - 2s 25ms/step - loss: 0.4324 - accuracy: 0.0973 - val_loss: 0.3284 - val_accuracy: 0.1083\n",
            "40/40 [==============================] - 2s 26ms/step - loss: 0.6881 - accuracy: 0.0992 - val_loss: 0.6664 - val_accuracy: 0.1000\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.3362 - accuracy: 0.1123 - val_loss: 0.3326 - val_accuracy: 0.1398\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.3278 - accuracy: 0.1296 - val_loss: 0.3266 - val_accuracy: 0.1606\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.6568 - accuracy: 0.1009 - val_loss: 0.6436 - val_accuracy: 0.1000\n",
            "----------------CLIENT 22-------------------------\n",
            "16/16 [==============================] - 1s 63ms/step - loss: 0.6667 - accuracy: 0.0979 - val_loss: 0.5101 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.9460 - accuracy: 0.1018 - val_loss: 0.3357 - val_accuracy: 0.1000\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 1404428.6585 - accuracy: 0.1252 - val_loss: 0.7155 - val_accuracy: 0.1000\n",
            "122/122 [==============================] - 2s 18ms/step - loss: 0.3434 - accuracy: 0.1226 - val_loss: 0.3293 - val_accuracy: 0.1433\n",
            "122/122 [==============================] - 2s 18ms/step - loss: 0.3301 - accuracy: 0.1030 - val_loss: 0.3295 - val_accuracy: 0.1000\n",
            "122/122 [==============================] - 2s 18ms/step - loss: 0.3300 - accuracy: 0.0989 - val_loss: 0.3255 - val_accuracy: 0.1000\n",
            "----------------CLIENT 23-------------------------\n",
            "18/18 [==============================] - 2s 66ms/step - loss: 0.8823 - accuracy: 0.1053 - val_loss: 0.3349 - val_accuracy: 0.1000\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.4997 - accuracy: 0.0979 - val_loss: 0.3461 - val_accuracy: 0.1005\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.6944 - accuracy: 0.1007 - val_loss: 0.6934 - val_accuracy: 0.0997\n",
            "141/141 [==============================] - 2s 17ms/step - loss: 0.3312 - accuracy: 0.1044 - val_loss: 0.3271 - val_accuracy: 0.1000\n",
            "141/141 [==============================] - 2s 16ms/step - loss: 0.3287 - accuracy: 0.1378 - val_loss: 0.3177 - val_accuracy: 0.1706\n",
            "141/141 [==============================] - 2s 16ms/step - loss: 0.6890 - accuracy: 0.0963 - val_loss: 0.6842 - val_accuracy: 0.1001\n",
            "----------------CLIENT 24-------------------------\n",
            "22/22 [==============================] - 2s 52ms/step - loss: 0.6942 - accuracy: 0.1026 - val_loss: 0.6932 - val_accuracy: 0.0997\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.8613 - accuracy: 0.1021 - val_loss: 0.3377 - val_accuracy: 0.1000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: 1226183.1213 - accuracy: 0.0924 - val_loss: 12.2463 - val_accuracy: 0.1000\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.6904 - accuracy: 0.1046 - val_loss: 0.6875 - val_accuracy: 0.1000\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.3294 - accuracy: 0.1061 - val_loss: 0.3315 - val_accuracy: 0.1000\n",
            "85/85 [==============================] - 1s 16ms/step - loss: 1.5487 - accuracy: 0.0924 - val_loss: 0.3256 - val_accuracy: 0.1000\n",
            "----------------CLIENT 25-------------------------\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.4718 - accuracy: 0.0984 - val_loss: 0.3304 - val_accuracy: 0.1273\n",
            "123/123 [==============================] - 2s 13ms/step - loss: 0.3769 - accuracy: 0.1158 - val_loss: 0.3091 - val_accuracy: 0.1965\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.6927 - accuracy: 0.0946 - val_loss: 0.6866 - val_accuracy: 0.1000\n",
            "31/31 [==============================] - 1s 38ms/step - loss: 0.3270 - accuracy: 0.1597 - val_loss: 0.3259 - val_accuracy: 0.1589\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 0.2934 - accuracy: 0.2606 - val_loss: 0.2860 - val_accuracy: 0.2897\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 0.6857 - accuracy: 0.0935 - val_loss: 0.6844 - val_accuracy: 0.1001\n",
            "----------------CLIENT 26-------------------------\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5490 - accuracy: 0.1024 - val_loss: 0.3264 - val_accuracy: 0.1000\n",
            "80/80 [==============================] - 2s 17ms/step - loss: 273323.7174 - accuracy: 0.1015 - val_loss: 0.3274 - val_accuracy: 0.1000\n",
            "80/80 [==============================] - 2s 17ms/step - loss: 0.3944 - accuracy: 0.1083 - val_loss: 0.3286 - val_accuracy: 0.1128\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.3268 - accuracy: 0.0963 - val_loss: 0.3260 - val_accuracy: 0.1000\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.3268 - accuracy: 0.1049 - val_loss: 0.3257 - val_accuracy: 0.1000\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.3261 - accuracy: 0.1097 - val_loss: 0.3254 - val_accuracy: 0.1361\n",
            "----------------CLIENT 27-------------------------\n",
            "44/44 [==============================] - 2s 28ms/step - loss: 591421.7002 - accuracy: 0.1083 - val_loss: 0.3544 - val_accuracy: 0.1000\n",
            "44/44 [==============================] - 2s 28ms/step - loss: 0.6490 - accuracy: 0.1033 - val_loss: 0.3368 - val_accuracy: 0.1000\n",
            "44/44 [==============================] - 2s 29ms/step - loss: 0.6874 - accuracy: 0.1263 - val_loss: 0.6632 - val_accuracy: 0.1000\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.3354 - accuracy: 0.1074 - val_loss: 0.3264 - val_accuracy: 0.1000\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.3300 - accuracy: 0.0830 - val_loss: 0.3273 - val_accuracy: 0.1000\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.6514 - accuracy: 0.1217 - val_loss: 0.6359 - val_accuracy: 0.1000\n",
            "----------------CLIENT 28-------------------------\n",
            "50/50 [==============================] - 2s 25ms/step - loss: 0.6488 - accuracy: 0.1055 - val_loss: 0.3279 - val_accuracy: 0.1000\n",
            "50/50 [==============================] - 2s 21ms/step - loss: 0.5650 - accuracy: 0.0975 - val_loss: 0.3329 - val_accuracy: 0.1061\n",
            "50/50 [==============================] - 2s 21ms/step - loss: 0.4207 - accuracy: 0.0891 - val_loss: 0.3294 - val_accuracy: 0.1000\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.3295 - accuracy: 0.0928 - val_loss: 0.3261 - val_accuracy: 0.1000\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.3297 - accuracy: 0.1389 - val_loss: 0.3227 - val_accuracy: 0.1506\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.3134 - accuracy: 0.1723 - val_loss: 0.2857 - val_accuracy: 0.2639\n",
            "----------------CLIENT 29-------------------------\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.6848 - accuracy: 0.0998 - val_loss: 0.6462 - val_accuracy: 0.1000\n",
            "58/58 [==============================] - 2s 19ms/step - loss: 0.4142 - accuracy: 0.1046 - val_loss: 0.3280 - val_accuracy: 0.1330\n",
            "58/58 [==============================] - 2s 20ms/step - loss: 0.5484 - accuracy: 0.0987 - val_loss: 0.3334 - val_accuracy: 0.1091\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.4964 - accuracy: 0.0974 - val_loss: 0.3436 - val_accuracy: 0.0989\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.3163 - accuracy: 0.1743 - val_loss: 0.2874 - val_accuracy: 0.2832\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.3290 - accuracy: 0.1365 - val_loss: 0.3263 - val_accuracy: 0.1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PB6ZV6dDWsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c849a34d-7286-47d4-b841-c1b868a98105"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3027 - accuracy: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3027024269104004, 0.10000000149011612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKNPHQV5Aj1"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI01x0RMlj9r"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "batches = np.int32(np.round(2**((np.random.random([NUM_CLIENTS])*3)+4)))\n",
        "lr_init = 10.0**((np.random.random([NUM_CLIENTS])*-4)-3)\n",
        "lr_init1 = np.reshape(lr_init, (-1,1))\n",
        "batches1 = np.reshape(batches, (-1,1))\n",
        "#print(lr_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYrFCumBCsyr",
        "outputId": "4ca688ec-b82c-445e-b292-58ffdb7b02f3"
      },
      "source": [
        "model = DBSCAN(eps=0.15, min_samples=2)\n",
        "print(np.concatenate(((np.log10(lr_init1)+3)/-4, (np.log2(batches1)-4)/3), axis=1))\n",
        "yhat = model.fit_predict(np.concatenate(((np.log10(lr_init1)-3)/4, (np.log2(batches1)-4)/3), axis=1))\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.69568846 0.80875492]\n",
            " [0.54016461 0.25162917]\n",
            " [0.25779074 0.95266033]\n",
            " [0.28652048 0.72330833]\n",
            " [0.45760921 0.17452065]\n",
            " [0.13700122 0.94005965]\n",
            " [0.60224679 0.5849625 ]\n",
            " [0.10567388 0.1949875 ]\n",
            " [0.46188454 0.0826425 ]\n",
            " [0.35230021 0.95678824]\n",
            " [0.09890151 0.88607049]\n",
            " [0.2092136  1.        ]\n",
            " [0.2354596  0.89080845]\n",
            " [0.37927    0.40315112]\n",
            " [0.33928977 0.6886964 ]\n",
            " [0.73606673 0.9271199 ]\n",
            " [0.82561768 0.71658237]\n",
            " [0.89765071 0.5849625 ]\n",
            " [0.0121459  0.05664167]\n",
            " [0.03983547 0.71658237]\n",
            " [0.56858895 0.89080845]\n",
            " [0.65552396 0.36248761]\n",
            " [0.68109916 0.        ]\n",
            " [0.812996   0.48647721]\n",
            " [0.14000248 0.72994152]\n",
            " [0.84914537 0.64357911]\n",
            " [0.61788191 0.88607049]\n",
            " [0.17005203 0.25162917]\n",
            " [0.09215617 0.23347991]\n",
            " [0.59470303 0.49728437]]\n",
            "[ 0  1  2  3  1  2  4  5  1  2  2  2  2 -1  3  0  6  6 -1  3  0  4 -1  6\n",
            "  3  6  0  5  5  4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "5U0-HWHZCi5f",
        "outputId": "89984972-93e4-41fd-89a7-ec503c4d1511"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(np.log2(batches), np.log10(lr_init), c=yhat, cmap=\"jet\")\n",
        "plt.xlabel(\"Batch Size\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.savefig(\"Cluster.png\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1fnH8c+TjYSEVSAugCyKGy6FKIpWiaXUulGrtVp3f5RqtavW1qq1tba1rV1+tZuI289qqdZa0eIu1LoiUFBUVPZVBEEgIWR9fn/cCWS5SYYk907uvd/36zWv3Dkz985zmHCfnDMz55i7IyIi0pasqAMQEZHUoIQhIiKhKGGIiEgoShgiIhKKEoaIiISSE3UAidCvXz8fMmRIo7Ly8nIKCwujCSiBVK/Uko71Ssc6QebVa+7cuRvdvX9r703LhDFkyBDmzJnTqGzWrFmMGzcumoASSPVKLelYr3SsE2RevcxsRVvvVZeUiIiEElnCMLMfm9kbZjbfzJ42s71b2O8iM3s/WC5KdpwiIhITZQvjl+5+mLsfATwO/KDpDmbWF7gRGAMcBdxoZn2SG6aIiECECcPdtzZYLQTijVHyGeAZd9/k7puBZ4CTkhGfiIg0ZlGOJWVmPwEuBLYApe6+ocn2q4F8d785WL8BqHD3W+N81mRgMkBxcfHoadOmNdpeVlZGUVFRQuoRJdUrtSSrXttrwR0Kk3Bbi85VammpXqWlpXPdvaS19yb018nMngX2jLPpOnd/1N2vA64zs2uBK4l1P7WLu08BpgCUlJR407sAMu2Oh1SnerXPaxvhjBdgWw0YkJcFDx4HJ8b7X9hJdK5SS0fqldCE4e7jQ+56PzCD5gljDTCuwfpAYFaHAxNJQ9uqYcJM2FrduPz0f8PSiTAgP5q4JH1EeZfU/g1WJwKL4uz2FDDBzPoEF7snBGUi0sQjq6AuTg9zLfDA8mRHI+koyrukbjGzhWb2BrFE8A0AMysxs6kA7r4J+DHwerDcFJSJSBMbK6Gqrnn5jlr4cEfy45H2qatz/vjH1znooD8wcOCvufzyx1m/vizqsIAIn/R29zNbKJ8DTGqwfhdwV7LiEklV44ohx6CqSXlRDnwqgdcwpHN9+cuPMW3aQrZvj/Ut3nnnf5k+/T3eeuur9O4dbb+invTORHWVsO5+eOdKWPE7qN4cdUSRm7kejnoSih6Egx6Hv6+MOqLdN6ovnL4PFGbvKivMhmP7w4nF0cUl4a1Y8TEPPPDGzmQBUF1dx+bNFUydOi/CyGLSciwpaUX1Jnh1DFR9ALVlkNUdlvwAjvwP9Dg06ugiMXM9nDILKmpj64u2wkWvQFk1XDw80tB22/3Hwl+Xw9QlUOtw8TC4cCiYRR2ZhDFv3jry8nLYsaO2UXlFRQ2zZi3n6qvHRhRZjBJGpln8A9ixAjz4C6ZuO9QBCy+EY/4baWhR+e5/dyWLettr4XsL4KJhqfVlm2Vw3tDYIqln0KBe1NY2vxCVm5vFfvv1jSCixtQllWnW/31Xsmio7O1Y6yMDvb01fvmmytjzDNJ+22vg9+/C+Ofg3JfgpQ1tvyeTjR69F/vv35ecnMZfzbm52VxxxZERRbWLEkamsZYald7KtvQ2uHv88u45ja8HyO4pr4Ejn4Tvzofn1sPfVsCE5+GP70UdWddlZjz99AWceOIQ8vKyKSjIYfDgXjz22Lnsv/8eUYenLqmMs/clsOJWqGtwn6VlQ+9jIadndHFF6MeHwYWvxLqh6nXPhu8eDNn6k6rd7lwCy8t3/bs6sddX/xcuGAo9ciMNr8vq37+Qp566gE2bKigvr2LgwJ5YF+kX1X+HTDPsOug1BrILISsfsntAt4Fw6H1RRxaZMwfDH0qgOD92W2qvXLhuJHzv4KgjS23/WNU4CdfLzYLXPkp+PKmmb98CBg3q1WWSBaiFkXmy86FkJmx5FbbOg4IhsMdnICuzfxUuHh67wF1eE+uKyuo6/0dTVv9u8ctrHfrkJTcW6RyZ/S2Rqcyg9zGxRXYygyJ1k3SaK0fAjLWNWxlZwN75MEqz2qQkdUmJSEKcUAw3Hwb52bFuvqIcGFoET5Sm1q3KsotaGCKSMN86CC4dDq9uhL7doKSvkkUqU8IQkYTqlQef2TvqKKQzqEtKRERCUcIQEZFQlDBERCQUXcMQSbB5m2Ij4u7RDQbHmRFPJFUoYYgkSJ3Dl16Cx9ZAjceecL45F7pvhKP7RR2dyO6LpEvKzH5sZm+Y2Xwze9rM4t5DYWa1wT7zzWx6suMU6Yi/LofH18QeXKuqiz1FXutwxgvx594W6eqiuobxS3c/zN2PAB4HftDCfhXufkSwnJ7E+EQ67M6lUB5nLKXyGpibmSPJS4qLJGG4e8MZCAqJDWQpklbizIOza5t+4yUFRXaXlJn9xMxWAefRcgsj38zmmNmrZva5JIYn0mEXDYs/n0ZeVuyJZ5FUY+6J+VPHzJ4F9oyz6Tp3f7TBftcC+e5+Y5zP2Mfd15jZMOB54FPuvqSF400GJgMUFxePnjZtWqPtZWVlFBUVtbs+XZXq1bW9vw3KamLXLMxgoJVRUFREjzS63SRdzlVTmVav0tLSue5e0tp7E5YwwjKzwcAMdx/Zxn73AI+7+9/b+sySkhKfM2dOo7JZs2Yxbty4DkTaNaleXZt77Jba59fHhvs+ZN0sxpeOizqsTpUu56qpTKuXmbWZMCL5O8fM9nf394PVicCiOPv0Aba7e6WZ9QOOBX6RxDBFOswMTtwztgDM+iDaeEQ6IqqG8S1mdgBQB6wALgMwsxLgMnefBBwE3G5mdcSutdzi7m9HFK+ISMaLJGG4+5ktlM8BJgWvXwYOTWZcIiLSMo0lJSIioShhiIhIKEoYIiISihKGiIiEooSR7io/gLK3oK4q6khEJMWl0fOm0kj1ZnjjXNg8CywXLBsO+C3sc3HUkYlIilILI13NPws2zYS6Sqgtg5ot8M4VsOmFqCMTkRSlhJGOKlbClpfBm3RD1W2H5XpYXkTaRwkjHVV9AJYXf9uOVcmNRUTShhJGOio8BLymebnlwh6fTn48IpIWlDDSUU4h7PcjyOq+q8xyIKcXDLk6urhEJKXpLql0NeRq6D4Clt8Kleug30kw9FroFm+KEhGRtilhpLMBp8cWEZFOoC4pEREJRQlDRERCUcIQEZFQlDBERCQUJQyRDnpvK3zhPzDgYRj5L/jLMnCPOiqRzhd5wjCzq8zMzaxfC9svMrP3g+WiZMcn0pplZXDkU/CPVbChEt7aApfNhpsWRh2ZSOeLNGGY2SBgArCyhe19gRuBMcBRwI1m1id5EYq07icLobwG6hqUldfCz9+GsurIwhJJiKhbGL8BrgFaasB/BnjG3Te5+2bgGeCkZAXXVNkHH/D+jBmsf+ONqEKQLubljVAb57c3Nwve25b8eEQSyTyizlYzmwic6O7fMLPlQIm7b2yyz9VAvrvfHKzfAFS4+61xPm8yMBmguLh49LRp0xptLysro6ioqN3xbl21ivING7CsLHAnJz+fvvvvT1ZOtM8+drReXVWq1GtxGWyJMzeVGRzWG3KscXmq1Gt3pGOdIPPqVVpaOtfdS1p7b0K/7czsWSDeWBTXAd8n1h3VKdx9CjAFoKSkxMeNG9do+6xZs2haFtb8e+7h5SuvpLq8fGdZVm4u+x5/PBc++2x7Q+4UHalXV5Yq9crbAJ9+HrbX7irLz4ZT9oZvf7L5/qlSr92RjnUC1SuehHZJuft4dx/ZdAGWAkOBBUHrYiAwz8yaJpc1wKAG6wODsqR69be/bZQsAOqqq1n54ouUb9iQ7HCkCxnbH/7vGNgzP5YoumXB2YNjZSLpJpL+FHd/ExhQv95SlxTwFPDTBhe6JwDXJiXIBnZ8/HHc8qzsbKq2baOwf/8kRyRdyZmD4YxB8EEF9MqDQo3QJmkq6ovezZhZiZlNBXD3TcCPgdeD5aagLKlGnHYaWbm5zcq79exJ7yFDkh2OdEFZBnt3V7KQ9NYlEoa7D6lvXbj7HHef1GDbXe6+X7DcHUV8x19/Pd379SOnoAAAy84mt3t3Tps6NXYRXEQkA+jvoRCKiov56sKFzLn9dpY99xx9hg1jzNe/zoCRI6MOTUQkaZQwQiro25dPXnstn7w26ZdQRES6BPWniIhIKEoYIiISihKGiEgKq6mBX/4Ohh4O/feHS66EtesScyxdwxARaeCdd2HDR1BX1/a+XcEFl8H0J2B7RWz9Lw/Ck8/BO69C716deyy1MEREgHUfwCdOgJIT4fRzYcFC+O2foo6qdYuXwj9n7EoWEGtxbNkKU+/r/OMpYYiIAKd9Cd58O/blu2VbrIVx/U/guX9HHVnL/vsG5DV/ppiKCvjPK51/PCUMEcl47y2Gt9+F2trG5eXb4TcttDI2fwxLlzd/TzIN3Tf+8fNy4cD9O/94ShhdxMZ33+WRCy/kDwcdxN/OOIO1c+ZEHZJIxvhoE+S2cEV3/YeN17duhc+dD3sdCIceC3sMg1/eFs20vKOPgBH7QdORi3Jz4fJLO/94ShhdwAcLFnBHSQlvPvAAGxctYtGjj3LPCSew+Kmnog5NJCMcPjL+X+r5+XBakynbvnAJPPksVFbt6r665kYYfCi8+35y4q1nBs/8A076VKxVkZcXSyBPPwxDBnf+8ZQwuoCnr7qKqrIyvP431p3q7duZccUV0QYmkiG6d4dbfxz7Wc+yoLgffG3yrrKVq+GFV2LJoqnVa6H09OR3Ue3RF6Y/AB8tgdUL4d3ZMHZMYo7VZsIwsxFm9pyZLQzWDzOz6xMTTmZa89prccu3rFhBVVlZkqMRyUyXXQJPPAifOwXGjIa9imH+f6BP7137rF0H3fJa/oyy7dFdJC8qgv79EnuMMC2MO4jNQVEN4O5vAOckMqhMU9C3b9zyrNxccvLzkxyNSOY6fiw8ch+8+kwsYTR9juHgA+K3LnZy2Jj0CRiSJ0zC6O7us5uU1SQimEw19jvfIbdhWxjIKShg1KRJkc8ZLtIRdXWx/v5vXgs33xrr0kllPXvC977Zciujuho+eXRyY0qmMN9GG81sOOAAZnYWkKAHzzPTkVdcwZaVK5l9221k5+VRU1XFwWedxYRbb406NJF2q6mBU74IL8+GsvLYBdmf/Qam3dn8QnIq+cF3YPi+MPlbULFjV3lhd/jKxTBoYGShJVyYhHEFMAU40MzWAMuA8xIaVYYxMz79i19w/PXXs2nxYnoNHkz3fgnujBRJsPsfgpdeiz3LAFBVBVXA+V+BD9+Dbt0iDa/dzOD8L8KZp8OUe+GvD0OPIrhiEkw8OeroEitMwnB3H29mhUCWu28zs6GJDiwTdevZk71GjYo6DJFO8ZcHdyWLpl55HcYdl9x4OltBAXzjstiSKcJcw3gYwN3L3X1bUPb3zji4mV1lZm5mcf+cNrNaM5sfLNM745gikhx5LfTzu8cfzkK6vhZbGGZ2IHAI0MvMPt9gU0+gw7fumNkgYAKwspXdKtz9iI4eS0SS78sXwr9fhvLyxuUFBTCmJJqYpGNa65I6ADgV6A2c1qB8G/DlTjj2b4BrgEc74bNEpIuZeDJccDbc+1fAICcbsrLgsQcgOzvq6KQ9zNsYAMXMjnH3Th330MwmAie6+zfMbDlQ4u4b4+xXA8wndhvvLe7+z1Y+czIwGaC4uHj0tGnTGm0vKyujqKio8yrRRaheqSUd69VWnXZUwrZtkJMDvXrGkkYqSMdzBS3Xq7S0dK67t972c/dWF2LdT1cAfwTuql9CvO9ZYGGcZSLwGtAr2G850K+Fz9gn+Dks2G94W8d1d0aPHu1NzZw5s1lZOlC9Uks61isd6+SeefUC5ngb361hcv19wJ7AZ4B/AwOJdUu1lYjGu/vIpguwFBgKLAhaFwOBeWa2Z5zPWBP8XArMAj4RIl4RkS5r/YewZFnqzOjXUJiEsZ+73wCUu/u9wClAu4e2cvc33X2Auw9x9yHAamCUu3/QcD8z62Nm3YLX/YBjgbfbe1wRkSit+wCOPwX2PRwO+yQMGglPPx91VLsnTMKoDn5+bGYjgV7AgEQEY2YlZjY1WD0ImGNmC4CZxK5hKGGISMpxh/FnxJ4/qayE7dth7QdwxgXw/pKoowsvzIN7U8ysD3A9MB0oAm7orACCVkb96znApOD1y8ChnXUcEZGozJ4LK1bHhktpqLoG/ngn/Oan0cS1u9pMGO5e/xf/C8QuPmNmCZiaQ0QkPa1ZB9lx+nOqq2HJ8qSH026tdkmZ2TFmdpaZDQjWDzOzB4CXkhKdiEgaKPlEbCytproXwPgTkh9Pe7WYMMzsl8RuoT0T+JeZ3Qw8TeyW2ARMLy4ikp4GD4QLz2k8o19eHvTbAy75UnRx7a7WuqROAT7h7juCaxirgJHuvjwpkXVB7k7Fpk1069GD7JYGyhERieNPv4IjR8FtU2IPMp5xKlz7LejRI+rIwmstYexw9x0A7r7ZzN7P5GTx1oMP8uQ3v0nFpk1YVhajJk1iwq9+RXauRlETkbZlZcGkC2JLqmotYQxrMkLs0Ibr7n564sLqWpY9/zyPXnIJ1dt3jdU8b+pUaquqOPXPf44wMhGR5GktYUxssv6rRAbSlf37ppsaJQuAmooKFtx7L5/+5S/plkptShGRdmoxYbj7v5MZSFe2eenSuOVZOTmUr1+vhCEiGSFFxo2M1t4lJbF5GePoOWhQkqMREYmGEkYIpTfdRG7D++GA3O7dOf6GG8hJ1YmJRUR2kxJGCANGjuTSF19k+IQJ5PfuTb8DD+TU22/n2GuuiTo0EZGkaXNoEDN7DGg6y9IWYA5we/2tt+luzyOO4Pynnoo6DBGRyIRpYSwFyoA7gmUrsfkwRgTrIiKSAcKMVjvW3Y9ssP6Ymb3u7kea2VuJCkxEpN6atfDIv6C2NjZX+BANfxqJMC2Mooaj0wav6yeEjTOclohI57nrL7BfCVxzI3zvR3DQ0fCr30cdVWYK08K4CnjRzJYARmx61a+aWSFwbyKDE5HMtnYdXHEN7GhypfSGn8IpE+DAEdHElanCzIcxw8z2Bw4Mit5tcKH7twmLTEQy3j9nxH8EqroGHnoUbvhO8mPKZGFvqx0NHAIcDpxtZhd25KBm9kMzW2Nm84Pl5Bb2O8nM3jWzxWb2vY4cU0RST11dbHrTptxj2yS52kwYZnYfcCtwHHBksJR0wrF/4+5HBMuMOMfNBv4AfBY4GDjXzA7uhOOKSIo4/bPxy/Py4MzTkhuLhLuGUQIc7B4vzyfUUcBid18KYGbTiA2I+HaS4xCRiAweCLf8AL53U2w+bPdYsvjOlTBSfz4mnbWVB8zsIeDr7r6u0w5q9kPgYmLPdMwBrnL3zU32OQs4yd0nBesXAGPc/coWPnMyMBmguLh49LRp0xptLysro6ioKN5bU5rqlVrSsV7JqFNlJWz+OPYEcZ9ekJ+f0MMB6XmuoOV6lZaWznX3VnuPwrQw+gFvm9lsoLK+sK35MMzsWWDPOJuuA/4E/JjY+f8xsaHTLw0RS4vcfQowBaCkpMTHjRvXaPusWbNoWpYOVK/Uko71Ssc6geoVT5iE8cP2fLC7jw+zn5ndATweZ9MaoOFQsAODMhERiUCY22o7fV4MM9urQRfXGcDCOLu9DuxvZkOJJYpzgBSaLl1EJL20mDDM7EV3P87MttF48EED3N17duC4vzCzI4LPXQ58JTjm3sBUdz/Z3WvM7ErgKSAbuMvdNRSJiEhEWptx77jgZ6dPJ+fucadBd/e1wMkN1mcAzW65FRGR5AtzDaP+mYjihvu7+8pEBSUiIl1PmPkwvgbcCKwH6p+tdOCwBMYlIiJdTJgWxjeAA9z9o0QHIyIiXVeYsaRWEZthT0REMliYFsZSYJaZ/YvGD+79OmFRiYhIlxMmYawMlrxgERGRDNRqwgjujhrh7uclKR4REemiWr2G4e61wL5mppaFiEiGC3sN4yUzmw6U1xfqGoaISGYJkzCWBEsW0OlPfYuISGoIM/jgj5IRiIiIdG1hnvTuD1xDbE7vndOWuPuJCYxLmnj99TU8//wy+vYt4KyzDqZPn4KoQxKRDBOmS+p+4G/AqcBlwEXAhkQGJbvU1Tnnnfcwjz32Hjt21NCtWw7f/vbT/OtfX+L44/eNOjwRySBhnvTew93vBKrd/d/ufimg1kWSPPjgWzz22HuUl1dTW+ts315NWVkVn//836ipqWv7A0REOkmYFkZ18HOdmZ0CrAX6Ji4kaejuu+dTXl7drLyqqpbXXlsdQUQikqnCJIybzawXcBVwG9AT+FZCo5Kd3D1uuZnRwiYRkYRos0vK3R939y3uvtDdS919tLtPT0ZwAhdddDiFhbnNynNysjj66IERRCQimarNhGFmI8zsOTNbGKwfZmbXJz40ATjnnJFMmDCcwsJczKCgIIfCwlweeugL5OSEuQQlItI5wnRJ3QF8B7gdwN3fMLMHgJvbe1Az+yHwZXbdbfX9YDrWpvstB7YBtUCNu5e095ipKjs7i4cfPpuXX17Fc88tY489CvjiF0fSr1/3qEMTkQwTJmF0d/fZZtawrKYTjv0bd781xH6l7r6xE46XssyMY48dzLHHDo46FBHJYGH6NDaa2XBi07JiZmcB6xIalYiIdDnW0l04O3cwGwZMAcYCm4FlwHnuvqLdB411SV0MbAXmAFe5++Y4+y0LjunA7e4+pZXPnAxMBiguLh49bdq0RtvLysooKipqb8hdluqVWtKxXulYJ8i8epWWls5ts9vf3UMtQCHQI3j9zRD7PwssjLNMBIqBbGItnJ8Ad7XwGfsEPwcAC4Djw8Q6evRob2rmzJnNytKB6pVakl2vxYs/8ttue83vvHOeb9q0PSHH0LlKLS3VC5jjbXy3hrmGUZ9Yyhusfhv4bRv7jw/zuWZ2B/B4C5+xJvj5oZk9AhwFvBAqYJEMd8MNz3Prra9gBllZxte+9gQPPfQFTj55/6hDkxTV3vsyre1dWnmz2V4NVs8g1vJouk+hmfWofw1MiLefpBd3Z8mSTVRXa9iTjnjllVX8+tevsmNHDRUVNZSXV7N9ezVnn/0QZWVVUYcnKaq9CaOjzxj/wszeNLM3gFKCJ8fNbG8zq7+9thh40cwWALOBf7n7kx08rnRhL7ywgn33/S2HHfZn3nxzPWPGTGXlyi1Rh5WS7r13ARUVzYeUycoynnpqcQQRSTposUvKzLYRPzEY0KGxtd39ghbK1wInB6+XAod35DiSOlat2sLJJ9+/c9wsd5g7dy0nnHA3S5Z8g6ysDjVqM051dW2LQ8do0MrUVcGHbON9CtiTHgxP+vFbTBjurtn1JGnuuGNes26o2lrno48qeP75ZYwfPyyiyFLTOeeM5G9/e6vZwJXV1XVMmJD8LxrpGKeWhdzKOp4ni1ycWooYSgk/JzeJE6FqbAnpEpYt+5iqqtpm5XV1zpo1WyOIKLWNHz+Ms88+ZOeQMrm5WRQU5PDnP5+iybdS0AoeYR0zqaOKGsqpZQdbeZ83uSWpcYS+S0okkU48cQiPPPJOs7+I6+qcMWM0yOLuMjPuvPN0Jk0axfTp71JYmMuXvnQow4drZoIobeA1VvJPqtnGnoxjEKeSvWsi0xat4BHqqGxU5tSwgdnUsJ0ckjNUkBKGdAnnnDOSW255iRUrPqayMtbS6N49l4kTD+DAA/tFHF1qMjPGjh3E2LGDog5FgPe5m+U8SC07ANjKYtbwJEfzR7LJa/W9tWyPW24YtVQmLWGoS0q6hIKCXGbPnsS3vnU0w4f3oaAgh1tv/TT33XdG1KGJdFglm1jGtJ3JAqCOSspZwzqeafP9/RhD7FnnxrrRnzx6d2aorVLCkC6jV698fvaz8Sxe/HUOPrg/l19+JNnZ+hWV1Pcxb2FxOnTq2MGHvNLm+0fwP+TRg6ygJWJkk00+h/IdrGOPxe0WdUmJiCRYLj2J/5RCFt3Yo83359Of47iHVTzGJhZQxGAG83kK2afTY22NEoaISIL14VBy6RF0Se1KHFnkMojTQn1GHr0YzvkM5/wERdk2tfdFRBLMyOJIfkV39iabfLLpTjYFHMK36cl+UYcXmloYIiJJUMhAPsl9bGMJNWynFweQTbeow9otShgiIkliWEq1KJpSl5SIiISihCEiIqEoYYiISChKGCIiEooShoiIhKKEISIioUSWMMzsa2a2yMzeMrNftLDPSWb2rpktNrPvJTtGERHZJZLnMMysFJgIHO7ulWY2IM4+2cAfgE8Dq4HXzWy6u7+d3GhFRASia2FcDtzi7pUA7v5hnH2OAha7+1J3rwKmEUsyIiISgagSxgjgk2b2mpn928yOjLPPPsCqBuurgzIREYlAwrqkzOxZYM84m64LjtsXOBo4EnjQzIa5e7zxf8MebzIwGaC4uJhZs2Y12l5WVtasLB2oXqklHeuVjnUC1Ssud0/6AjwJlDZYXwL0b7LPMcBTDdavBa4N8/mjR4/2pmbOnNmsLB2oXqklHeuVjnVyz7x6AXO8je/WqLqk/gmUApjZCCAP2Nhkn9eB/c1sqJnlAecA05MapYiI7BRVwrgLGGZmC4ldzL7I3d3M9jazGQDuXgNcCTwFvAM86O5vRRSviEjGi+S2Wo/d9dRs2ih3Xwuc3GB9BjAjiaGJiEgL9KS3iIiEooQhIiKhKGGIiEgoShgiIhKKEoaIiIQSyV1SsnvWU8HdvM/rbKSIXL7AEE5hIIZFHZqIZBAljC5uE5VM5mXKqKYO2EQVf2ARyynjSg6KLC7HeYkPeZgVlFHN8RTzeYZQqF8pkbSl/91d3D9YQQW11DUo20Et01nFeQyLLK47eZ+HWcEOagFYSTlPs5YpjKVAv1YiaUnXMLq4BWwK2haN5ZHFUsoiiCjW6nmI5TuTBUAVdWxgB0+wJpKYRCTxlDC6uH0ojHuSaqhjAPlJjwfgHbaQEyeqSup4jQ0RRCQiyaCE0cWdzRBym5ymXLI4kF4MojCSmPqQh9N8JPosoH9ESUxEEk8Jo4sbRg9+xCfoRzfyyCIX4yj6cTOjIovpIHqxB92a/fLkksXnGBxJTCKSeLo6mQLG0J8HGcdGKulOTuR3IhnGrRzJdcxjNWTuDMIAAAw1SURBVOVkYxjGVRzCfvSMNDYRSRwljBRhWJfq7immgKkcy2rKKaeGYfRo1nUmEsrKxTDlR/DfF2HPwfA/34exn4k6KolDCUM6ZGBE11EkTax4H84rgYpyqKuFtcvh7Tnw3dvgc5dGHZ00oT8JRSQ6f74RKspiyaLeju3w66ugpia6uCQuJQwRic68F6Cu+XNG1FTDByuTH4+0SglDRKIzYJ/45bU10GuP5MYibYosYZjZ18xskZm9ZWa/aGGf5Wb2ppnNN7M5yY5RRBLs0u9DfvfGZd3y4VNnQo9e0cQkLYrkoreZlQITgcPdvdLMBrSye6m7b0xSaCKSTKUT4eu3wB+uA/dYV9S4z8EPpkYdmcQR1V1SlwO3uHslgLt/GFEcIhK1c78GZ06O3SHVdwD07BN1RNICc28+xEPCD2o2H3gUOAnYAVzt7q/H2W8ZsBlw4HZ3n9LKZ04GJgMUFxePnjZtWqPtZWVlFBUVdVodugrVq/1qcKqoJZespD1Dko7nKx3rBJlXr9LS0rnuXtLaexPWwjCzZ4E942y6LjhuX+Bo4EjgQTMb5s2z13HuvibosnrGzBa5+wvxjhckkykAJSUlPm7cuEbbZ82aRdOydKB6xec4yyljOzXsTy/yGiSEGuq4hTf5D+vJJYtqahjFHvyQI+hGdidE37J0PF/pWCdQveJJWMJw9/EtbTOzy4F/BAlitpnVAf2g8VCn7r4m+PmhmT0CHAXETRgi9dZQzrXMYwM7dqaJqxlJKXsB8BeW8CLrqaKOqmDo+Hl8xB9ZxLc4JKKoRbq+qO6S+idQCmBmI4A8oNGFbTMrNLMe9a+BCcDCRAW0fPnH3HPPfB59dBGVlXpgKFXV4Xyb11lNOTuoZXuw/Jw3WcY2AB5lFZVN5hipoo4nWUNdnFF4RSQmqovedwF3mdlCoAq4yN3dzPYGprr7yUAx8IiZ1cf5gLs/2dmBuDvXXPMsv//9bLKzjawsIzc3m2eeuYBRo/bq7MNJgr3BZsqobva1X00d01nFNziY7cT/g6CaOupwsjRXukhckSQMd68Czo9TvhY4OXi9FDg80bE8+eRi/vSn19mxo/GXyKmnPsDq1d8mK0tfHqlkC1Vxy+uAj9gBwGH0YS4fNUsq+9Ej7sRQIhKT8f87br99LuXl1c3Ky8qqePXV1RFEJB1xCL3jtC8gnyzGEHvc5woOooAccoKWRDZGPtm6fiHShowfrTZesgAwMyoq4m+Trqsf+XyBffkHK3fOOd6NLPaiO58OLnoPoYh7OI6HWM4iPmY4PTmLIexD99Y+WiTjZXzCOO+8Q3nllVXNEkddnTN27KCIopKOmMQIDqYP/2QFZdQwjj05nUHkNbhltj/5fJUDI4xSJPUoYZx3KPfcM585c9ZSXl5Nbm4WOTlZ3Hnn6RQU5EYdnrSDYRzLAI6ltRFnRGR3ZXzCyM3N5rnnLmT69Hd5/PH36d+/O5de+glGjNBImSIiDWV8wgDIzs7ijDMO4owzDoo6FBGRLksJQ0TSU3U1zHwEZj8PxYNg4sUtz78hoShhiEj6qSiHS46DlYtjU8DmdYO7fwa/+xeUnBB1dCkr45/DEJE0dP//wvJFsWQBUFUZSyLXnht/SlgJRQlDRNLPkw9A5Y7m5eVbYdmi5MeTJpQwRCT95OXHL6+ri3VPSbsoYYhI+jnrK1BQ2LjMDPYZCoOGRxNTGlDCEJH0M/FSOP406FYA+QVQ2CM2/euvH4k6spSmu6REJP1kZ8Mtf4XFC2HBy9BvLxh7EuRq9IaOUMIQkfS138jYIp1CXVIiIhKKEoaIiISihCEiIqEoYYiISChKGCIiEoq5N5//ONWZ2QZgRZPifsDGCMJJNNUrtaRjvdKxTpB59drX3fu39sa0TBjxmNkcdy+JOo7OpnqllnSsVzrWCVSveNQlJSIioShhiIhIKJmUMKZEHUCCqF6pJR3rlY51AtWrmYy5hiEiIh2TSS0MERHpACUMEREJJS0Thpllm9l/zezxONu6mdnfzGyxmb1mZkOSH2H7tFGvi81sg5nND5ZJUcS4u8xsuZm9GcQ8J852M7PfBefrDTMbFUWcuyNEncaZ2ZYG5+oHUcS5u8yst5n93cwWmdk7ZnZMk+0pd64gVL1S7nyZ2QEN4p1vZlvN7JtN9tnt85Wuw5t/A3gH6Bln2/8Am919PzM7B/g58MVkBtcBrdUL4G/ufmUS4+kspe7e0gNSnwX2D5YxwJ+Cn11da3UC+I+7n5q0aDrH/wJPuvtZZpYHdG+yPVXPVVv1ghQ7X+7+LnAExP7QBNYATWeP2u3zlXYtDDMbCJwCTG1hl4nAvcHrvwOfMjNLRmwdEaJe6Woi8H8e8yrQ28z2ijqoTGNmvYDjgTsB3L3K3T9uslvKnauQ9Up1nwKWuHvT0S92+3ylXcIAfgtcA9S1sH0fYBWAu9cAW4A9khNah7RVL4Azg6bl381sUJLi6igHnjazuWY2Oc72necrsDoo68raqhPAMWa2wMyeMLNDkhlcOw0FNgB3B92iU82syaTZKXmuwtQLUu98NXQO8Nc45bt9vtIqYZjZqcCH7j436lg6U8h6PQYMcffDgGfY1Yrq6o5z91HEmsdXmNnxUQfUCdqq0zxi4/YcDtwG/DPZAbZDDjAK+JO7fwIoB74XbUidIky9UvF8ARB0sZ0OPNQZn5dWCQM4FjjdzJYD04ATzewvTfZZAwwCMLMcoBfwUTKDbIc26+XuH7l7ZbA6FRid3BDbx93XBD8/JNbHelSTXXaer8DAoKzLaqtO7r7V3cuC1zOAXDPrl/RAd89qYLW7vxas/53YF21DKXeuCFGvFD1f9T4LzHP39XG27fb5SquE4e7XuvtAdx9CrBn2vLuf32S36cBFweuzgn269NOLYerVpO/xdGIXx7s0Mys0sx71r4EJwMImu00HLgzu6Dga2OLu65Icamhh6mRme9ZfNzOzo4j9P+zSf7S4+wfAKjM7ICj6FPB2k91S6lxBuHql4vlq4Fzid0dBO85Xut4l1YiZ3QTMcffpxC5u3Wdmi4FNxL6AU1KTen3dzE4HaojV6+IoYwupGHgk+L+YAzzg7k+a2WUA7v5nYAZwMrAY2A5cElGsYYWp01nA5WZWA1QA53T1P1oCXwPuD7o5lgKXpPi5qtdWvVLyfAV/sHwa+EqDsg6dLw0NIiIioaRVl5SIiCSOEoaIiISihCEiIqEoYYiISChKGCIiEooShkjAzGqDkT0XmNk8Mxvbxv69zeyrIT53lpmVtLFPVjBy6EKLjXT7upkNDbbNMLPeu1cbkc6XEc9hiIRU4e71I3x+BvgZcEIr+/cGvgr8sROO/UVgb+Awd68LBpssB3D3kzvh80U6TC0Mkfh6ApsBzKzIzJ4LWh1vmtnEYJ9bgOFBq+SXwb7fDfZZYGa3NPi8L5jZbDN7z8w+Ged4ewHr3L0OwN1Xu3v98ZebWT8zu8x2zW+wzMxmBtsnmNkrQXwPmVlRYv5JJNPpwT2RgJnVAm8C+cS+wE9097nBmGPd3X1rMIbQq8TmENgXeNzdRwbv/yxwAzDe3bebWV9332Rms4C57n6VmZ0MfNvdxzc59kDgReBj4DngL+7+32DbcqCkfn4NM8sFngd+AbwC/AP4rLuXm9l3gW7uflOi/p0kc6lLSmSXhl1SxwD/Z2YjAQN+Gow6W0dsCOjiOO8fD9zt7tsB3H1Tg23/CH7OBYY0faO7rw7GMzoxWJ4zsy+4+3NxjvO/xMYTeywYyfhg4KVgOJI8YklEpNMpYYjE4e6vBK2J/sTG2+kPjHb36uAv/vzd/Mj6kYRraeH/XTDa8BPAE2a2HvgcsdbGTmZ2MbGWTf3MigY84+7n7mY8IrtN1zBE4jCzA4FsYqOS9iI2H0m1mZUS+8IG2Ab0aPC2Z4gNXNc9+Iy+u3G8UWa2d/A6CzgMWNFkn9HA1cD59dc6iHWPHWtm+wX7FJrZiN2qrEhIamGI7FJgZvOD1wZc5O61ZnY/8JiZvQnMARZBbA4SM3vJzBYCT7j7d8zsCGCOmVURGw30+yGPPQC4w8y6Beuzgd832edKoC8wM+h+muPuk4JWx18bvPd64L3dq7pI23TRW0REQlGXlIiIhKKEISIioShhiIhIKEoYIiISihKGiIiEooQhIiKhKGGIiEgo/w+vTfWXZiG8mwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "6KAwu3IZVVJr",
        "outputId": "9d375225-7f1c-43cf-d6d4-cef1baeb12c0"
      },
      "source": [
        "t_yhat = yhat+1\n",
        "clust = sorted(list(set(yhat+1)))\n",
        "freq = [t_yhat[t_yhat[:]==i].shape[0] for i in clust]\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(111)\n",
        "clust = np.arange(0, 7)\n",
        "freq=[9, 5, 2, 2, 8, 3, 2]\n",
        "ax.bar(clust, freq, zorder=1, color=\"#770000\")\n",
        "ax.plot(clust, freq, zorder=2, linewidth=3)\n",
        "ax.scatter(clust, freq, zorder=3, marker='x', s=150)\n",
        "ax.set_axisbelow(True)\n",
        "ax.set_xticks(clust)\n",
        "plt.grid(True)\n",
        "plt.savefig(\"bar.png\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KZ7TDOaAeTn1",
        "outputId": "b98df5f6-9291-41a6-d324-d32d91d90150"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"Cluster.png\")\n",
        "files.download(\"bar.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ba220dc2-a1c1-4cfa-b3d9-2c7dc4cee2e3\", \"Cluster.png\", 68743)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b3f8984f-67ea-4b4b-93a7-ea655e25928c\", \"bar.png\", 102506)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRe2H2yw5E-4"
      },
      "source": [
        "# Genetic Mutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQaytgH0m14"
      },
      "source": [
        "def mutate(lr):\n",
        "\n",
        "    num = random.randint(-1,1)\n",
        "    lr += (lr/10)*num\n",
        "\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5XwnJgL5HYC"
      },
      "source": [
        "# Genetic Mating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqZ5ySE815Ku"
      },
      "source": [
        "def crossover(lrs, batches):\n",
        "  new_lrs = []\n",
        "  new_batches = []\n",
        "\n",
        "  new_lrs.append(lrs[0])\n",
        "  new_batches.append(batches[0])\n",
        "  if(len(lrs) >1):\n",
        "    new_lrs.append(lrs[1])\n",
        "    new_batches.append(batches[1])\n",
        "\n",
        "  if(len(lrs) > 2):\n",
        "    for i in range(2, len(lrs)):\n",
        "      # parentA = random.randint(0, len(lrs)-1)\n",
        "      # parentB = random.randint(0, len(lrs)-1)\n",
        "\n",
        "      # num = np.random.choice([parentA, parentB])\n",
        "      # num2 = parentA if num == parentB else parentB\n",
        "      new_lrs.append(mutate(lrs[random.randint(0, len(lrs)-1)]))\n",
        "      new_batches.append(batches[random.randint(0, len(batches)-1)])\n",
        "\n",
        "\n",
        "  return new_lrs, new_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26iigDPI5KwA"
      },
      "source": [
        "# Genetic Evolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDdAywv0nHM"
      },
      "source": [
        "def evolve(losses, lrs, batches):\n",
        "    sorted_y_idx_list = sorted(range(len(losses)),key=lambda x:losses[x])\n",
        "    lrs = [lrs[i] for i in sorted_y_idx_list]\n",
        "    batches = [batches[i] for i in sorted_y_idx_list]\n",
        "    lrs, batches = crossover(lrs, batches)\n",
        "\n",
        "    return lrs, batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK_QwKuA5PIv"
      },
      "source": [
        "# Edge Device training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5wHd3GX0i-"
      },
      "source": [
        "def train_client(num, model, lr, batch):\n",
        "\n",
        "  new_model = model_cloner(model, lr, 'adam')\n",
        "  hist = model.fit(client_train_x[num], client_train_y[num], epochs=2, batch_size=batch, validation_data=(X_test, y_test))\n",
        "\n",
        "  return new_model, lr, round(hist.history['val_loss'][-1], 4), batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X14df0oaLrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e907c4ca-a9d3-4851-fde1-866ede0d6b73"
      },
      "source": [
        "losses "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2754,\n",
              " 0.3094,\n",
              " 0.2609,\n",
              " 0.3261,\n",
              " 0.3016,\n",
              " 0.2605,\n",
              " 0.2825,\n",
              " 0.2886,\n",
              " 0.3018,\n",
              " 0.3197,\n",
              " 0.2867,\n",
              " 0.3255,\n",
              " 0.2944,\n",
              " 0.3003,\n",
              " 0.3269,\n",
              " 0.3222,\n",
              " 0.3268,\n",
              " 0.3288,\n",
              " 0.3255,\n",
              " 0.3275,\n",
              " 0.3239,\n",
              " 0.3306,\n",
              " 0.327,\n",
              " 0.3254,\n",
              " 0.3143,\n",
              " 0.3214,\n",
              " 0.3258,\n",
              " 0.2942,\n",
              " 0.3117,\n",
              " 0.3301]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MdhJtDYkZXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3b9aab-b75e-4714-88d9-9824493ea540"
      },
      "source": [
        "lr_init "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.97145754e-07, 4.62420842e-06, 3.35551851e-05, 2.29753384e-06,\n",
              "       1.01735740e-07, 7.08797848e-05, 5.24905468e-05, 3.35534081e-05,\n",
              "       4.19695594e-04, 9.36806673e-04, 8.25264914e-04, 2.25170441e-04,\n",
              "       1.15956746e-04, 6.89400491e-06, 4.33920608e-05, 3.96124178e-07,\n",
              "       2.89568558e-06, 1.09272270e-07, 1.44513764e-05, 2.02552672e-05,\n",
              "       1.44546011e-05, 3.68926822e-07, 1.52183388e-04, 2.12903856e-07,\n",
              "       5.53088120e-06, 3.62099971e-07, 4.03157435e-05, 7.02352621e-07,\n",
              "       8.64159785e-04, 6.49323023e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6lHPZHvKitx",
        "outputId": "497a0f53-2d67-4607-bc02-f1efd31d13a0"
      },
      "source": [
        "batches1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 59],\n",
              "       [ 31],\n",
              "       [ 35],\n",
              "       [ 38],\n",
              "       [ 16],\n",
              "       [ 54],\n",
              "       [ 70],\n",
              "       [ 32],\n",
              "       [ 19],\n",
              "       [ 34],\n",
              "       [ 19],\n",
              "       [ 67],\n",
              "       [ 25],\n",
              "       [ 43],\n",
              "       [ 86],\n",
              "       [ 17],\n",
              "       [ 40],\n",
              "       [ 28],\n",
              "       [ 18],\n",
              "       [ 71],\n",
              "       [ 49],\n",
              "       [ 51],\n",
              "       [ 16],\n",
              "       [ 26],\n",
              "       [ 39],\n",
              "       [121],\n",
              "       [ 34],\n",
              "       [ 16],\n",
              "       [ 84],\n",
              "       [ 38]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSK_7dY0Tlx"
      },
      "source": [
        "yhat\n",
        "if(-1 in yhat):\n",
        "  flag=1\n",
        "else:\n",
        "  flag=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88GFprXB54KL"
      },
      "source": [
        "# Genetic Clustering FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJePiAuto7dJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6997af-cfb6-4ff5-cde9-0f59b0186797"
      },
      "source": [
        "yhat = list(yhat)\n",
        "serverhist1={\n",
        "    \"loss\": list(),\n",
        "    \"accuracy\": list()\n",
        "}\n",
        "# Control loop\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"---------\"+str(i)+\"------------\")\n",
        "  lr_global = []\n",
        "  batch_global = []\n",
        "  data = []\n",
        "  #  Genetic Optimization of Hyper-Parameters\n",
        "  for cluster in clusters:\n",
        "    ind = [k for k in range(len(yhat)) if(yhat[k]==cluster)]\n",
        "    #print(ind)\n",
        "    #print(losses)\n",
        "    #print(lr_init)\n",
        "    #print(batches)\n",
        "    data.append(evolve([losses[k] for k in ind], [lr_init[k] for k in ind], [batches[k] for k in ind]))\n",
        "    lr_global.append(data[-1][0])\n",
        "    batch_global.append(data[-1][1])\n",
        "    \n",
        "\n",
        "  lr_init = []\n",
        "  batches = []\n",
        "  losses = []\n",
        "  data = []\n",
        "  lrid = np.zeros(len(clusters)) # lrid=[2,1,0]\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    print(lrid)\n",
        "    # SHAASHWAT AGRAWAL FACT CHECK THE LOGIC HERE lr_global[cluster][clusteri - current index]\n",
        "    data.append(train_client(j, server_model, lr_global[yhat[j]+flag][int(lrid[yhat[j]+flag])], batch_global[yhat[j]+flag][int(lrid[yhat[j]+flag])]))\n",
        "    lrid[yhat[j]+flag] +=1\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "    batches.append(data[j][3])\n",
        "\n",
        "  '''# Cluster head aggregation\n",
        "  n_clust = len(set(yhat))\n",
        "  a = [[i*0 for i in client_models[0].get_weights()] for i in range(n_clust)]\n",
        "  for i in range(len(yhat)):\n",
        "    a[yhat[i]] = [k+j for k, j in zip(client_models[i].get_weights(), a[yhat[i]])]'''\n",
        "\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(NUM_CLIENTS):\n",
        "    sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "  server_model.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "\n",
        "  # Model Evaluation\n",
        "  h=server_model.evaluate(X_test,y_test)\n",
        "  serverhist1['loss'].append(h[1])\n",
        "  serverhist1['accuracy'].append(h[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------0------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 2s 24ms/step - loss: 2.2523 - accuracy: 0.1373 - val_loss: 2.1079 - val_accuracy: 0.2087\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 1.9747 - accuracy: 0.2690 - val_loss: 1.9108 - val_accuracy: 0.2922\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 1.8687 - accuracy: 0.3104 - val_loss: 1.9740 - val_accuracy: 0.2760\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 1.7363 - accuracy: 0.3553 - val_loss: 1.6650 - val_accuracy: 0.3843\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "114/114 [==============================] - 2s 16ms/step - loss: 1.6983 - accuracy: 0.3709 - val_loss: 1.7016 - val_accuracy: 0.3646\n",
            "Epoch 2/2\n",
            "114/114 [==============================] - 2s 15ms/step - loss: 1.5760 - accuracy: 0.4229 - val_loss: 1.4848 - val_accuracy: 0.4586\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 1.5318 - accuracy: 0.4516 - val_loss: 1.4399 - val_accuracy: 0.4754\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 1.3888 - accuracy: 0.4932 - val_loss: 1.4105 - val_accuracy: 0.4776\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 1.5918 - accuracy: 0.4261 - val_loss: 1.6628 - val_accuracy: 0.3952\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 1.4130 - accuracy: 0.4729 - val_loss: 1.5015 - val_accuracy: 0.4539\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 1.4349 - accuracy: 0.4795 - val_loss: 1.3202 - val_accuracy: 0.5173\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.2662 - accuracy: 0.5381 - val_loss: 1.2562 - val_accuracy: 0.5489\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "179/179 [==============================] - 3s 17ms/step - loss: 1.3698 - accuracy: 0.5085 - val_loss: 1.3364 - val_accuracy: 0.5151\n",
            "Epoch 2/2\n",
            "179/179 [==============================] - 3s 16ms/step - loss: 1.1942 - accuracy: 0.5705 - val_loss: 1.4327 - val_accuracy: 0.5045\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 1.2146 - accuracy: 0.5679 - val_loss: 1.1827 - val_accuracy: 0.5739\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 18ms/step - loss: 1.0528 - accuracy: 0.6217 - val_loss: 1.1672 - val_accuracy: 0.5876\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.1435 - accuracy: 0.5955 - val_loss: 1.1485 - val_accuracy: 0.5861\n",
            "Epoch 2/2\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.9877 - accuracy: 0.6398 - val_loss: 1.1238 - val_accuracy: 0.5935\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.9162 - accuracy: 0.6826 - val_loss: 1.1792 - val_accuracy: 0.5756\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 29ms/step - loss: 0.7564 - accuracy: 0.7189 - val_loss: 1.3991 - val_accuracy: 0.5245\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 1.1422 - accuracy: 0.5859 - val_loss: 1.1339 - val_accuracy: 0.5958\n",
            "Epoch 2/2\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.9222 - accuracy: 0.6644 - val_loss: 1.1535 - val_accuracy: 0.5994\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 1.0844 - accuracy: 0.6117 - val_loss: 1.0716 - val_accuracy: 0.6209\n",
            "Epoch 2/2\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.8473 - accuracy: 0.7000 - val_loss: 1.0618 - val_accuracy: 0.6298\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 2s 30ms/step - loss: 1.0575 - accuracy: 0.6237 - val_loss: 1.0140 - val_accuracy: 0.6479\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 26ms/step - loss: 0.7981 - accuracy: 0.7152 - val_loss: 1.0380 - val_accuracy: 0.6369\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 41ms/step - loss: 0.9289 - accuracy: 0.6870 - val_loss: 0.9814 - val_accuracy: 0.6546\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7411 - accuracy: 0.7438 - val_loss: 0.9967 - val_accuracy: 0.6637\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 1.0377 - accuracy: 0.6351 - val_loss: 1.0690 - val_accuracy: 0.6257\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.7657 - accuracy: 0.7422 - val_loss: 1.1054 - val_accuracy: 0.6301\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 1.1137 - accuracy: 0.6021 - val_loss: 1.0549 - val_accuracy: 0.6293\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8495 - accuracy: 0.7032 - val_loss: 1.0957 - val_accuracy: 0.6339\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "69/69 [==============================] - 1s 21ms/step - loss: 0.9141 - accuracy: 0.6815 - val_loss: 0.9267 - val_accuracy: 0.6733\n",
            "Epoch 2/2\n",
            "69/69 [==============================] - 1s 19ms/step - loss: 0.6450 - accuracy: 0.7775 - val_loss: 0.9710 - val_accuracy: 0.6763\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 35ms/step - loss: 0.8337 - accuracy: 0.7107 - val_loss: 0.9498 - val_accuracy: 0.6751\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 2s 32ms/step - loss: 0.4528 - accuracy: 0.8512 - val_loss: 1.1402 - val_accuracy: 0.6592\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.9962 - accuracy: 0.6505 - val_loss: 1.1856 - val_accuracy: 0.6058\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 14ms/step - loss: 0.7506 - accuracy: 0.7362 - val_loss: 0.9821 - val_accuracy: 0.6624\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "32/32 [==============================] - 1s 42ms/step - loss: 0.9660 - accuracy: 0.6709 - val_loss: 0.9406 - val_accuracy: 0.6736\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.6548 - accuracy: 0.7837 - val_loss: 0.9473 - val_accuracy: 0.6788\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.8666 - accuracy: 0.6992 - val_loss: 0.9130 - val_accuracy: 0.6819\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 30ms/step - loss: 0.5519 - accuracy: 0.8135 - val_loss: 0.9525 - val_accuracy: 0.6851\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4711 - accuracy: 0.8436 - val_loss: 0.9398 - val_accuracy: 0.7001\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 0.2518 - accuracy: 0.9267 - val_loss: 1.0523 - val_accuracy: 0.6992\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 38ms/step - loss: 0.9375 - accuracy: 0.6816 - val_loss: 0.8866 - val_accuracy: 0.6933\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.6176 - accuracy: 0.7849 - val_loss: 0.8797 - val_accuracy: 0.7026\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.8279 - accuracy: 0.7139 - val_loss: 0.8711 - val_accuracy: 0.7025\n",
            "Epoch 2/2\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.5462 - accuracy: 0.8105 - val_loss: 0.9325 - val_accuracy: 0.6955\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 19ms/step - loss: 0.8048 - accuracy: 0.7158 - val_loss: 0.9290 - val_accuracy: 0.6772\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 3s 18ms/step - loss: 0.4622 - accuracy: 0.8424 - val_loss: 1.0870 - val_accuracy: 0.6760\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6385 - accuracy: 0.7876 - val_loss: 0.8919 - val_accuracy: 0.7015\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4440 - accuracy: 0.8593 - val_loss: 0.8969 - val_accuracy: 0.7094\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 2s 22ms/step - loss: 0.6994 - accuracy: 0.7645 - val_loss: 0.9817 - val_accuracy: 0.6671\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 2s 22ms/step - loss: 0.3793 - accuracy: 0.8781 - val_loss: 1.0202 - val_accuracy: 0.6796\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "232/232 [==============================] - 3s 15ms/step - loss: 0.9314 - accuracy: 0.6736 - val_loss: 0.9741 - val_accuracy: 0.6706\n",
            "Epoch 2/2\n",
            "232/232 [==============================] - 3s 14ms/step - loss: 0.6287 - accuracy: 0.7836 - val_loss: 0.9834 - val_accuracy: 0.6685\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "194/194 [==============================] - 3s 18ms/step - loss: 0.9413 - accuracy: 0.6806 - val_loss: 0.9704 - val_accuracy: 0.6669\n",
            "Epoch 2/2\n",
            "194/194 [==============================] - 3s 17ms/step - loss: 0.6050 - accuracy: 0.7932 - val_loss: 0.9214 - val_accuracy: 0.6912\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.6150 - accuracy: 0.7978 - val_loss: 0.8630 - val_accuracy: 0.7152\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.3055 - accuracy: 0.9015 - val_loss: 0.9574 - val_accuracy: 0.7212\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9965 - accuracy: 0.6664\n",
            "---------1------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 26ms/step - loss: 0.8960 - accuracy: 0.6820 - val_loss: 0.9276 - val_accuracy: 0.6672\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 0.7496 - accuracy: 0.7326 - val_loss: 1.0297 - val_accuracy: 0.6469\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 23ms/step - loss: 0.7893 - accuracy: 0.7241 - val_loss: 0.8808 - val_accuracy: 0.6965\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 20ms/step - loss: 0.5899 - accuracy: 0.7997 - val_loss: 0.9119 - val_accuracy: 0.6941\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "248/248 [==============================] - 4s 15ms/step - loss: 1.0004 - accuracy: 0.6460 - val_loss: 1.0617 - val_accuracy: 0.6314\n",
            "Epoch 2/2\n",
            "248/248 [==============================] - 4s 15ms/step - loss: 0.7682 - accuracy: 0.7292 - val_loss: 1.0136 - val_accuracy: 0.6571\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.8201 - accuracy: 0.7035 - val_loss: 0.9017 - val_accuracy: 0.6813\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.5761 - accuracy: 0.8009 - val_loss: 0.9040 - val_accuracy: 0.6949\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "119/119 [==============================] - 3s 24ms/step - loss: 0.9110 - accuracy: 0.6770 - val_loss: 0.9324 - val_accuracy: 0.6768\n",
            "Epoch 2/2\n",
            "119/119 [==============================] - 3s 23ms/step - loss: 0.5873 - accuracy: 0.7840 - val_loss: 1.1765 - val_accuracy: 0.6207\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.8830 - accuracy: 0.6886 - val_loss: 0.8381 - val_accuracy: 0.7120\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6157 - accuracy: 0.7843 - val_loss: 0.8710 - val_accuracy: 0.7017\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 19ms/step - loss: 0.7748 - accuracy: 0.7267 - val_loss: 0.8795 - val_accuracy: 0.6952\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 18ms/step - loss: 0.5191 - accuracy: 0.8205 - val_loss: 0.9524 - val_accuracy: 0.6880\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "193/193 [==============================] - 3s 16ms/step - loss: 0.8040 - accuracy: 0.7204 - val_loss: 0.9530 - val_accuracy: 0.6714\n",
            "Epoch 2/2\n",
            "193/193 [==============================] - 3s 15ms/step - loss: 0.5046 - accuracy: 0.8230 - val_loss: 1.0794 - val_accuracy: 0.6791\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.8453 - accuracy: 0.7175 - val_loss: 0.8445 - val_accuracy: 0.7114\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.5772 - accuracy: 0.8085 - val_loss: 0.8585 - val_accuracy: 0.7133\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 33ms/step - loss: 0.4193 - accuracy: 0.8538 - val_loss: 0.9100 - val_accuracy: 0.7154\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 28ms/step - loss: 0.1638 - accuracy: 0.9536 - val_loss: 1.1010 - val_accuracy: 0.7144\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.7000 - accuracy: 0.7551 - val_loss: 0.9266 - val_accuracy: 0.6977\n",
            "Epoch 2/2\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.3887 - accuracy: 0.8633 - val_loss: 0.9964 - val_accuracy: 0.7095\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "225/225 [==============================] - 4s 16ms/step - loss: 0.8639 - accuracy: 0.6953 - val_loss: 0.9326 - val_accuracy: 0.6765\n",
            "Epoch 2/2\n",
            "225/225 [==============================] - 4s 16ms/step - loss: 0.5153 - accuracy: 0.8160 - val_loss: 0.9384 - val_accuracy: 0.6930\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "57/57 [==============================] - 2s 27ms/step - loss: 0.7284 - accuracy: 0.7446 - val_loss: 0.8362 - val_accuracy: 0.7082\n",
            "Epoch 2/2\n",
            "57/57 [==============================] - 1s 24ms/step - loss: 0.3754 - accuracy: 0.8730 - val_loss: 0.9219 - val_accuracy: 0.7159\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "118/118 [==============================] - 3s 26ms/step - loss: 0.7247 - accuracy: 0.7469 - val_loss: 0.8968 - val_accuracy: 0.7066\n",
            "Epoch 2/2\n",
            "118/118 [==============================] - 3s 25ms/step - loss: 0.3203 - accuracy: 0.8870 - val_loss: 1.0982 - val_accuracy: 0.6925\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.8518 - accuracy: 0.7137 - val_loss: 0.8469 - val_accuracy: 0.7111\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.4561 - accuracy: 0.8438 - val_loss: 0.8993 - val_accuracy: 0.7141\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8145 - accuracy: 0.7187 - val_loss: 0.8478 - val_accuracy: 0.7074\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.4433 - accuracy: 0.8423 - val_loss: 0.9069 - val_accuracy: 0.7221\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.6197 - accuracy: 0.7997 - val_loss: 0.7998 - val_accuracy: 0.7326\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.3950 - accuracy: 0.8641 - val_loss: 0.8183 - val_accuracy: 0.7440\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 2s 36ms/step - loss: 0.2118 - accuracy: 0.9286 - val_loss: 1.0475 - val_accuracy: 0.7205\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.0476 - accuracy: 0.9947 - val_loss: 1.1347 - val_accuracy: 0.7376\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.8188 - accuracy: 0.7160 - val_loss: 0.8922 - val_accuracy: 0.6931\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.4577 - accuracy: 0.8420 - val_loss: 0.9387 - val_accuracy: 0.7093\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 0.9007 - accuracy: 0.7003 - val_loss: 0.8978 - val_accuracy: 0.6886\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.4865 - accuracy: 0.8405 - val_loss: 0.8916 - val_accuracy: 0.7094\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.6688 - accuracy: 0.7720 - val_loss: 0.8239 - val_accuracy: 0.7248\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.2780 - accuracy: 0.9134 - val_loss: 0.9022 - val_accuracy: 0.7339\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 0.2516 - accuracy: 0.9153 - val_loss: 0.9252 - val_accuracy: 0.7392\n",
            "Epoch 2/2\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 0.1073 - accuracy: 0.9748 - val_loss: 0.9692 - val_accuracy: 0.7380\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.6616 - accuracy: 0.7895 - val_loss: 0.8837 - val_accuracy: 0.7294\n",
            "Epoch 2/2\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.3400 - accuracy: 0.8960 - val_loss: 0.8637 - val_accuracy: 0.7385\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.6706 - accuracy: 0.7731 - val_loss: 0.8327 - val_accuracy: 0.7182\n",
            "Epoch 2/2\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.3224 - accuracy: 0.8898 - val_loss: 0.9219 - val_accuracy: 0.7178\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "89/89 [==============================] - 2s 20ms/step - loss: 0.5629 - accuracy: 0.8119 - val_loss: 0.8193 - val_accuracy: 0.7331\n",
            "Epoch 2/2\n",
            "89/89 [==============================] - 2s 19ms/step - loss: 0.2120 - accuracy: 0.9341 - val_loss: 0.9955 - val_accuracy: 0.7296\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4484 - accuracy: 0.8656 - val_loss: 0.8444 - val_accuracy: 0.7451\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.2610 - accuracy: 0.9250 - val_loss: 0.8493 - val_accuracy: 0.7536\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "121/121 [==============================] - 3s 22ms/step - loss: 0.5383 - accuracy: 0.8204 - val_loss: 0.9344 - val_accuracy: 0.7042\n",
            "Epoch 2/2\n",
            "121/121 [==============================] - 3s 21ms/step - loss: 0.2128 - accuracy: 0.9301 - val_loss: 1.1627 - val_accuracy: 0.7051\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.7515 - accuracy: 0.7406 - val_loss: 0.8409 - val_accuracy: 0.7140\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 15ms/step - loss: 0.3565 - accuracy: 0.8796 - val_loss: 1.0428 - val_accuracy: 0.7098\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "194/194 [==============================] - 4s 18ms/step - loss: 0.8748 - accuracy: 0.7003 - val_loss: 0.8290 - val_accuracy: 0.7164\n",
            "Epoch 2/2\n",
            "194/194 [==============================] - 3s 18ms/step - loss: 0.4593 - accuracy: 0.8439 - val_loss: 0.9193 - val_accuracy: 0.7235\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.4459 - accuracy: 0.8511 - val_loss: 0.8946 - val_accuracy: 0.7321\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 27ms/step - loss: 0.1380 - accuracy: 0.9612 - val_loss: 0.9826 - val_accuracy: 0.7398\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7309 - accuracy: 0.7617\n",
            "---------2------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.6083 - accuracy: 0.7889 - val_loss: 0.7279 - val_accuracy: 0.7509\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 0.4076 - accuracy: 0.8671 - val_loss: 0.7872 - val_accuracy: 0.7519\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 0.3983 - accuracy: 0.8626 - val_loss: 0.7734 - val_accuracy: 0.7573\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.2528 - accuracy: 0.9202 - val_loss: 0.8445 - val_accuracy: 0.7524\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 22ms/step - loss: 0.4639 - accuracy: 0.8368 - val_loss: 0.7745 - val_accuracy: 0.7502\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.2736 - accuracy: 0.9101 - val_loss: 0.8867 - val_accuracy: 0.7497\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.2395 - accuracy: 0.9272 - val_loss: 0.8938 - val_accuracy: 0.7485\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.0992 - accuracy: 0.9742 - val_loss: 0.9611 - val_accuracy: 0.7464\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.6400 - accuracy: 0.7755 - val_loss: 0.8847 - val_accuracy: 0.7083\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.2354 - accuracy: 0.9268 - val_loss: 1.2177 - val_accuracy: 0.6732\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.5532 - accuracy: 0.8069 - val_loss: 0.8723 - val_accuracy: 0.7264\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2294 - accuracy: 0.9279 - val_loss: 0.9978 - val_accuracy: 0.7260\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 19ms/step - loss: 0.4584 - accuracy: 0.8432 - val_loss: 0.9223 - val_accuracy: 0.7198\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 18ms/step - loss: 0.1699 - accuracy: 0.9396 - val_loss: 1.2142 - val_accuracy: 0.7121\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 0.4330 - accuracy: 0.8527 - val_loss: 0.9967 - val_accuracy: 0.7106\n",
            "Epoch 2/2\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 0.1537 - accuracy: 0.9512 - val_loss: 1.2547 - val_accuracy: 0.7115\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.6593 - accuracy: 0.8031 - val_loss: 0.8930 - val_accuracy: 0.7236\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.2790 - accuracy: 0.9154 - val_loss: 0.9266 - val_accuracy: 0.7313\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 32ms/step - loss: 0.1202 - accuracy: 0.9661 - val_loss: 1.0979 - val_accuracy: 0.7362\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 29ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 1.2312 - val_accuracy: 0.7365\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5627 - accuracy: 0.7973 - val_loss: 1.0800 - val_accuracy: 0.6729\n",
            "Epoch 2/2\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2708 - accuracy: 0.9080 - val_loss: 1.0341 - val_accuracy: 0.7044\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "189/189 [==============================] - 3s 17ms/step - loss: 0.6942 - accuracy: 0.7628 - val_loss: 0.9214 - val_accuracy: 0.6970\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 3s 16ms/step - loss: 0.3024 - accuracy: 0.8980 - val_loss: 1.0229 - val_accuracy: 0.7009\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 0.6286 - accuracy: 0.7876 - val_loss: 0.9197 - val_accuracy: 0.6996\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 23ms/step - loss: 0.1837 - accuracy: 0.9408 - val_loss: 1.1458 - val_accuracy: 0.7028\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 0.4406 - accuracy: 0.8329 - val_loss: 0.9728 - val_accuracy: 0.7144\n",
            "Epoch 2/2\n",
            "61/61 [==============================] - 1s 25ms/step - loss: 0.1271 - accuracy: 0.9613 - val_loss: 1.1663 - val_accuracy: 0.7211\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.8106 - accuracy: 0.7257 - val_loss: 0.8866 - val_accuracy: 0.7074\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 3s 24ms/step - loss: 0.3570 - accuracy: 0.8814 - val_loss: 1.0217 - val_accuracy: 0.7133\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7051 - accuracy: 0.7528 - val_loss: 0.9660 - val_accuracy: 0.6792\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.3406 - accuracy: 0.8844 - val_loss: 0.9763 - val_accuracy: 0.7196\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.5564 - accuracy: 0.8140 - val_loss: 0.8555 - val_accuracy: 0.7302\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.2083 - accuracy: 0.9431 - val_loss: 0.9759 - val_accuracy: 0.7335\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 36ms/step - loss: 0.2239 - accuracy: 0.9172 - val_loss: 1.1091 - val_accuracy: 0.7264\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 2s 33ms/step - loss: 0.0462 - accuracy: 0.9909 - val_loss: 1.1495 - val_accuracy: 0.7409\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.6771 - accuracy: 0.7645 - val_loss: 0.8729 - val_accuracy: 0.7169\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.3120 - accuracy: 0.8900 - val_loss: 0.9918 - val_accuracy: 0.7122\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.8098 - accuracy: 0.7617 - val_loss: 0.8880 - val_accuracy: 0.7158\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.4403 - accuracy: 0.8634 - val_loss: 0.8552 - val_accuracy: 0.7214\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.5478 - accuracy: 0.8014 - val_loss: 0.9388 - val_accuracy: 0.7071\n",
            "Epoch 2/2\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.1535 - accuracy: 0.9573 - val_loss: 1.1132 - val_accuracy: 0.7270\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.1998 - accuracy: 0.9275 - val_loss: 1.0781 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.1139 - accuracy: 0.9674 - val_loss: 1.1515 - val_accuracy: 0.7277\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 3s 31ms/step - loss: 0.7843 - accuracy: 0.7440 - val_loss: 1.0242 - val_accuracy: 0.6640\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 3s 29ms/step - loss: 0.2826 - accuracy: 0.9064 - val_loss: 1.1048 - val_accuracy: 0.6970\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.6345 - accuracy: 0.7853 - val_loss: 0.8236 - val_accuracy: 0.7354\n",
            "Epoch 2/2\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.2483 - accuracy: 0.9197 - val_loss: 0.9643 - val_accuracy: 0.7275\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "172/172 [==============================] - 3s 20ms/step - loss: 0.4737 - accuracy: 0.8399 - val_loss: 1.0469 - val_accuracy: 0.7098\n",
            "Epoch 2/2\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 0.1710 - accuracy: 0.9421 - val_loss: 1.1934 - val_accuracy: 0.7213\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3820 - accuracy: 0.8801 - val_loss: 0.9857 - val_accuracy: 0.7358\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.1747 - accuracy: 0.9462 - val_loss: 0.9868 - val_accuracy: 0.7402\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "27/27 [==============================] - 1s 35ms/step - loss: 0.4627 - accuracy: 0.8445 - val_loss: 0.8884 - val_accuracy: 0.7425\n",
            "Epoch 2/2\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.1932 - accuracy: 0.9454 - val_loss: 0.9219 - val_accuracy: 0.7464\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.5965 - accuracy: 0.7940 - val_loss: 0.9772 - val_accuracy: 0.6907\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 15ms/step - loss: 0.2143 - accuracy: 0.9254 - val_loss: 1.1523 - val_accuracy: 0.7033\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.7951 - accuracy: 0.7323 - val_loss: 0.8385 - val_accuracy: 0.7223\n",
            "Epoch 2/2\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.3598 - accuracy: 0.8794 - val_loss: 0.8894 - val_accuracy: 0.7349\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.3044 - accuracy: 0.8893 - val_loss: 0.9023 - val_accuracy: 0.7435\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0755 - accuracy: 0.9832 - val_loss: 1.0528 - val_accuracy: 0.7411\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7819 - accuracy: 0.7688\n",
            "---------3------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.4624 - accuracy: 0.8400 - val_loss: 0.7656 - val_accuracy: 0.7622\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.2214 - accuracy: 0.9298 - val_loss: 0.8506 - val_accuracy: 0.7652\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 0.2444 - accuracy: 0.9178 - val_loss: 0.8554 - val_accuracy: 0.7650\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.1081 - accuracy: 0.9744 - val_loss: 0.9447 - val_accuracy: 0.7639\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "57/57 [==============================] - 1s 19ms/step - loss: 0.3903 - accuracy: 0.8663 - val_loss: 0.8131 - val_accuracy: 0.7572\n",
            "Epoch 2/2\n",
            "57/57 [==============================] - 1s 17ms/step - loss: 0.1546 - accuracy: 0.9553 - val_loss: 0.9735 - val_accuracy: 0.7532\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.0928 - accuracy: 0.9718 - val_loss: 1.0128 - val_accuracy: 0.7576\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.0257 - accuracy: 0.9982 - val_loss: 1.0669 - val_accuracy: 0.7591\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3673 - accuracy: 0.8616 - val_loss: 1.0539 - val_accuracy: 0.6940\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 1.2523 - val_accuracy: 0.7112\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3774 - accuracy: 0.8700 - val_loss: 0.9391 - val_accuracy: 0.7355\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0811 - accuracy: 0.9785 - val_loss: 1.1741 - val_accuracy: 0.7408\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.1980 - accuracy: 0.9304 - val_loss: 1.0117 - val_accuracy: 0.7434\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9915 - val_loss: 1.1246 - val_accuracy: 0.7517\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "193/193 [==============================] - 3s 16ms/step - loss: 0.3101 - accuracy: 0.8993 - val_loss: 1.1091 - val_accuracy: 0.7168\n",
            "Epoch 2/2\n",
            "193/193 [==============================] - 3s 15ms/step - loss: 0.1490 - accuracy: 0.9487 - val_loss: 1.4004 - val_accuracy: 0.6977\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "129/129 [==============================] - 3s 25ms/step - loss: 0.6315 - accuracy: 0.7817 - val_loss: 0.9861 - val_accuracy: 0.6866\n",
            "Epoch 2/2\n",
            "129/129 [==============================] - 3s 24ms/step - loss: 0.1617 - accuracy: 0.9485 - val_loss: 1.4070 - val_accuracy: 0.6970\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 32ms/step - loss: 0.3366 - accuracy: 0.8915 - val_loss: 1.0226 - val_accuracy: 0.7297\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 29ms/step - loss: 0.0605 - accuracy: 0.9875 - val_loss: 1.1547 - val_accuracy: 0.7351\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.2673 - accuracy: 0.9096 - val_loss: 1.1336 - val_accuracy: 0.7148\n",
            "Epoch 2/2\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0687 - accuracy: 0.9770 - val_loss: 1.3963 - val_accuracy: 0.7171\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 25ms/step - loss: 0.4905 - accuracy: 0.8414 - val_loss: 0.9096 - val_accuracy: 0.7292\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 19ms/step - loss: 0.1683 - accuracy: 0.9493 - val_loss: 1.0594 - val_accuracy: 0.7393\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 0.4828 - accuracy: 0.8371 - val_loss: 1.1198 - val_accuracy: 0.6810\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 24ms/step - loss: 0.1928 - accuracy: 0.9312 - val_loss: 1.2306 - val_accuracy: 0.7132\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.3169 - accuracy: 0.8902 - val_loss: 1.1440 - val_accuracy: 0.7257\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0852 - accuracy: 0.9788 - val_loss: 1.1452 - val_accuracy: 0.7347\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6589 - accuracy: 0.7748 - val_loss: 0.9553 - val_accuracy: 0.7043\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.2176 - accuracy: 0.9289 - val_loss: 1.1558 - val_accuracy: 0.7183\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6297 - accuracy: 0.7828 - val_loss: 0.8942 - val_accuracy: 0.7147\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.2502 - accuracy: 0.9147 - val_loss: 1.0595 - val_accuracy: 0.7221\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "140/140 [==============================] - 3s 21ms/step - loss: 0.5724 - accuracy: 0.8133 - val_loss: 0.9018 - val_accuracy: 0.7133\n",
            "Epoch 2/2\n",
            "140/140 [==============================] - 3s 19ms/step - loss: 0.1732 - accuracy: 0.9398 - val_loss: 1.1765 - val_accuracy: 0.7287\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 0.2520 - accuracy: 0.9013 - val_loss: 1.2170 - val_accuracy: 0.7169\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.1152 - accuracy: 0.9628 - val_loss: 1.2927 - val_accuracy: 0.7236\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.6240 - accuracy: 0.7899 - val_loss: 0.9207 - val_accuracy: 0.7161\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.2230 - accuracy: 0.9251 - val_loss: 1.1914 - val_accuracy: 0.7171\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 1.1674 - accuracy: 0.7003 - val_loss: 1.1281 - val_accuracy: 0.6669\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6965 - accuracy: 0.7608 - val_loss: 1.0001 - val_accuracy: 0.6825\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.5874 - accuracy: 0.7900 - val_loss: 0.8908 - val_accuracy: 0.7184\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.2998 - accuracy: 0.9097 - val_loss: 0.9236 - val_accuracy: 0.7288\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.1457 - accuracy: 0.9536 - val_loss: 0.9939 - val_accuracy: 0.7391\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0431 - accuracy: 0.9959 - val_loss: 1.0855 - val_accuracy: 0.7326\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 3s 30ms/step - loss: 0.6525 - accuracy: 0.7797 - val_loss: 0.9639 - val_accuracy: 0.7103\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 2s 29ms/step - loss: 0.1603 - accuracy: 0.9480 - val_loss: 1.1311 - val_accuracy: 0.7281\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.5815 - accuracy: 0.7975 - val_loss: 0.8661 - val_accuracy: 0.7314\n",
            "Epoch 2/2\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1906 - accuracy: 0.9365 - val_loss: 1.0007 - val_accuracy: 0.7429\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "110/110 [==============================] - 2s 23ms/step - loss: 0.3256 - accuracy: 0.8883 - val_loss: 1.0443 - val_accuracy: 0.7204\n",
            "Epoch 2/2\n",
            "110/110 [==============================] - 2s 22ms/step - loss: 0.0500 - accuracy: 0.9898 - val_loss: 1.1872 - val_accuracy: 0.7485\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.1927 - accuracy: 0.9384 - val_loss: 1.1156 - val_accuracy: 0.7457\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0586 - accuracy: 0.9866 - val_loss: 1.1251 - val_accuracy: 0.7524\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "144/144 [==============================] - 3s 23ms/step - loss: 0.6526 - accuracy: 0.7829 - val_loss: 0.9185 - val_accuracy: 0.7150\n",
            "Epoch 2/2\n",
            "144/144 [==============================] - 3s 22ms/step - loss: 0.1835 - accuracy: 0.9432 - val_loss: 1.1204 - val_accuracy: 0.7115\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.5121 - accuracy: 0.8243 - val_loss: 1.0321 - val_accuracy: 0.7006\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 15ms/step - loss: 0.1755 - accuracy: 0.9366 - val_loss: 1.2197 - val_accuracy: 0.7137\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 21ms/step - loss: 0.7931 - accuracy: 0.7400 - val_loss: 0.8379 - val_accuracy: 0.7186\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 3s 21ms/step - loss: 0.2977 - accuracy: 0.9010 - val_loss: 0.9799 - val_accuracy: 0.7375\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.2628 - accuracy: 0.9090 - val_loss: 1.0169 - val_accuracy: 0.7413\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 27ms/step - loss: 0.0407 - accuracy: 0.9936 - val_loss: 1.1321 - val_accuracy: 0.7484\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8681 - accuracy: 0.7726\n",
            "---------4------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 24ms/step - loss: 0.3489 - accuracy: 0.8771 - val_loss: 0.8604 - val_accuracy: 0.7617\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.1216 - accuracy: 0.9725 - val_loss: 0.9629 - val_accuracy: 0.7651\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 0.1278 - accuracy: 0.9582 - val_loss: 1.0139 - val_accuracy: 0.7665\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0398 - accuracy: 0.9924 - val_loss: 1.0973 - val_accuracy: 0.7662\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.2773 - accuracy: 0.9083 - val_loss: 0.9667 - val_accuracy: 0.7600\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0759 - accuracy: 0.9823 - val_loss: 1.1187 - val_accuracy: 0.7635\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "90/90 [==============================] - 3s 28ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 1.3574 - val_accuracy: 0.7445\n",
            "Epoch 2/2\n",
            "90/90 [==============================] - 2s 27ms/step - loss: 0.0587 - accuracy: 0.9818 - val_loss: 1.4336 - val_accuracy: 0.7353\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3202 - accuracy: 0.8885 - val_loss: 1.3154 - val_accuracy: 0.6958\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.1099 - accuracy: 0.9662 - val_loss: 1.3083 - val_accuracy: 0.7217\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "211/211 [==============================] - 3s 16ms/step - loss: 0.3774 - accuracy: 0.8722 - val_loss: 1.0740 - val_accuracy: 0.7117\n",
            "Epoch 2/2\n",
            "211/211 [==============================] - 3s 15ms/step - loss: 0.1232 - accuracy: 0.9602 - val_loss: 1.3221 - val_accuracy: 0.7201\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.3074 - accuracy: 0.9001 - val_loss: 1.0402 - val_accuracy: 0.7427\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0695 - accuracy: 0.9829 - val_loss: 1.1350 - val_accuracy: 0.7471\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1418 - accuracy: 0.9495 - val_loss: 1.3385 - val_accuracy: 0.7100\n",
            "Epoch 2/2\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 1.4107 - val_accuracy: 0.7383\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "129/129 [==============================] - 3s 25ms/step - loss: 0.4894 - accuracy: 0.8391 - val_loss: 1.1718 - val_accuracy: 0.6829\n",
            "Epoch 2/2\n",
            "129/129 [==============================] - 3s 24ms/step - loss: 0.1757 - accuracy: 0.9417 - val_loss: 1.3894 - val_accuracy: 0.6964\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.2604 - accuracy: 0.9034 - val_loss: 1.2343 - val_accuracy: 0.7186\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 29ms/step - loss: 0.0423 - accuracy: 0.9875 - val_loss: 1.3295 - val_accuracy: 0.7275\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.1588 - accuracy: 0.9497 - val_loss: 1.1619 - val_accuracy: 0.7364\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.0296 - accuracy: 0.9951 - val_loss: 1.2778 - val_accuracy: 0.7372\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 23ms/step - loss: 0.4397 - accuracy: 0.8601 - val_loss: 0.9273 - val_accuracy: 0.7350\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 19ms/step - loss: 0.1280 - accuracy: 0.9696 - val_loss: 1.0561 - val_accuracy: 0.7428\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.1580 - accuracy: 0.9464 - val_loss: 1.0980 - val_accuracy: 0.7451\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.0342 - accuracy: 0.9965 - val_loss: 1.1662 - val_accuracy: 0.7457\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "76/76 [==============================] - 2s 30ms/step - loss: 0.1387 - accuracy: 0.9565 - val_loss: 1.3308 - val_accuracy: 0.7269\n",
            "Epoch 2/2\n",
            "76/76 [==============================] - 2s 28ms/step - loss: 0.0612 - accuracy: 0.9814 - val_loss: 1.3036 - val_accuracy: 0.7376\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.5535 - accuracy: 0.8213 - val_loss: 1.0548 - val_accuracy: 0.6992\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 24ms/step - loss: 0.1593 - accuracy: 0.9469 - val_loss: 1.3126 - val_accuracy: 0.7155\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.5574 - accuracy: 0.8033 - val_loss: 0.9861 - val_accuracy: 0.6922\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.2149 - accuracy: 0.9319 - val_loss: 1.0666 - val_accuracy: 0.7072\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.4271 - accuracy: 0.8603 - val_loss: 1.1269 - val_accuracy: 0.6963\n",
            "Epoch 2/2\n",
            "107/107 [==============================] - 2s 22ms/step - loss: 0.0955 - accuracy: 0.9733 - val_loss: 1.2041 - val_accuracy: 0.7268\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 36ms/step - loss: 0.1399 - accuracy: 0.9506 - val_loss: 1.3396 - val_accuracy: 0.7218\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 2s 34ms/step - loss: 0.0197 - accuracy: 0.9977 - val_loss: 1.3736 - val_accuracy: 0.7298\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.6551 - accuracy: 0.7721 - val_loss: 0.8899 - val_accuracy: 0.7148\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 15ms/step - loss: 0.2025 - accuracy: 0.9337 - val_loss: 1.1097 - val_accuracy: 0.7204\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.8268 - accuracy: 0.7626 - val_loss: 0.9865 - val_accuracy: 0.7094\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.3543 - accuracy: 0.8827 - val_loss: 0.9057 - val_accuracy: 0.7260\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.5004 - accuracy: 0.8357 - val_loss: 0.9901 - val_accuracy: 0.7114\n",
            "Epoch 2/2\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.1103 - accuracy: 0.9711 - val_loss: 1.1374 - val_accuracy: 0.7342\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.1211 - accuracy: 0.9658 - val_loss: 1.1709 - val_accuracy: 0.7357\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0278 - accuracy: 0.9959 - val_loss: 1.1945 - val_accuracy: 0.7424\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "81/81 [==============================] - 3s 32ms/step - loss: 0.6743 - accuracy: 0.7778 - val_loss: 0.9374 - val_accuracy: 0.7048\n",
            "Epoch 2/2\n",
            "81/81 [==============================] - 2s 30ms/step - loss: 0.2102 - accuracy: 0.9311 - val_loss: 1.1014 - val_accuracy: 0.7229\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5611 - accuracy: 0.8094 - val_loss: 0.9680 - val_accuracy: 0.7193\n",
            "Epoch 2/2\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.1741 - accuracy: 0.9406 - val_loss: 1.1657 - val_accuracy: 0.7155\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "172/172 [==============================] - 3s 20ms/step - loss: 0.3420 - accuracy: 0.8825 - val_loss: 1.0806 - val_accuracy: 0.7151\n",
            "Epoch 2/2\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 0.1109 - accuracy: 0.9676 - val_loss: 1.3762 - val_accuracy: 0.7195\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3093 - accuracy: 0.9009 - val_loss: 1.0876 - val_accuracy: 0.7331\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0997 - accuracy: 0.9710 - val_loss: 1.0719 - val_accuracy: 0.7421\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.4452 - accuracy: 0.8554 - val_loss: 0.9971 - val_accuracy: 0.7326\n",
            "Epoch 2/2\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.1546 - accuracy: 0.9567 - val_loss: 1.0166 - val_accuracy: 0.7455\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4843 - accuracy: 0.8383 - val_loss: 1.1419 - val_accuracy: 0.6629\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1357 - accuracy: 0.9549 - val_loss: 1.3270 - val_accuracy: 0.7197\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "164/164 [==============================] - 3s 18ms/step - loss: 0.7684 - accuracy: 0.7503 - val_loss: 0.8914 - val_accuracy: 0.7171\n",
            "Epoch 2/2\n",
            "164/164 [==============================] - 3s 17ms/step - loss: 0.2717 - accuracy: 0.9013 - val_loss: 1.0521 - val_accuracy: 0.7132\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.2709 - accuracy: 0.9061 - val_loss: 1.0962 - val_accuracy: 0.7258\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0498 - accuracy: 0.9907 - val_loss: 1.1246 - val_accuracy: 0.7375\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9387 - accuracy: 0.7678\n",
            "---------5------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.2369 - accuracy: 0.9194 - val_loss: 0.9568 - val_accuracy: 0.7650\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0599 - accuracy: 0.9908 - val_loss: 1.0917 - val_accuracy: 0.7637\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 24ms/step - loss: 0.0889 - accuracy: 0.9689 - val_loss: 1.1326 - val_accuracy: 0.7609\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 21ms/step - loss: 0.0174 - accuracy: 0.9997 - val_loss: 1.2236 - val_accuracy: 0.7667\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 21ms/step - loss: 0.2081 - accuracy: 0.9257 - val_loss: 1.0762 - val_accuracy: 0.7602\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0424 - accuracy: 0.9922 - val_loss: 1.2341 - val_accuracy: 0.7630\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 1.3841 - val_accuracy: 0.7613\n",
            "Epoch 2/2\n",
            "69/69 [==============================] - 2s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.7623\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.1907 - accuracy: 0.9303 - val_loss: 1.4923 - val_accuracy: 0.7097\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.1111 - accuracy: 0.9632 - val_loss: 1.4635 - val_accuracy: 0.7101\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.1903 - accuracy: 0.9356 - val_loss: 1.2094 - val_accuracy: 0.7339\n",
            "Epoch 2/2\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 1.5015 - val_accuracy: 0.7306\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.1629 - accuracy: 0.9449 - val_loss: 1.2849 - val_accuracy: 0.7438\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0275 - accuracy: 0.9950 - val_loss: 1.3505 - val_accuracy: 0.7498\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1127 - accuracy: 0.9613 - val_loss: 1.5137 - val_accuracy: 0.7147\n",
            "Epoch 2/2\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 1.5582 - val_accuracy: 0.7372\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.2186 - accuracy: 0.9295 - val_loss: 1.4204 - val_accuracy: 0.7311\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 1.3762 - val_accuracy: 0.7357\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 1.4365 - val_accuracy: 0.7368\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 29ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 1.5332 - val_accuracy: 0.7393\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.1354 - accuracy: 0.9599 - val_loss: 1.3243 - val_accuracy: 0.7381\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 1.4365 - val_accuracy: 0.7422\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "225/225 [==============================] - 4s 17ms/step - loss: 0.6423 - accuracy: 0.7820 - val_loss: 1.0725 - val_accuracy: 0.6810\n",
            "Epoch 2/2\n",
            "225/225 [==============================] - 4s 16ms/step - loss: 0.2365 - accuracy: 0.9233 - val_loss: 1.4015 - val_accuracy: 0.6607\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4721 - accuracy: 0.8432 - val_loss: 1.0025 - val_accuracy: 0.7198\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.1500 - accuracy: 0.9570 - val_loss: 1.0309 - val_accuracy: 0.7283\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.1906 - accuracy: 0.9316 - val_loss: 1.0991 - val_accuracy: 0.7359\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0465 - accuracy: 0.9936 - val_loss: 1.1889 - val_accuracy: 0.7386\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.2862 - accuracy: 0.9084 - val_loss: 1.0854 - val_accuracy: 0.7333\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0725 - accuracy: 0.9865 - val_loss: 1.1287 - val_accuracy: 0.7403\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.4919 - accuracy: 0.8281 - val_loss: 1.0507 - val_accuracy: 0.6997\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.1626 - accuracy: 0.9432 - val_loss: 1.2191 - val_accuracy: 0.7209\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.3967 - accuracy: 0.8660 - val_loss: 0.9894 - val_accuracy: 0.7353\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.1234 - accuracy: 0.9695 - val_loss: 1.0528 - val_accuracy: 0.7392\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 2s 36ms/step - loss: 0.1098 - accuracy: 0.9636 - val_loss: 1.3260 - val_accuracy: 0.7289\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 1.3254 - val_accuracy: 0.7422\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.5483 - accuracy: 0.8116 - val_loss: 0.9409 - val_accuracy: 0.7124\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.1699 - accuracy: 0.9413 - val_loss: 1.2751 - val_accuracy: 0.7194\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.9034 - accuracy: 0.7644 - val_loss: 0.9927 - val_accuracy: 0.7187\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.3660 - accuracy: 0.8753 - val_loss: 0.9403 - val_accuracy: 0.7199\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 0.4016 - accuracy: 0.8472 - val_loss: 0.9060 - val_accuracy: 0.7378\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.1522 - accuracy: 0.9627 - val_loss: 0.9550 - val_accuracy: 0.7407\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.0496 - accuracy: 0.9902 - val_loss: 1.0649 - val_accuracy: 0.7436\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.7434\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.3882 - accuracy: 0.8759 - val_loss: 1.0366 - val_accuracy: 0.7426\n",
            "Epoch 2/2\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.1275 - accuracy: 0.9688 - val_loss: 1.0819 - val_accuracy: 0.7431\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.4867 - accuracy: 0.8366 - val_loss: 0.8902 - val_accuracy: 0.7290\n",
            "Epoch 2/2\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1485 - accuracy: 0.9498 - val_loss: 1.1943 - val_accuracy: 0.7297\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 0.2999 - accuracy: 0.8999 - val_loss: 1.0506 - val_accuracy: 0.7301\n",
            "Epoch 2/2\n",
            "110/110 [==============================] - 2s 22ms/step - loss: 0.0556 - accuracy: 0.9851 - val_loss: 1.2282 - val_accuracy: 0.7373\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.2318 - accuracy: 0.9224 - val_loss: 1.1292 - val_accuracy: 0.7490\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0756 - accuracy: 0.9822 - val_loss: 1.1178 - val_accuracy: 0.7474\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "121/121 [==============================] - 3s 23ms/step - loss: 0.3970 - accuracy: 0.8720 - val_loss: 0.9831 - val_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "121/121 [==============================] - 3s 22ms/step - loss: 0.0962 - accuracy: 0.9703 - val_loss: 1.2447 - val_accuracy: 0.7335\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4537 - accuracy: 0.8455 - val_loss: 1.0357 - val_accuracy: 0.6972\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1498 - accuracy: 0.9516 - val_loss: 1.2904 - val_accuracy: 0.7043\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.7928 - accuracy: 0.7626 - val_loss: 0.8781 - val_accuracy: 0.7216\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.4361 - accuracy: 0.8494 - val_loss: 0.9121 - val_accuracy: 0.7292\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.1771 - accuracy: 0.9450 - val_loss: 1.0312 - val_accuracy: 0.7387\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 28ms/step - loss: 0.0221 - accuracy: 0.9988 - val_loss: 1.1394 - val_accuracy: 0.7418\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9891 - accuracy: 0.7647\n",
            "---------6------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.1693 - accuracy: 0.9417 - val_loss: 1.0754 - val_accuracy: 0.7647\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0327 - accuracy: 0.9956 - val_loss: 1.1636 - val_accuracy: 0.7647\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 1.2488 - val_accuracy: 0.7625\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.7659\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 21ms/step - loss: 0.1541 - accuracy: 0.9464 - val_loss: 1.2077 - val_accuracy: 0.7592\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0276 - accuracy: 0.9970 - val_loss: 1.3455 - val_accuracy: 0.7603\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 1.4064 - val_accuracy: 0.7562\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 1.4182 - val_accuracy: 0.7580\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.1213 - accuracy: 0.9592 - val_loss: 1.5504 - val_accuracy: 0.6993\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.0971 - accuracy: 0.9691 - val_loss: 1.8469 - val_accuracy: 0.7147\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 21ms/step - loss: 0.1687 - accuracy: 0.9456 - val_loss: 1.4183 - val_accuracy: 0.7384\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 1.4451 - val_accuracy: 0.7451\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.1495 - accuracy: 0.9475 - val_loss: 1.3379 - val_accuracy: 0.7470\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0178 - accuracy: 0.9979 - val_loss: 1.4036 - val_accuracy: 0.7534\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "53/53 [==============================] - 1s 20ms/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 1.5026 - val_accuracy: 0.7485\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5600 - val_accuracy: 0.7499\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.1218 - accuracy: 0.9596 - val_loss: 1.5204 - val_accuracy: 0.7433\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 1.4919 - val_accuracy: 0.7458\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 1.5385 - val_accuracy: 0.7504\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6106 - val_accuracy: 0.7494\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.2163 - accuracy: 0.9337 - val_loss: 1.4248 - val_accuracy: 0.7033\n",
            "Epoch 2/2\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.1203 - accuracy: 0.9591 - val_loss: 1.4450 - val_accuracy: 0.7248\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 23ms/step - loss: 0.2456 - accuracy: 0.9144 - val_loss: 1.1805 - val_accuracy: 0.7314\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 20ms/step - loss: 0.0436 - accuracy: 0.9902 - val_loss: 1.2586 - val_accuracy: 0.7452\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 25ms/step - loss: 0.3113 - accuracy: 0.8958 - val_loss: 1.2603 - val_accuracy: 0.7036\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 3s 24ms/step - loss: 0.1198 - accuracy: 0.9605 - val_loss: 1.3825 - val_accuracy: 0.7074\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "76/76 [==============================] - 2s 30ms/step - loss: 0.2497 - accuracy: 0.9098 - val_loss: 1.3510 - val_accuracy: 0.7137\n",
            "Epoch 2/2\n",
            "76/76 [==============================] - 2s 29ms/step - loss: 0.0476 - accuracy: 0.9867 - val_loss: 1.4224 - val_accuracy: 0.7315\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.2872 - accuracy: 0.9044 - val_loss: 1.1852 - val_accuracy: 0.7378\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0578 - accuracy: 0.9895 - val_loss: 1.2050 - val_accuracy: 0.7391\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.4019 - accuracy: 0.8594 - val_loss: 1.1279 - val_accuracy: 0.7098\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.1310 - accuracy: 0.9540 - val_loss: 1.3915 - val_accuracy: 0.7050\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4258 - accuracy: 0.8656 - val_loss: 1.0827 - val_accuracy: 0.7254\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.1260 - accuracy: 0.9665 - val_loss: 1.1284 - val_accuracy: 0.7359\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 36ms/step - loss: 0.0777 - accuracy: 0.9757 - val_loss: 1.3321 - val_accuracy: 0.7248\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 2s 34ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3859 - val_accuracy: 0.7372\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.4776 - accuracy: 0.8334 - val_loss: 1.0791 - val_accuracy: 0.6972\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.1421 - accuracy: 0.9528 - val_loss: 1.2910 - val_accuracy: 0.7100\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.8407 - accuracy: 0.7406 - val_loss: 0.9463 - val_accuracy: 0.6936\n",
            "Epoch 2/2\n",
            "44/44 [==============================] - 2s 45ms/step - loss: 0.2244 - accuracy: 0.9340 - val_loss: 1.0231 - val_accuracy: 0.7168\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.3978 - accuracy: 0.8700 - val_loss: 1.0227 - val_accuracy: 0.7365\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.1386 - accuracy: 0.9597 - val_loss: 1.0564 - val_accuracy: 0.7404\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 0.0496 - accuracy: 0.9870 - val_loss: 1.1501 - val_accuracy: 0.7433\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.7418\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.4143 - accuracy: 0.8668 - val_loss: 1.0578 - val_accuracy: 0.7412\n",
            "Epoch 2/2\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.1294 - accuracy: 0.9695 - val_loss: 1.1183 - val_accuracy: 0.7420\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4441 - accuracy: 0.8523 - val_loss: 0.9486 - val_accuracy: 0.7262\n",
            "Epoch 2/2\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.1075 - accuracy: 0.9710 - val_loss: 1.1438 - val_accuracy: 0.7494\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 0.2294 - accuracy: 0.9254 - val_loss: 1.0795 - val_accuracy: 0.7473\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 0.0492 - accuracy: 0.9905 - val_loss: 1.1295 - val_accuracy: 0.7520\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.1808 - accuracy: 0.9450 - val_loss: 1.1056 - val_accuracy: 0.7494\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0656 - accuracy: 0.9837 - val_loss: 1.1155 - val_accuracy: 0.7552\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.2006 - accuracy: 0.9292 - val_loss: 1.0534 - val_accuracy: 0.7518\n",
            "Epoch 2/2\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0428 - accuracy: 0.9952 - val_loss: 1.1177 - val_accuracy: 0.7536\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.3862 - accuracy: 0.8745 - val_loss: 1.1696 - val_accuracy: 0.6976\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1495 - accuracy: 0.9519 - val_loss: 1.3340 - val_accuracy: 0.7065\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.7637 - accuracy: 0.7771 - val_loss: 0.9566 - val_accuracy: 0.7239\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3211 - accuracy: 0.8932 - val_loss: 1.0026 - val_accuracy: 0.7307\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 30ms/step - loss: 0.1381 - accuracy: 0.9502 - val_loss: 1.1328 - val_accuracy: 0.7369\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0221 - accuracy: 0.9959 - val_loss: 1.1838 - val_accuracy: 0.7396\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0582 - accuracy: 0.7678\n",
            "---------7------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 25ms/step - loss: 0.1166 - accuracy: 0.9669 - val_loss: 1.1579 - val_accuracy: 0.7662\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0227 - accuracy: 0.9992 - val_loss: 1.2508 - val_accuracy: 0.7659\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 0.0216 - accuracy: 0.9955 - val_loss: 1.2706 - val_accuracy: 0.7689\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3204 - val_accuracy: 0.7686\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.2567 - accuracy: 0.9090 - val_loss: 1.2298 - val_accuracy: 0.7200\n",
            "Epoch 2/2\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.1555 - accuracy: 0.9434 - val_loss: 1.3649 - val_accuracy: 0.7308\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 0.0878 - accuracy: 0.9654 - val_loss: 1.3085 - val_accuracy: 0.7403\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 1.3314 - val_accuracy: 0.7455\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.1106 - accuracy: 0.9647 - val_loss: 1.7078 - val_accuracy: 0.6881\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.0646 - accuracy: 0.9766 - val_loss: 1.6677 - val_accuracy: 0.7237\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "211/211 [==============================] - 3s 16ms/step - loss: 0.2553 - accuracy: 0.9103 - val_loss: 1.4476 - val_accuracy: 0.7062\n",
            "Epoch 2/2\n",
            "211/211 [==============================] - 3s 16ms/step - loss: 0.0755 - accuracy: 0.9732 - val_loss: 1.6309 - val_accuracy: 0.7242\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.2283 - accuracy: 0.9290 - val_loss: 1.3074 - val_accuracy: 0.7326\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0376 - accuracy: 0.9915 - val_loss: 1.3858 - val_accuracy: 0.7401\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 23ms/step - loss: 0.0617 - accuracy: 0.9798 - val_loss: 1.4124 - val_accuracy: 0.7410\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 1.4808 - val_accuracy: 0.7418\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1510 - accuracy: 0.9480 - val_loss: 1.4528 - val_accuracy: 0.7438\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 1.4710 - val_accuracy: 0.7427\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 1.5326 - val_accuracy: 0.7459\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5683 - val_accuracy: 0.7471\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0639 - accuracy: 0.9802 - val_loss: 1.5474 - val_accuracy: 0.7471\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 1.5769 - val_accuracy: 0.7488\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 22ms/step - loss: 0.2274 - accuracy: 0.9278 - val_loss: 1.2933 - val_accuracy: 0.7407\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 20ms/step - loss: 0.0343 - accuracy: 0.9928 - val_loss: 1.3599 - val_accuracy: 0.7476\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 1.3974 - val_accuracy: 0.7444\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.7458\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 1.4952 - val_accuracy: 0.7506\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5186 - val_accuracy: 0.7504\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1971 - accuracy: 0.9319 - val_loss: 1.3632 - val_accuracy: 0.7423\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0396 - accuracy: 0.9925 - val_loss: 1.3737 - val_accuracy: 0.7439\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.3654 - accuracy: 0.8771 - val_loss: 1.2714 - val_accuracy: 0.7046\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.1090 - accuracy: 0.9640 - val_loss: 1.4500 - val_accuracy: 0.7151\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4313 - accuracy: 0.8637 - val_loss: 1.1259 - val_accuracy: 0.7346\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.1151 - accuracy: 0.9661 - val_loss: 1.1794 - val_accuracy: 0.7392\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 2s 36ms/step - loss: 0.0887 - accuracy: 0.9727 - val_loss: 1.3954 - val_accuracy: 0.7285\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0227 - accuracy: 0.9947 - val_loss: 1.4980 - val_accuracy: 0.7351\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.4716 - accuracy: 0.8460 - val_loss: 1.2521 - val_accuracy: 0.6764\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.1575 - accuracy: 0.9510 - val_loss: 1.2695 - val_accuracy: 0.7200\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.7483 - accuracy: 0.7910 - val_loss: 1.1050 - val_accuracy: 0.7181\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.2851 - accuracy: 0.9120 - val_loss: 1.0392 - val_accuracy: 0.7243\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.3481 - accuracy: 0.8797 - val_loss: 1.0340 - val_accuracy: 0.7312\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 0.1103 - accuracy: 0.9735 - val_loss: 1.0525 - val_accuracy: 0.7371\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 1.1302 - val_accuracy: 0.7375\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1792 - val_accuracy: 0.7369\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 36ms/step - loss: 0.2696 - accuracy: 0.8947 - val_loss: 1.2125 - val_accuracy: 0.7275\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 2s 33ms/step - loss: 0.0532 - accuracy: 0.9857 - val_loss: 1.3252 - val_accuracy: 0.7325\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "142/142 [==============================] - 2s 18ms/step - loss: 0.4506 - accuracy: 0.8575 - val_loss: 1.0179 - val_accuracy: 0.7196\n",
            "Epoch 2/2\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 1.2261 - val_accuracy: 0.7385\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.2549 - accuracy: 0.9079 - val_loss: 1.1411 - val_accuracy: 0.7258\n",
            "Epoch 2/2\n",
            "110/110 [==============================] - 2s 22ms/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 1.3377 - val_accuracy: 0.7436\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.2406 - accuracy: 0.9306 - val_loss: 1.1943 - val_accuracy: 0.7483\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0577 - accuracy: 0.9848 - val_loss: 1.1880 - val_accuracy: 0.7515\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "121/121 [==============================] - 3s 24ms/step - loss: 0.5046 - accuracy: 0.8370 - val_loss: 0.9726 - val_accuracy: 0.7111\n",
            "Epoch 2/2\n",
            "121/121 [==============================] - 3s 22ms/step - loss: 0.1055 - accuracy: 0.9664 - val_loss: 1.1911 - val_accuracy: 0.7287\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 17ms/step - loss: 0.3551 - accuracy: 0.8768 - val_loss: 1.2022 - val_accuracy: 0.7197\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1531 - accuracy: 0.9448 - val_loss: 1.4403 - val_accuracy: 0.7032\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.8042 - accuracy: 0.7655 - val_loss: 0.9330 - val_accuracy: 0.7127\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.3480 - accuracy: 0.8903 - val_loss: 0.9842 - val_accuracy: 0.7268\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.1675 - accuracy: 0.9421 - val_loss: 1.1198 - val_accuracy: 0.7299\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.0187 - accuracy: 0.9988 - val_loss: 1.2083 - val_accuracy: 0.7342\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1159 - accuracy: 0.7659\n",
            "---------8------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 25ms/step - loss: 0.1125 - accuracy: 0.9597 - val_loss: 1.2217 - val_accuracy: 0.7598\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 22ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 1.3093 - val_accuracy: 0.7661\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 1.3572 - val_accuracy: 0.7674\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3819 - val_accuracy: 0.7648\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 21ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 1.4094 - val_accuracy: 0.7648\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 1.4604 - val_accuracy: 0.7661\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4818 - val_accuracy: 0.7661\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4978 - val_accuracy: 0.7667\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 1.6027 - val_accuracy: 0.7531\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.6338 - val_accuracy: 0.7557\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "211/211 [==============================] - 4s 17ms/step - loss: 0.1275 - accuracy: 0.9629 - val_loss: 1.5890 - val_accuracy: 0.7174\n",
            "Epoch 2/2\n",
            "211/211 [==============================] - 3s 16ms/step - loss: 0.1248 - accuracy: 0.9544 - val_loss: 1.6202 - val_accuracy: 0.7119\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 25ms/step - loss: 0.2418 - accuracy: 0.9192 - val_loss: 1.3426 - val_accuracy: 0.7343\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0331 - accuracy: 0.9920 - val_loss: 1.4137 - val_accuracy: 0.7410\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 1.5079 - val_accuracy: 0.7132\n",
            "Epoch 2/2\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 1.7056 - val_accuracy: 0.7266\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.2135 - accuracy: 0.9290 - val_loss: 1.6087 - val_accuracy: 0.7299\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 1.5716 - val_accuracy: 0.7359\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 1.7583 - val_accuracy: 0.7286\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 1.7348 - val_accuracy: 0.7365\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2671 - accuracy: 0.9123 - val_loss: 1.2678 - val_accuracy: 0.7025\n",
            "Epoch 2/2\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1298 - accuracy: 0.9564 - val_loss: 1.7058 - val_accuracy: 0.6960\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 23ms/step - loss: 0.4451 - accuracy: 0.8631 - val_loss: 1.1404 - val_accuracy: 0.7246\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 20ms/step - loss: 0.0968 - accuracy: 0.9744 - val_loss: 1.2394 - val_accuracy: 0.7329\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.1464 - accuracy: 0.9454 - val_loss: 1.2599 - val_accuracy: 0.7342\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.0269 - accuracy: 0.9970 - val_loss: 1.3045 - val_accuracy: 0.7352\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.1086 - accuracy: 0.9597 - val_loss: 1.3368 - val_accuracy: 0.7370\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0168 - accuracy: 0.9984 - val_loss: 1.3920 - val_accuracy: 0.7411\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.2093 - accuracy: 0.9189 - val_loss: 1.3494 - val_accuracy: 0.7382\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0423 - accuracy: 0.9900 - val_loss: 1.3552 - val_accuracy: 0.7402\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.3307 - accuracy: 0.8916 - val_loss: 1.2534 - val_accuracy: 0.6998\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.1124 - accuracy: 0.9630 - val_loss: 1.5152 - val_accuracy: 0.7125\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4316 - accuracy: 0.8694 - val_loss: 1.1636 - val_accuracy: 0.7329\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.1082 - accuracy: 0.9657 - val_loss: 1.1904 - val_accuracy: 0.7377\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 36ms/step - loss: 0.0956 - accuracy: 0.9658 - val_loss: 1.3258 - val_accuracy: 0.7355\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 2s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4621 - val_accuracy: 0.7396\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 4s 17ms/step - loss: 0.3850 - accuracy: 0.8687 - val_loss: 1.0522 - val_accuracy: 0.7211\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 3s 16ms/step - loss: 0.1058 - accuracy: 0.9620 - val_loss: 1.4498 - val_accuracy: 0.7111\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.7673 - accuracy: 0.7974 - val_loss: 1.2642 - val_accuracy: 0.7190\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.2394 - accuracy: 0.9157 - val_loss: 1.1380 - val_accuracy: 0.7180\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.3428 - accuracy: 0.8857 - val_loss: 1.1002 - val_accuracy: 0.7349\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.0836 - accuracy: 0.9801 - val_loss: 1.1398 - val_accuracy: 0.7383\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 0.0324 - accuracy: 0.9927 - val_loss: 1.1839 - val_accuracy: 0.7424\n",
            "Epoch 2/2\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.7423\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 37ms/step - loss: 0.3274 - accuracy: 0.8915 - val_loss: 1.1931 - val_accuracy: 0.7243\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 2s 34ms/step - loss: 0.0770 - accuracy: 0.9760 - val_loss: 1.3124 - val_accuracy: 0.7392\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4269 - accuracy: 0.8651 - val_loss: 1.0755 - val_accuracy: 0.7227\n",
            "Epoch 2/2\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.0895 - accuracy: 0.9734 - val_loss: 1.2296 - val_accuracy: 0.7416\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1992 - accuracy: 0.9294 - val_loss: 1.1406 - val_accuracy: 0.7446\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 0.0404 - accuracy: 0.9927 - val_loss: 1.2212 - val_accuracy: 0.7498\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.1843 - accuracy: 0.9387 - val_loss: 1.1928 - val_accuracy: 0.7473\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0552 - accuracy: 0.9874 - val_loss: 1.2191 - val_accuracy: 0.7510\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "33/33 [==============================] - 1s 33ms/step - loss: 0.2254 - accuracy: 0.9262 - val_loss: 1.2019 - val_accuracy: 0.7426\n",
            "Epoch 2/2\n",
            "33/33 [==============================] - 1s 25ms/step - loss: 0.0449 - accuracy: 0.9908 - val_loss: 1.2233 - val_accuracy: 0.7476\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.3135 - accuracy: 0.8961 - val_loss: 1.2562 - val_accuracy: 0.7162\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1407 - accuracy: 0.9544 - val_loss: 1.5334 - val_accuracy: 0.7038\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.7935 - accuracy: 0.7742 - val_loss: 0.9796 - val_accuracy: 0.7272\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.2538 - accuracy: 0.9245 - val_loss: 1.0569 - val_accuracy: 0.7388\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 0.1087 - accuracy: 0.9606 - val_loss: 1.2333 - val_accuracy: 0.7432\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0133 - accuracy: 0.9988 - val_loss: 1.3074 - val_accuracy: 0.7458\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1621 - accuracy: 0.7615\n",
            "---------9------------\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 26ms/step - loss: 0.0903 - accuracy: 0.9685 - val_loss: 1.2924 - val_accuracy: 0.7610\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.7620\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 1.4183 - val_accuracy: 0.7637\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4330 - val_accuracy: 0.7633\n",
            "[1. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "47/47 [==============================] - 1s 22ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 1.4662 - val_accuracy: 0.7610\n",
            "Epoch 2/2\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 1.5909 - val_accuracy: 0.7579\n",
            "[1. 2. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 1.5672 - val_accuracy: 0.7609\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5629 - val_accuracy: 0.7630\n",
            "[1. 3. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.0414 - accuracy: 0.9841 - val_loss: 2.0423 - val_accuracy: 0.7250\n",
            "Epoch 2/2\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.1758 - accuracy: 0.9472 - val_loss: 1.6503 - val_accuracy: 0.7105\n",
            "[1. 3. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0942 - accuracy: 0.9697 - val_loss: 1.5287 - val_accuracy: 0.7237\n",
            "Epoch 2/2\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 1.6974 - val_accuracy: 0.7280\n",
            "[1. 4. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.1288 - accuracy: 0.9573 - val_loss: 1.5342 - val_accuracy: 0.7476\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 1.5810 - val_accuracy: 0.7452\n",
            "[1. 5. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 22ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 1.5698 - val_accuracy: 0.7500\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 1.5980 - val_accuracy: 0.7495\n",
            "[1. 6. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "109/109 [==============================] - 3s 26ms/step - loss: 0.1796 - accuracy: 0.9417 - val_loss: 1.7217 - val_accuracy: 0.7055\n",
            "Epoch 2/2\n",
            "109/109 [==============================] - 3s 24ms/step - loss: 0.1800 - accuracy: 0.9421 - val_loss: 1.5832 - val_accuracy: 0.6888\n",
            "[1. 7. 1. 0. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 33ms/step - loss: 0.2477 - accuracy: 0.9178 - val_loss: 1.4448 - val_accuracy: 0.7191\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 1.5277 - val_accuracy: 0.7282\n",
            "[1. 7. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "43/43 [==============================] - 1s 23ms/step - loss: 0.0729 - accuracy: 0.9770 - val_loss: 1.4989 - val_accuracy: 0.7347\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 1.5247 - val_accuracy: 0.7384\n",
            "[1. 8. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 23ms/step - loss: 0.2681 - accuracy: 0.9113 - val_loss: 1.2317 - val_accuracy: 0.7395\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 20ms/step - loss: 0.0471 - accuracy: 0.9886 - val_loss: 1.3353 - val_accuracy: 0.7411\n",
            "[1. 9. 1. 1. 0. 0. 0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.0911 - accuracy: 0.9676 - val_loss: 1.3860 - val_accuracy: 0.7407\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 1.4570 - val_accuracy: 0.7422\n",
            "[ 1. 10.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "76/76 [==============================] - 2s 31ms/step - loss: 0.1107 - accuracy: 0.9570 - val_loss: 1.6893 - val_accuracy: 0.7341\n",
            "Epoch 2/2\n",
            "76/76 [==============================] - 2s 29ms/step - loss: 0.0926 - accuracy: 0.9687 - val_loss: 1.6265 - val_accuracy: 0.7183\n",
            "[ 1. 11.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.3446 - accuracy: 0.8959 - val_loss: 1.3345 - val_accuracy: 0.7298\n",
            "Epoch 2/2\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0665 - accuracy: 0.9820 - val_loss: 1.3429 - val_accuracy: 0.7329\n",
            "[ 1. 12.  1.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.2714 - accuracy: 0.9092 - val_loss: 1.5839 - val_accuracy: 0.6853\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.1584 - accuracy: 0.9482 - val_loss: 1.5507 - val_accuracy: 0.7131\n",
            "[ 1. 12.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 0.4151 - accuracy: 0.8739 - val_loss: 1.1687 - val_accuracy: 0.7261\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 1.2251 - val_accuracy: 0.7327\n",
            "[ 1. 13.  2.  1.  0.  0.  0.]\n",
            "Epoch 1/2\n",
            "48/48 [==============================] - 2s 37ms/step - loss: 0.0611 - accuracy: 0.9795 - val_loss: 1.4452 - val_accuracy: 0.7311\n",
            "Epoch 2/2\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.4829 - val_accuracy: 0.7381\n",
            "[ 1. 13.  2.  1.  1.  0.  0.]\n",
            "Epoch 1/2\n",
            "213/213 [==============================] - 4s 17ms/step - loss: 0.3912 - accuracy: 0.8611 - val_loss: 1.0868 - val_accuracy: 0.7138\n",
            "Epoch 2/2\n",
            "213/213 [==============================] - 4s 16ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 1.5086 - val_accuracy: 0.6907\n",
            "[ 1. 13.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.7691 - accuracy: 0.7974 - val_loss: 1.2620 - val_accuracy: 0.7149\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.2751 - accuracy: 0.9184 - val_loss: 1.1938 - val_accuracy: 0.7110\n",
            "[ 1. 14.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 0.3239 - accuracy: 0.8869 - val_loss: 1.1466 - val_accuracy: 0.7317\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.0839 - accuracy: 0.9807 - val_loss: 1.1535 - val_accuracy: 0.7384\n",
            "[ 1. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.0254 - accuracy: 0.9959 - val_loss: 1.2008 - val_accuracy: 0.7410\n",
            "Epoch 2/2\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.7411\n",
            "[ 2. 15.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.2674 - accuracy: 0.9025 - val_loss: 1.2432 - val_accuracy: 0.7398\n",
            "Epoch 2/2\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0524 - accuracy: 0.9916 - val_loss: 1.2705 - val_accuracy: 0.7405\n",
            "[ 2. 16.  2.  1.  1.  1.  0.]\n",
            "Epoch 1/2\n",
            "142/142 [==============================] - 2s 18ms/step - loss: 0.4016 - accuracy: 0.8664 - val_loss: 1.0704 - val_accuracy: 0.7174\n",
            "Epoch 2/2\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0952 - accuracy: 0.9693 - val_loss: 1.3583 - val_accuracy: 0.7366\n",
            "[ 2. 16.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2057 - accuracy: 0.9338 - val_loss: 1.1664 - val_accuracy: 0.7383\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 0.0512 - accuracy: 0.9887 - val_loss: 1.2076 - val_accuracy: 0.7488\n",
            "[ 2. 17.  2.  1.  2.  1.  0.]\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.1554 - accuracy: 0.9514 - val_loss: 1.2051 - val_accuracy: 0.7479\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.0447 - accuracy: 0.9922 - val_loss: 1.1925 - val_accuracy: 0.7530\n",
            "[ 2. 17.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "33/33 [==============================] - 1s 29ms/step - loss: 0.2198 - accuracy: 0.9214 - val_loss: 1.1650 - val_accuracy: 0.7420\n",
            "Epoch 2/2\n",
            "33/33 [==============================] - 1s 26ms/step - loss: 0.0419 - accuracy: 0.9913 - val_loss: 1.2088 - val_accuracy: 0.7461\n",
            "[ 2. 18.  2.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "246/246 [==============================] - 4s 18ms/step - loss: 0.2830 - accuracy: 0.9045 - val_loss: 1.4758 - val_accuracy: 0.6966\n",
            "Epoch 2/2\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.1488 - accuracy: 0.9524 - val_loss: 1.7036 - val_accuracy: 0.7055\n",
            "[ 2. 18.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.8025 - accuracy: 0.7835 - val_loss: 1.0066 - val_accuracy: 0.7227\n",
            "Epoch 2/2\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.2891 - accuracy: 0.9116 - val_loss: 1.0318 - val_accuracy: 0.7339\n",
            "[ 2. 19.  3.  1.  2.  1.  1.]\n",
            "Epoch 1/2\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.1275 - accuracy: 0.9594 - val_loss: 1.1926 - val_accuracy: 0.7263\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 1.2253 - val_accuracy: 0.7418\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1962 - accuracy: 0.7624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cu0s25cq7uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091a64b6-4c8a-4649-b811-3bef75198dfb"
      },
      "source": [
        "len(batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0UewZMpo0SG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58ea8b9-de97-41ec-8829-dc1e82fb94c2"
      },
      "source": [
        "batch_global"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[59, 51],\n",
              " [86, 86, 86, 25, 86, 86, 19, 86, 86, 86, 25, 86, 86, 86, 86, 86, 86, 70, 86],\n",
              " [16, 16, 16],\n",
              " [38, 34],\n",
              " [28, 26],\n",
              " [18],\n",
              " [121]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5gGXFwoXzCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ad94b2-c077-44de-83c5-55e97347eeb2"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1724d8a1d0>,\n",
              "  1.9714575439424883e-07,\n",
              "  1.377,\n",
              "  59),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1724f8a450>,\n",
              "  4.532186668506956e-06,\n",
              "  1.433,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a4cf7d0>,\n",
              "  5.4839458688934165e-06,\n",
              "  1.5909,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a20a6c50>,\n",
              "  5.962898333850164e-06,\n",
              "  1.5629,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a2fbb10>,\n",
              "  6.953290948085145e-07,\n",
              "  1.6503,\n",
              "  16),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1724f0ad90>,\n",
              "  4.985405335357651e-06,\n",
              "  1.6974,\n",
              "  25),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17248e4f50>,\n",
              "  5.035762965007729e-06,\n",
              "  1.581,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17248b6050>,\n",
              "  5.4839458688934165e-06,\n",
              "  1.598,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a7f7890>,\n",
              "  4.985405335357651e-06,\n",
              "  1.5832,\n",
              "  19),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a53d390>,\n",
              "  0.0006493230231798845,\n",
              "  1.5277,\n",
              "  38),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a22ac910>,\n",
              "  5.3666085004651485e-06,\n",
              "  1.5247,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a259bc50>,\n",
              "  5.6605511811488384e-05,\n",
              "  1.3353,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a226acd0>,\n",
              "  5.1459556192262165e-05,\n",
              "  1.457,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a2773c50>,\n",
              "  5.035762965007729e-06,\n",
              "  1.6265,\n",
              "  25),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a240c50>,\n",
              "  4.935551282004075e-06,\n",
              "  1.3429,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a21a9d10>,\n",
              "  6.953290948085145e-07,\n",
              "  1.5507,\n",
              "  16),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a7d70d0>,\n",
              "  4.3908615003805756e-06,\n",
              "  1.2251,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a20578d0>,\n",
              "  1.0927227001504459e-07,\n",
              "  1.4829,\n",
              "  28),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17249ed850>,\n",
              "  1.4451376359339526e-05,\n",
              "  1.5086,\n",
              "  18),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1725127590>,\n",
              "  4.985405335357651e-06,\n",
              "  1.1938,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a251a0d0>,\n",
              "  4.0789680016562605e-06,\n",
              "  1.1535,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a26af910>,\n",
              "  3.6892682175581583e-07,\n",
              "  1.2444,\n",
              "  51),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17241b9310>,\n",
              "  5.6605511811488384e-05,\n",
              "  1.2705,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a21f8b50>,\n",
              "  2.1290385571733888e-07,\n",
              "  1.3583,\n",
              "  26),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1724993290>,\n",
              "  4.928015151942285e-06,\n",
              "  1.2076,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a1509d0>,\n",
              "  3.620999712936003e-07,\n",
              "  1.1925,\n",
              "  121),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17243dd850>,\n",
              "  3.592523045765926e-06,\n",
              "  1.2088,\n",
              "  70),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f170a532d10>,\n",
              "  6.953290948085145e-07,\n",
              "  1.7036,\n",
              "  16),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1724993610>,\n",
              "  5.962898333850164e-06,\n",
              "  1.0318,\n",
              "  86),\n",
              " (<tensorflow.python.keras.engine.sequential.Sequential at 0x7f17a220b910>,\n",
              "  0.0009368066730514583,\n",
              "  1.2253,\n",
              "  34)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQAr-G-MXF0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b433d75a-6912-4e62-a900-c29fcd0f4e69"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1962 - accuracy: 0.7624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1961537599563599, 0.7623999714851379]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp-SXeCW6DrV"
      },
      "source": [
        "# Generic FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhCR65NEqD11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ea309e-cd04-46c4-cd80-5556230e8bb2"
      },
      "source": [
        "client_models = [0]*NUM_CLIENTS\n",
        "client_models\n",
        "\n",
        "server_model_norm = create_server_model()\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "serverhist={\n",
        "    \"loss\":[],\n",
        "    \"accuracy\":[]\n",
        "}\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"-----\"+str(i)+\"---------\")\n",
        "  losses = []\n",
        "  lr_init = []\n",
        "  data= []\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    data.append(train_client(j, server_model_norm, 0.0001, 32))\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(NUM_CLIENTS):\n",
        "    sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "  server_model_norm.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "  h=server_model_norm.evaluate(X_test,y_test)\n",
        "  serverhist['loss'].append(h[1])\n",
        "  serverhist['accuracy'].append(h[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----0---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 2.2785 - accuracy: 0.1234 - val_loss: 1.9972 - val_accuracy: 0.2563\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 1.9821 - accuracy: 0.2792 - val_loss: 1.8405 - val_accuracy: 0.3395\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 1.8440 - accuracy: 0.3242 - val_loss: 1.6721 - val_accuracy: 0.3890\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 17ms/step - loss: 1.6805 - accuracy: 0.3885 - val_loss: 1.5928 - val_accuracy: 0.4185\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 1.6164 - accuracy: 0.4022 - val_loss: 1.5433 - val_accuracy: 0.4289\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 1.4705 - accuracy: 0.4601 - val_loss: 1.4272 - val_accuracy: 0.4815\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 1.4907 - accuracy: 0.4680 - val_loss: 1.3883 - val_accuracy: 0.4933\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 1.3495 - accuracy: 0.5226 - val_loss: 1.4229 - val_accuracy: 0.4711\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 1.3891 - accuracy: 0.5017 - val_loss: 1.4660 - val_accuracy: 0.4604\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 1.2351 - accuracy: 0.5595 - val_loss: 1.4434 - val_accuracy: 0.4772\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 1.3454 - accuracy: 0.5088 - val_loss: 1.3043 - val_accuracy: 0.5290\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.2124 - accuracy: 0.5639 - val_loss: 1.4646 - val_accuracy: 0.5043\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 1.2426 - accuracy: 0.5566 - val_loss: 1.3199 - val_accuracy: 0.5265\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 1.0583 - accuracy: 0.6341 - val_loss: 1.1649 - val_accuracy: 0.5859\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 1.1052 - accuracy: 0.6146 - val_loss: 1.2009 - val_accuracy: 0.5744\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.9538 - accuracy: 0.6656 - val_loss: 1.1369 - val_accuracy: 0.5983\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 1.1971 - accuracy: 0.5814 - val_loss: 1.1528 - val_accuracy: 0.5845\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.9264 - accuracy: 0.6767 - val_loss: 1.1236 - val_accuracy: 0.6048\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.9671 - accuracy: 0.6581 - val_loss: 1.1292 - val_accuracy: 0.6058\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.7152 - accuracy: 0.7509 - val_loss: 1.2915 - val_accuracy: 0.5876\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.9931 - accuracy: 0.6498 - val_loss: 1.1507 - val_accuracy: 0.5935\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.7888 - accuracy: 0.7196 - val_loss: 1.1946 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.0612 - accuracy: 0.6250 - val_loss: 1.0651 - val_accuracy: 0.6258\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.8252 - accuracy: 0.7006 - val_loss: 1.1192 - val_accuracy: 0.6163\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 1.0164 - accuracy: 0.6302 - val_loss: 0.9985 - val_accuracy: 0.6553\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.7201 - accuracy: 0.7521 - val_loss: 1.0643 - val_accuracy: 0.6304\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 26ms/step - loss: 0.9308 - accuracy: 0.6732 - val_loss: 1.0236 - val_accuracy: 0.6400\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.6591 - accuracy: 0.7761 - val_loss: 1.1416 - val_accuracy: 0.6275\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 1.0577 - accuracy: 0.6436 - val_loss: 1.0790 - val_accuracy: 0.6226\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.7513 - accuracy: 0.7362 - val_loss: 1.0110 - val_accuracy: 0.6528\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.9916 - accuracy: 0.6557 - val_loss: 0.9754 - val_accuracy: 0.6559\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7414 - accuracy: 0.7440 - val_loss: 0.9706 - val_accuracy: 0.6719\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.8076 - accuracy: 0.7142 - val_loss: 1.0051 - val_accuracy: 0.6597\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 18ms/step - loss: 0.5459 - accuracy: 0.8166 - val_loss: 1.0051 - val_accuracy: 0.6699\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 34ms/step - loss: 0.5708 - accuracy: 0.8003 - val_loss: 1.0392 - val_accuracy: 0.6592\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.2937 - accuracy: 0.9066 - val_loss: 1.2601 - val_accuracy: 0.6451\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.9555 - accuracy: 0.6702 - val_loss: 0.9262 - val_accuracy: 0.6747\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.6470 - accuracy: 0.7784 - val_loss: 0.9151 - val_accuracy: 0.6851\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 0.9311 - accuracy: 0.6783 - val_loss: 0.9960 - val_accuracy: 0.6552\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 36ms/step - loss: 0.6102 - accuracy: 0.7855 - val_loss: 0.9773 - val_accuracy: 0.6660\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.8874 - accuracy: 0.6829 - val_loss: 0.9302 - val_accuracy: 0.6804\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5169 - accuracy: 0.8183 - val_loss: 1.0139 - val_accuracy: 0.6769\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 37ms/step - loss: 0.6746 - accuracy: 0.7687 - val_loss: 0.9914 - val_accuracy: 0.6724\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 0.2894 - accuracy: 0.9153 - val_loss: 1.1004 - val_accuracy: 0.6868\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 1.0573 - accuracy: 0.6426 - val_loss: 0.9651 - val_accuracy: 0.6637\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.7450 - accuracy: 0.7388 - val_loss: 1.0755 - val_accuracy: 0.6537\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.8808 - accuracy: 0.6949 - val_loss: 0.8969 - val_accuracy: 0.6938\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.5911 - accuracy: 0.7994 - val_loss: 0.9519 - val_accuracy: 0.6882\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7348 - accuracy: 0.7438 - val_loss: 0.9126 - val_accuracy: 0.6889\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 0.4404 - accuracy: 0.8457 - val_loss: 0.9756 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5486 - accuracy: 0.8076 - val_loss: 0.9878 - val_accuracy: 0.6915\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.2680 - accuracy: 0.9124 - val_loss: 1.1116 - val_accuracy: 0.6941\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7226 - accuracy: 0.7554 - val_loss: 0.9451 - val_accuracy: 0.6863\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.3654 - accuracy: 0.8812 - val_loss: 0.9893 - val_accuracy: 0.6984\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.8325 - accuracy: 0.7052 - val_loss: 0.8673 - val_accuracy: 0.7035\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.4822 - accuracy: 0.8315 - val_loss: 0.9616 - val_accuracy: 0.6953\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.8903 - accuracy: 0.6923 - val_loss: 0.8726 - val_accuracy: 0.6972\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.5513 - accuracy: 0.8084 - val_loss: 0.8661 - val_accuracy: 0.7077\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 28ms/step - loss: 0.5963 - accuracy: 0.7984 - val_loss: 0.9371 - val_accuracy: 0.6942\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.2345 - accuracy: 0.9258 - val_loss: 1.0319 - val_accuracy: 0.7116\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9584 - accuracy: 0.6709\n",
            "-----1---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.9420 - accuracy: 0.6656 - val_loss: 0.9605 - val_accuracy: 0.6690\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.7191 - accuracy: 0.7438 - val_loss: 1.0156 - val_accuracy: 0.6517\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.8395 - accuracy: 0.7141 - val_loss: 0.9207 - val_accuracy: 0.6800\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.5717 - accuracy: 0.7983 - val_loss: 0.9692 - val_accuracy: 0.6777\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.9327 - accuracy: 0.6761 - val_loss: 0.9459 - val_accuracy: 0.6699\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.6627 - accuracy: 0.7671 - val_loss: 0.8911 - val_accuracy: 0.6898\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.6853 - accuracy: 0.7557 - val_loss: 0.9919 - val_accuracy: 0.6654\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.3775 - accuracy: 0.8696 - val_loss: 1.0535 - val_accuracy: 0.6820\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.8983 - accuracy: 0.6924 - val_loss: 0.9144 - val_accuracy: 0.6817\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5399 - accuracy: 0.8104 - val_loss: 0.8956 - val_accuracy: 0.6938\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.7906 - accuracy: 0.7242 - val_loss: 0.9174 - val_accuracy: 0.6870\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.5427 - accuracy: 0.8084 - val_loss: 0.9172 - val_accuracy: 0.7008\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.7307 - accuracy: 0.7491 - val_loss: 0.8908 - val_accuracy: 0.6940\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.4116 - accuracy: 0.8550 - val_loss: 1.0082 - val_accuracy: 0.6922\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.6185 - accuracy: 0.7853 - val_loss: 0.9502 - val_accuracy: 0.6854\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.3314 - accuracy: 0.8884 - val_loss: 1.0604 - val_accuracy: 0.6952\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.8063 - accuracy: 0.7161 - val_loss: 0.9067 - val_accuracy: 0.6930\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.3825 - accuracy: 0.8678 - val_loss: 1.0031 - val_accuracy: 0.7002\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.3815 - accuracy: 0.8733 - val_loss: 1.0818 - val_accuracy: 0.6858\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.0953 - accuracy: 0.9762 - val_loss: 1.2909 - val_accuracy: 0.6941\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.5947 - accuracy: 0.8078 - val_loss: 0.9366 - val_accuracy: 0.6932\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.2666 - accuracy: 0.9077 - val_loss: 1.2284 - val_accuracy: 0.6805\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8416 - accuracy: 0.7056 - val_loss: 0.8444 - val_accuracy: 0.7131\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.4195 - accuracy: 0.8564 - val_loss: 0.9849 - val_accuracy: 0.6954\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.6954 - accuracy: 0.7734 - val_loss: 0.8798 - val_accuracy: 0.7021\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.3227 - accuracy: 0.8933 - val_loss: 1.0245 - val_accuracy: 0.7019\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.5003 - accuracy: 0.8329 - val_loss: 0.9935 - val_accuracy: 0.6982\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.1293 - accuracy: 0.9607 - val_loss: 1.1967 - val_accuracy: 0.7047\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.8579 - accuracy: 0.7237 - val_loss: 0.8820 - val_accuracy: 0.6953\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.4127 - accuracy: 0.8649 - val_loss: 0.9261 - val_accuracy: 0.7016\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.7507 - accuracy: 0.7472 - val_loss: 0.8476 - val_accuracy: 0.7097\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.4174 - accuracy: 0.8616 - val_loss: 1.0050 - val_accuracy: 0.6825\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.5429 - accuracy: 0.8287 - val_loss: 0.9051 - val_accuracy: 0.7097\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.2235 - accuracy: 0.9326 - val_loss: 1.0445 - val_accuracy: 0.7110\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 34ms/step - loss: 0.2432 - accuracy: 0.9096 - val_loss: 1.0382 - val_accuracy: 0.7134\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.0519 - accuracy: 0.9901 - val_loss: 1.2166 - val_accuracy: 0.7195\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.7613 - accuracy: 0.7391 - val_loss: 0.8110 - val_accuracy: 0.7287\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.3697 - accuracy: 0.8774 - val_loss: 0.9903 - val_accuracy: 0.7062\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 0.8504 - accuracy: 0.7067 - val_loss: 0.8570 - val_accuracy: 0.7081\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 36ms/step - loss: 0.3568 - accuracy: 0.8753 - val_loss: 0.9485 - val_accuracy: 0.7171\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.6043 - accuracy: 0.7900 - val_loss: 0.8364 - val_accuracy: 0.7201\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.1761 - accuracy: 0.9513 - val_loss: 1.0253 - val_accuracy: 0.7256\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.3499 - accuracy: 0.8852 - val_loss: 0.9804 - val_accuracy: 0.7161\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.1013 - accuracy: 0.9756 - val_loss: 1.1582 - val_accuracy: 0.7201\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.7758 - accuracy: 0.7479 - val_loss: 0.8371 - val_accuracy: 0.7150\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.2814 - accuracy: 0.9038 - val_loss: 1.0945 - val_accuracy: 0.7012\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.7301 - accuracy: 0.7522 - val_loss: 0.8622 - val_accuracy: 0.7111\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.3569 - accuracy: 0.8765 - val_loss: 0.9311 - val_accuracy: 0.7187\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.5243 - accuracy: 0.8173 - val_loss: 0.8715 - val_accuracy: 0.7205\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 0.1752 - accuracy: 0.9421 - val_loss: 1.0547 - val_accuracy: 0.7321\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.3128 - accuracy: 0.8916 - val_loss: 1.0484 - val_accuracy: 0.7206\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.1005 - accuracy: 0.9703 - val_loss: 1.2291 - val_accuracy: 0.7257\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.6074 - accuracy: 0.7969 - val_loss: 0.8934 - val_accuracy: 0.7085\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.1886 - accuracy: 0.9401 - val_loss: 1.0155 - val_accuracy: 0.7315\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.6011 - accuracy: 0.7963 - val_loss: 0.8877 - val_accuracy: 0.7197\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2549 - accuracy: 0.9073 - val_loss: 1.1748 - val_accuracy: 0.7030\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.8311 - accuracy: 0.7284 - val_loss: 0.7986 - val_accuracy: 0.7299\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.3796 - accuracy: 0.8684 - val_loss: 0.9388 - val_accuracy: 0.7207\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.4204 - accuracy: 0.8517 - val_loss: 0.9334 - val_accuracy: 0.7197\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.1053 - accuracy: 0.9705 - val_loss: 1.1640 - val_accuracy: 0.7243\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7717 - accuracy: 0.7523\n",
            "-----2---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.6113 - accuracy: 0.7813 - val_loss: 0.8043 - val_accuracy: 0.7280\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.2920 - accuracy: 0.9010 - val_loss: 0.9712 - val_accuracy: 0.7263\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.4837 - accuracy: 0.8294 - val_loss: 0.9158 - val_accuracy: 0.7199\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 17ms/step - loss: 0.1842 - accuracy: 0.9434 - val_loss: 1.1048 - val_accuracy: 0.7144\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.6814 - accuracy: 0.7650 - val_loss: 0.8465 - val_accuracy: 0.7246\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.2983 - accuracy: 0.9040 - val_loss: 0.9974 - val_accuracy: 0.7076\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.2973 - accuracy: 0.8967 - val_loss: 1.1466 - val_accuracy: 0.7026\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 1.2599 - val_accuracy: 0.7219\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.7034 - accuracy: 0.7641 - val_loss: 0.9164 - val_accuracy: 0.7022\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.2640 - accuracy: 0.9184 - val_loss: 1.0391 - val_accuracy: 0.7149\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.5428 - accuracy: 0.8159 - val_loss: 1.0337 - val_accuracy: 0.6811\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2078 - accuracy: 0.9299 - val_loss: 1.1832 - val_accuracy: 0.7048\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.4736 - accuracy: 0.8399 - val_loss: 0.9131 - val_accuracy: 0.7102\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.1380 - accuracy: 0.9552 - val_loss: 1.2238 - val_accuracy: 0.7142\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.4204 - accuracy: 0.8625 - val_loss: 0.9914 - val_accuracy: 0.7082\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.1128 - accuracy: 0.9640 - val_loss: 1.2920 - val_accuracy: 0.7048\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.6133 - accuracy: 0.7963 - val_loss: 0.9646 - val_accuracy: 0.6957\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.1917 - accuracy: 0.9383 - val_loss: 1.1101 - val_accuracy: 0.7198\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.1631 - accuracy: 0.9423 - val_loss: 1.2435 - val_accuracy: 0.7048\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.0274 - accuracy: 0.9950 - val_loss: 1.3568 - val_accuracy: 0.7176\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.3929 - accuracy: 0.8698 - val_loss: 1.0118 - val_accuracy: 0.7036\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.1252 - accuracy: 0.9624 - val_loss: 1.2437 - val_accuracy: 0.7158\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6766 - accuracy: 0.7756 - val_loss: 0.9151 - val_accuracy: 0.6994\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.3033 - accuracy: 0.8957 - val_loss: 1.0115 - val_accuracy: 0.7168\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.5140 - accuracy: 0.8235 - val_loss: 1.0629 - val_accuracy: 0.6872\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.1372 - accuracy: 0.9585 - val_loss: 1.1791 - val_accuracy: 0.7208\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 1s 26ms/step - loss: 0.3255 - accuracy: 0.8881 - val_loss: 1.0490 - val_accuracy: 0.7144\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.0873 - accuracy: 0.9751 - val_loss: 1.3130 - val_accuracy: 0.7152\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.7571 - accuracy: 0.7578 - val_loss: 0.9147 - val_accuracy: 0.6990\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.2399 - accuracy: 0.9229 - val_loss: 1.0745 - val_accuracy: 0.7201\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6418 - accuracy: 0.7855 - val_loss: 0.8858 - val_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2454 - accuracy: 0.9217 - val_loss: 1.1174 - val_accuracy: 0.7127\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.4410 - accuracy: 0.8618 - val_loss: 1.0077 - val_accuracy: 0.7134\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 18ms/step - loss: 0.1180 - accuracy: 0.9631 - val_loss: 1.1825 - val_accuracy: 0.7179\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 34ms/step - loss: 0.1331 - accuracy: 0.9560 - val_loss: 1.3037 - val_accuracy: 0.7153\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 32ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 1.2641 - val_accuracy: 0.7265\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.6637 - accuracy: 0.7778 - val_loss: 0.8814 - val_accuracy: 0.7030\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.2443 - accuracy: 0.9170 - val_loss: 1.0608 - val_accuracy: 0.7223\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 39ms/step - loss: 0.7839 - accuracy: 0.7617 - val_loss: 0.9162 - val_accuracy: 0.6866\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 36ms/step - loss: 0.2991 - accuracy: 0.9129 - val_loss: 0.9551 - val_accuracy: 0.7221\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.4571 - accuracy: 0.8327 - val_loss: 0.9358 - val_accuracy: 0.7168\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.0864 - accuracy: 0.9783 - val_loss: 1.1808 - val_accuracy: 0.7237\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.2190 - accuracy: 0.9292 - val_loss: 1.1368 - val_accuracy: 0.7077\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0576 - accuracy: 0.9837 - val_loss: 1.2005 - val_accuracy: 0.7268\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.6646 - accuracy: 0.7771 - val_loss: 0.9238 - val_accuracy: 0.7102\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.1661 - accuracy: 0.9467 - val_loss: 1.1028 - val_accuracy: 0.7212\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.6188 - accuracy: 0.7959 - val_loss: 0.8699 - val_accuracy: 0.7173\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.2174 - accuracy: 0.9330 - val_loss: 1.0594 - val_accuracy: 0.7192\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4581 - accuracy: 0.8439 - val_loss: 0.9732 - val_accuracy: 0.7018\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 0.1248 - accuracy: 0.9585 - val_loss: 1.1601 - val_accuracy: 0.7173\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.2594 - accuracy: 0.9153 - val_loss: 1.1175 - val_accuracy: 0.7110\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 1.3702 - val_accuracy: 0.7238\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.5146 - accuracy: 0.8331 - val_loss: 0.9272 - val_accuracy: 0.7207\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.1157 - accuracy: 0.9720 - val_loss: 1.1609 - val_accuracy: 0.7307\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.4792 - accuracy: 0.8371 - val_loss: 0.9391 - val_accuracy: 0.7172\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.1554 - accuracy: 0.9486 - val_loss: 1.2049 - val_accuracy: 0.7204\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.7840 - accuracy: 0.7471 - val_loss: 0.8351 - val_accuracy: 0.7268\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.3232 - accuracy: 0.8865 - val_loss: 0.9773 - val_accuracy: 0.7157\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.3228 - accuracy: 0.8893 - val_loss: 0.9778 - val_accuracy: 0.7341\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0542 - accuracy: 0.9884 - val_loss: 1.1394 - val_accuracy: 0.7451\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8709 - accuracy: 0.7579\n",
            "-----3---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.3901 - accuracy: 0.8563 - val_loss: 0.9608 - val_accuracy: 0.7256\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1121 - accuracy: 0.9629 - val_loss: 1.1162 - val_accuracy: 0.7416\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.2782 - accuracy: 0.9075 - val_loss: 1.0582 - val_accuracy: 0.7280\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 17ms/step - loss: 0.0525 - accuracy: 0.9862 - val_loss: 1.2781 - val_accuracy: 0.7393\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.4604 - accuracy: 0.8396 - val_loss: 0.9512 - val_accuracy: 0.7200\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.1302 - accuracy: 0.9583 - val_loss: 1.3469 - val_accuracy: 0.7211\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 28ms/step - loss: 0.1675 - accuracy: 0.9366 - val_loss: 1.4034 - val_accuracy: 0.7014\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 1.3856 - val_accuracy: 0.7176\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.5546 - accuracy: 0.8163 - val_loss: 0.9618 - val_accuracy: 0.7146\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1161 - accuracy: 0.9642 - val_loss: 1.1852 - val_accuracy: 0.7253\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.4018 - accuracy: 0.8572 - val_loss: 1.0376 - val_accuracy: 0.7180\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.0902 - accuracy: 0.9717 - val_loss: 1.3024 - val_accuracy: 0.7172\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.3150 - accuracy: 0.8909 - val_loss: 1.1869 - val_accuracy: 0.6958\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 1.3942 - val_accuracy: 0.7140\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.2801 - accuracy: 0.9059 - val_loss: 1.1714 - val_accuracy: 0.7073\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.0920 - accuracy: 0.9716 - val_loss: 1.3329 - val_accuracy: 0.7164\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.4771 - accuracy: 0.8371 - val_loss: 1.0927 - val_accuracy: 0.6956\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 21ms/step - loss: 0.1226 - accuracy: 0.9592 - val_loss: 1.2371 - val_accuracy: 0.7147\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.1376 - accuracy: 0.9460 - val_loss: 1.3347 - val_accuracy: 0.7093\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 1.3661 - val_accuracy: 0.7223\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.2547 - accuracy: 0.9123 - val_loss: 1.2114 - val_accuracy: 0.7168\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0826 - accuracy: 0.9716 - val_loss: 1.3761 - val_accuracy: 0.7091\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6168 - accuracy: 0.7926 - val_loss: 0.9472 - val_accuracy: 0.7088\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.1979 - accuracy: 0.9317 - val_loss: 1.0306 - val_accuracy: 0.7286\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.3886 - accuracy: 0.8700 - val_loss: 1.1471 - val_accuracy: 0.6997\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.1134 - accuracy: 0.9676 - val_loss: 1.1856 - val_accuracy: 0.7234\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 1s 26ms/step - loss: 0.1800 - accuracy: 0.9385 - val_loss: 1.3729 - val_accuracy: 0.7022\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 1.4382 - val_accuracy: 0.7266\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.6256 - accuracy: 0.7958 - val_loss: 0.9345 - val_accuracy: 0.7088\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1645 - accuracy: 0.9469 - val_loss: 1.0970 - val_accuracy: 0.7181\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.5586 - accuracy: 0.8136 - val_loss: 0.9591 - val_accuracy: 0.7133\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.1759 - accuracy: 0.9459 - val_loss: 1.1512 - val_accuracy: 0.7230\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.3905 - accuracy: 0.8769 - val_loss: 1.0393 - val_accuracy: 0.7101\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 18ms/step - loss: 0.0940 - accuracy: 0.9748 - val_loss: 1.1800 - val_accuracy: 0.7287\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 33ms/step - loss: 0.0943 - accuracy: 0.9719 - val_loss: 1.1883 - val_accuracy: 0.7351\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 1.2692 - val_accuracy: 0.7396\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.5713 - accuracy: 0.8111 - val_loss: 0.9076 - val_accuracy: 0.7169\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1751 - accuracy: 0.9424 - val_loss: 1.1464 - val_accuracy: 0.7255\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 0.7664 - accuracy: 0.7709 - val_loss: 0.9536 - val_accuracy: 0.6854\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 36ms/step - loss: 0.3311 - accuracy: 0.9001 - val_loss: 0.9937 - val_accuracy: 0.7100\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 0.4065 - accuracy: 0.8538 - val_loss: 1.0118 - val_accuracy: 0.7212\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.0656 - accuracy: 0.9832 - val_loss: 1.1793 - val_accuracy: 0.7336\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 37ms/step - loss: 0.2146 - accuracy: 0.9210 - val_loss: 1.1340 - val_accuracy: 0.7240\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0413 - accuracy: 0.9910 - val_loss: 1.2121 - val_accuracy: 0.7303\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.4770 - accuracy: 0.8428 - val_loss: 0.9677 - val_accuracy: 0.7227\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.1512 - accuracy: 0.9519 - val_loss: 1.1516 - val_accuracy: 0.7276\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.5526 - accuracy: 0.8179 - val_loss: 0.9181 - val_accuracy: 0.7224\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.1462 - accuracy: 0.9577 - val_loss: 1.1252 - val_accuracy: 0.7309\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.3770 - accuracy: 0.8770 - val_loss: 0.9883 - val_accuracy: 0.7217\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 0.0641 - accuracy: 0.9851 - val_loss: 1.1984 - val_accuracy: 0.7371\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.1868 - accuracy: 0.9324 - val_loss: 1.1870 - val_accuracy: 0.7323\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 1.3079 - val_accuracy: 0.7357\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.4199 - accuracy: 0.8663 - val_loss: 1.0197 - val_accuracy: 0.7245\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0720 - accuracy: 0.9847 - val_loss: 1.1325 - val_accuracy: 0.7381\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.3742 - accuracy: 0.8753 - val_loss: 1.0864 - val_accuracy: 0.7139\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0919 - accuracy: 0.9717 - val_loss: 1.2478 - val_accuracy: 0.7378\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.7292 - accuracy: 0.7697 - val_loss: 0.8934 - val_accuracy: 0.7187\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.2372 - accuracy: 0.9239 - val_loss: 1.0418 - val_accuracy: 0.7288\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 28ms/step - loss: 0.2401 - accuracy: 0.9171 - val_loss: 1.0801 - val_accuracy: 0.7298\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 1.2911 - val_accuracy: 0.7307\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9525 - accuracy: 0.7648\n",
            "-----4---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2145 - accuracy: 0.9226 - val_loss: 1.2096 - val_accuracy: 0.7215\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.0847 - accuracy: 0.9733 - val_loss: 1.3096 - val_accuracy: 0.7418\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.1825 - accuracy: 0.9351 - val_loss: 1.2806 - val_accuracy: 0.7242\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 17ms/step - loss: 0.0526 - accuracy: 0.9838 - val_loss: 1.3615 - val_accuracy: 0.7412\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.3059 - accuracy: 0.8951 - val_loss: 1.1421 - val_accuracy: 0.7214\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.0826 - accuracy: 0.9720 - val_loss: 1.3640 - val_accuracy: 0.7276\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 28ms/step - loss: 0.1216 - accuracy: 0.9571 - val_loss: 1.4444 - val_accuracy: 0.7231\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 1.5549 - val_accuracy: 0.7320\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3640 - accuracy: 0.8785 - val_loss: 1.2601 - val_accuracy: 0.6947\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.1066 - accuracy: 0.9671 - val_loss: 1.3545 - val_accuracy: 0.7146\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.2814 - accuracy: 0.8993 - val_loss: 1.1761 - val_accuracy: 0.7315\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 1.4052 - val_accuracy: 0.7186\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2470 - accuracy: 0.9130 - val_loss: 1.2209 - val_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0428 - accuracy: 0.9850 - val_loss: 1.4210 - val_accuracy: 0.7287\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.2366 - accuracy: 0.9209 - val_loss: 1.1713 - val_accuracy: 0.7135\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.0646 - accuracy: 0.9774 - val_loss: 1.4416 - val_accuracy: 0.7280\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.3647 - accuracy: 0.8877 - val_loss: 1.1909 - val_accuracy: 0.6968\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.1107 - accuracy: 0.9650 - val_loss: 1.3099 - val_accuracy: 0.7129\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 29ms/step - loss: 0.1177 - accuracy: 0.9598 - val_loss: 1.4811 - val_accuracy: 0.7102\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 1.5271 - val_accuracy: 0.7162\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.2402 - accuracy: 0.9240 - val_loss: 1.3485 - val_accuracy: 0.6969\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0736 - accuracy: 0.9735 - val_loss: 1.7766 - val_accuracy: 0.6820\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5471 - accuracy: 0.8127 - val_loss: 0.9716 - val_accuracy: 0.7177\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.1536 - accuracy: 0.9481 - val_loss: 1.2415 - val_accuracy: 0.7250\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.3038 - accuracy: 0.8973 - val_loss: 1.1152 - val_accuracy: 0.7129\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0484 - accuracy: 0.9889 - val_loss: 1.3177 - val_accuracy: 0.7197\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 26ms/step - loss: 0.1649 - accuracy: 0.9464 - val_loss: 1.3565 - val_accuracy: 0.7154\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.0444 - accuracy: 0.9883 - val_loss: 1.4719 - val_accuracy: 0.7250\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.5654 - accuracy: 0.8158 - val_loss: 1.0208 - val_accuracy: 0.7069\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 1.2191 - val_accuracy: 0.7241\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.4916 - accuracy: 0.8343 - val_loss: 0.9930 - val_accuracy: 0.7168\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.1387 - accuracy: 0.9535 - val_loss: 1.2211 - val_accuracy: 0.7217\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.3039 - accuracy: 0.8976 - val_loss: 1.0724 - val_accuracy: 0.7224\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.0592 - accuracy: 0.9842 - val_loss: 1.2638 - val_accuracy: 0.7350\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 34ms/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 1.4695 - val_accuracy: 0.7209\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 1.4715 - val_accuracy: 0.7255\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.5755 - accuracy: 0.8174 - val_loss: 0.9666 - val_accuracy: 0.7084\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1526 - accuracy: 0.9489 - val_loss: 1.2083 - val_accuracy: 0.7210\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 0.7534 - accuracy: 0.7745 - val_loss: 0.9616 - val_accuracy: 0.6903\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 0.2456 - accuracy: 0.9239 - val_loss: 1.0321 - val_accuracy: 0.7140\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 0.3420 - accuracy: 0.8797 - val_loss: 1.1156 - val_accuracy: 0.7068\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.0660 - accuracy: 0.9795 - val_loss: 1.2216 - val_accuracy: 0.7280\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.1211 - accuracy: 0.9593 - val_loss: 1.2515 - val_accuracy: 0.7291\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 1.2732 - val_accuracy: 0.7320\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 2s 36ms/step - loss: 0.4329 - accuracy: 0.8609 - val_loss: 1.0780 - val_accuracy: 0.7131\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 1.2489 - val_accuracy: 0.7296\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.5301 - accuracy: 0.8352 - val_loss: 0.9433 - val_accuracy: 0.7256\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.1227 - accuracy: 0.9625 - val_loss: 1.1609 - val_accuracy: 0.7256\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.2863 - accuracy: 0.8992 - val_loss: 1.0396 - val_accuracy: 0.7261\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 1.2196 - val_accuracy: 0.7367\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.1785 - accuracy: 0.9410 - val_loss: 1.3735 - val_accuracy: 0.7161\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 1.3084 - val_accuracy: 0.7330\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.3551 - accuracy: 0.8838 - val_loss: 1.0600 - val_accuracy: 0.7189\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0937 - accuracy: 0.9729 - val_loss: 1.1157 - val_accuracy: 0.7364\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.3356 - accuracy: 0.8862 - val_loss: 1.1205 - val_accuracy: 0.7263\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0934 - accuracy: 0.9689 - val_loss: 1.2887 - val_accuracy: 0.7352\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.6851 - accuracy: 0.7848 - val_loss: 0.8908 - val_accuracy: 0.7226\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.1975 - accuracy: 0.9365 - val_loss: 1.0351 - val_accuracy: 0.7330\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.1809 - accuracy: 0.9380 - val_loss: 1.1322 - val_accuracy: 0.7357\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 1.2628 - val_accuracy: 0.7405\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0224 - accuracy: 0.7654\n",
            "-----5---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1150 - accuracy: 0.9593 - val_loss: 1.1922 - val_accuracy: 0.7440\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 1.3203 - val_accuracy: 0.7451\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.0677 - accuracy: 0.9734 - val_loss: 1.4214 - val_accuracy: 0.7472\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 1.5435 - val_accuracy: 0.7390\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.2108 - accuracy: 0.9275 - val_loss: 1.4301 - val_accuracy: 0.7097\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.1085 - accuracy: 0.9664 - val_loss: 1.4360 - val_accuracy: 0.7207\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 1s 28ms/step - loss: 0.0818 - accuracy: 0.9718 - val_loss: 1.5680 - val_accuracy: 0.7181\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 1.5248 - val_accuracy: 0.7320\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.3321 - accuracy: 0.8955 - val_loss: 1.3779 - val_accuracy: 0.7027\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0841 - accuracy: 0.9731 - val_loss: 1.3997 - val_accuracy: 0.7248\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.2199 - accuracy: 0.9254 - val_loss: 1.3916 - val_accuracy: 0.7057\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.1050 - accuracy: 0.9627 - val_loss: 1.4904 - val_accuracy: 0.7208\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.1896 - accuracy: 0.9378 - val_loss: 1.3468 - val_accuracy: 0.7168\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 1.4620 - val_accuracy: 0.7297\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.2012 - accuracy: 0.9343 - val_loss: 1.4195 - val_accuracy: 0.7018\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 1.5666 - val_accuracy: 0.7222\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.2783 - accuracy: 0.9062 - val_loss: 1.3306 - val_accuracy: 0.7142\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 1.5175 - val_accuracy: 0.7242\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.0867 - accuracy: 0.9705 - val_loss: 1.4895 - val_accuracy: 0.7234\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 27ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 1.5572 - val_accuracy: 0.7241\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1727 - accuracy: 0.9442 - val_loss: 1.3718 - val_accuracy: 0.7111\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0611 - accuracy: 0.9808 - val_loss: 1.5466 - val_accuracy: 0.7231\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4611 - accuracy: 0.8444 - val_loss: 1.0339 - val_accuracy: 0.7247\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.1450 - accuracy: 0.9487 - val_loss: 1.2940 - val_accuracy: 0.7210\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.2937 - accuracy: 0.9079 - val_loss: 1.1466 - val_accuracy: 0.7197\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0482 - accuracy: 0.9879 - val_loss: 1.3053 - val_accuracy: 0.7281\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 26ms/step - loss: 0.1850 - accuracy: 0.9432 - val_loss: 1.4054 - val_accuracy: 0.7110\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 1.5093 - val_accuracy: 0.7287\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.4694 - accuracy: 0.8483 - val_loss: 1.0677 - val_accuracy: 0.7075\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0948 - accuracy: 0.9705 - val_loss: 1.2268 - val_accuracy: 0.7248\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.4424 - accuracy: 0.8534 - val_loss: 1.0889 - val_accuracy: 0.7077\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.1198 - accuracy: 0.9627 - val_loss: 1.2314 - val_accuracy: 0.7287\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.2807 - accuracy: 0.9021 - val_loss: 1.1824 - val_accuracy: 0.7177\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.0741 - accuracy: 0.9770 - val_loss: 1.3319 - val_accuracy: 0.7269\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0731 - accuracy: 0.9757 - val_loss: 1.4766 - val_accuracy: 0.7214\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 32ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 1.4446 - val_accuracy: 0.7270\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.5203 - accuracy: 0.8376 - val_loss: 1.0167 - val_accuracy: 0.7126\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1325 - accuracy: 0.9568 - val_loss: 1.1991 - val_accuracy: 0.7295\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 0.6127 - accuracy: 0.7993 - val_loss: 1.0343 - val_accuracy: 0.6894\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 0.1644 - accuracy: 0.9523 - val_loss: 1.0829 - val_accuracy: 0.7238\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.2505 - accuracy: 0.9110 - val_loss: 1.1338 - val_accuracy: 0.7239\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.0383 - accuracy: 0.9886 - val_loss: 1.2443 - val_accuracy: 0.7321\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 37ms/step - loss: 0.1126 - accuracy: 0.9601 - val_loss: 1.2541 - val_accuracy: 0.7308\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 1.3271 - val_accuracy: 0.7373\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 31ms/step - loss: 0.3206 - accuracy: 0.8928 - val_loss: 1.1831 - val_accuracy: 0.7227\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.0500 - accuracy: 0.9857 - val_loss: 1.2860 - val_accuracy: 0.7349\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.4887 - accuracy: 0.8507 - val_loss: 0.9796 - val_accuracy: 0.7235\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.1391 - accuracy: 0.9539 - val_loss: 1.1945 - val_accuracy: 0.7335\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.2347 - accuracy: 0.9192 - val_loss: 1.1679 - val_accuracy: 0.7251\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 0.0458 - accuracy: 0.9876 - val_loss: 1.2531 - val_accuracy: 0.7396\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.1514 - accuracy: 0.9458 - val_loss: 1.4750 - val_accuracy: 0.7121\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 1.5508 - val_accuracy: 0.7334\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.3592 - accuracy: 0.8869 - val_loss: 1.0023 - val_accuracy: 0.7279\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0697 - accuracy: 0.9834 - val_loss: 1.2013 - val_accuracy: 0.7376\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2648 - accuracy: 0.9061 - val_loss: 1.1923 - val_accuracy: 0.7286\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 1.3710 - val_accuracy: 0.7339\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.6784 - accuracy: 0.7845 - val_loss: 0.8789 - val_accuracy: 0.7256\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.1986 - accuracy: 0.9355 - val_loss: 0.9947 - val_accuracy: 0.7386\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.1280 - accuracy: 0.9594 - val_loss: 1.1814 - val_accuracy: 0.7362\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 1.2478 - val_accuracy: 0.7421\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0892 - accuracy: 0.7634\n",
            "-----6---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.0806 - accuracy: 0.9725 - val_loss: 1.3587 - val_accuracy: 0.7450\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 1.4822 - val_accuracy: 0.7447\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0921 - accuracy: 0.9631 - val_loss: 1.4076 - val_accuracy: 0.7343\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.0478 - accuracy: 0.9810 - val_loss: 1.4796 - val_accuracy: 0.7394\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1482 - accuracy: 0.9490 - val_loss: 1.3848 - val_accuracy: 0.7234\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 1.4874 - val_accuracy: 0.7402\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 1.5123 - val_accuracy: 0.7389\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.5642 - val_accuracy: 0.7448\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.2739 - accuracy: 0.9084 - val_loss: 1.5499 - val_accuracy: 0.6954\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0736 - accuracy: 0.9751 - val_loss: 1.6390 - val_accuracy: 0.7261\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.2078 - accuracy: 0.9316 - val_loss: 1.3645 - val_accuracy: 0.7149\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0694 - accuracy: 0.9742 - val_loss: 1.5486 - val_accuracy: 0.7298\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.1629 - accuracy: 0.9475 - val_loss: 1.5731 - val_accuracy: 0.7215\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0570 - accuracy: 0.9800 - val_loss: 1.7541 - val_accuracy: 0.7125\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.1477 - accuracy: 0.9550 - val_loss: 1.5884 - val_accuracy: 0.7111\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 1.7529 - val_accuracy: 0.7135\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.2713 - accuracy: 0.9144 - val_loss: 1.3976 - val_accuracy: 0.7091\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.0669 - accuracy: 0.9781 - val_loss: 1.4973 - val_accuracy: 0.7236\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 0.0622 - accuracy: 0.9818 - val_loss: 1.6008 - val_accuracy: 0.7119\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 28ms/step - loss: 0.0217 - accuracy: 0.9912 - val_loss: 1.6426 - val_accuracy: 0.7189\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1752 - accuracy: 0.9388 - val_loss: 1.4180 - val_accuracy: 0.7164\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 1.7212 - val_accuracy: 0.7136\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4274 - accuracy: 0.8542 - val_loss: 1.0585 - val_accuracy: 0.7193\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.0676 - accuracy: 0.9802 - val_loss: 1.3671 - val_accuracy: 0.7299\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.2469 - accuracy: 0.9206 - val_loss: 1.3243 - val_accuracy: 0.7165\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.0597 - accuracy: 0.9848 - val_loss: 1.4167 - val_accuracy: 0.7284\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.1243 - accuracy: 0.9507 - val_loss: 1.6462 - val_accuracy: 0.7135\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.0395 - accuracy: 0.9857 - val_loss: 1.7351 - val_accuracy: 0.7191\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.4366 - accuracy: 0.8679 - val_loss: 1.2242 - val_accuracy: 0.7099\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0834 - accuracy: 0.9705 - val_loss: 1.3073 - val_accuracy: 0.7280\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3983 - accuracy: 0.8664 - val_loss: 1.0111 - val_accuracy: 0.7226\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0877 - accuracy: 0.9747 - val_loss: 1.2979 - val_accuracy: 0.7288\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 21ms/step - loss: 0.2638 - accuracy: 0.9179 - val_loss: 1.2284 - val_accuracy: 0.7183\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 1.3750 - val_accuracy: 0.7363\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 1.4666 - val_accuracy: 0.7348\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5635 - val_accuracy: 0.7335\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.4902 - accuracy: 0.8465 - val_loss: 1.0385 - val_accuracy: 0.7118\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1098 - accuracy: 0.9612 - val_loss: 1.2951 - val_accuracy: 0.7324\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 0.6367 - accuracy: 0.8112 - val_loss: 1.0134 - val_accuracy: 0.7004\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 38ms/step - loss: 0.1213 - accuracy: 0.9661 - val_loss: 1.1457 - val_accuracy: 0.7220\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.2528 - accuracy: 0.9146 - val_loss: 1.2237 - val_accuracy: 0.7191\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.0495 - accuracy: 0.9868 - val_loss: 1.2746 - val_accuracy: 0.7351\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 38ms/step - loss: 0.1115 - accuracy: 0.9601 - val_loss: 1.3359 - val_accuracy: 0.7287\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 1.3370 - val_accuracy: 0.7379\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 31ms/step - loss: 0.2709 - accuracy: 0.9077 - val_loss: 1.3469 - val_accuracy: 0.6991\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1124 - accuracy: 0.9630 - val_loss: 1.4046 - val_accuracy: 0.7294\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.4591 - accuracy: 0.8594 - val_loss: 1.0787 - val_accuracy: 0.7108\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1128 - accuracy: 0.9631 - val_loss: 1.2298 - val_accuracy: 0.7332\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.2301 - accuracy: 0.9236 - val_loss: 1.1866 - val_accuracy: 0.7226\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0350 - accuracy: 0.9927 - val_loss: 1.3677 - val_accuracy: 0.7358\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.1245 - accuracy: 0.9569 - val_loss: 1.3321 - val_accuracy: 0.7280\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 1.4091 - val_accuracy: 0.7370\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.2983 - accuracy: 0.9030 - val_loss: 1.1760 - val_accuracy: 0.7184\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0579 - accuracy: 0.9790 - val_loss: 1.3021 - val_accuracy: 0.7364\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2513 - accuracy: 0.9155 - val_loss: 1.3271 - val_accuracy: 0.7170\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0701 - accuracy: 0.9776 - val_loss: 1.4344 - val_accuracy: 0.7217\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 19ms/step - loss: 0.6731 - accuracy: 0.7900 - val_loss: 0.9282 - val_accuracy: 0.7142\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 17ms/step - loss: 0.1690 - accuracy: 0.9461 - val_loss: 1.1748 - val_accuracy: 0.7241\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.1586 - accuracy: 0.9432 - val_loss: 1.2494 - val_accuracy: 0.7252\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0236 - accuracy: 0.9971 - val_loss: 1.3396 - val_accuracy: 0.7361\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1617 - accuracy: 0.7647\n",
            "-----7---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0785 - accuracy: 0.9749 - val_loss: 1.4315 - val_accuracy: 0.7425\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.0335 - accuracy: 0.9924 - val_loss: 1.5909 - val_accuracy: 0.7483\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0621 - accuracy: 0.9803 - val_loss: 1.4678 - val_accuracy: 0.7442\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 1.5610 - val_accuracy: 0.7455\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1404 - accuracy: 0.9502 - val_loss: 1.7408 - val_accuracy: 0.7108\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.0827 - accuracy: 0.9720 - val_loss: 1.5825 - val_accuracy: 0.7315\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.0433 - accuracy: 0.9818 - val_loss: 1.6452 - val_accuracy: 0.7390\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 1.7735 - val_accuracy: 0.7435\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1871 - accuracy: 0.9423 - val_loss: 1.5904 - val_accuracy: 0.7124\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0606 - accuracy: 0.9781 - val_loss: 1.7871 - val_accuracy: 0.7150\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.2044 - accuracy: 0.9336 - val_loss: 1.4667 - val_accuracy: 0.7162\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0408 - accuracy: 0.9877 - val_loss: 1.7757 - val_accuracy: 0.7239\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1384 - accuracy: 0.9555 - val_loss: 1.6709 - val_accuracy: 0.7172\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 1.7401 - val_accuracy: 0.7269\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.1386 - accuracy: 0.9528 - val_loss: 1.7281 - val_accuracy: 0.7205\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.0731 - accuracy: 0.9785 - val_loss: 1.7636 - val_accuracy: 0.7246\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.2548 - accuracy: 0.9208 - val_loss: 1.4190 - val_accuracy: 0.7049\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.0531 - accuracy: 0.9791 - val_loss: 1.5401 - val_accuracy: 0.7254\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 2s 31ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 1.6868 - val_accuracy: 0.7230\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 29ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 1.7754 - val_accuracy: 0.7239\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1229 - accuracy: 0.9572 - val_loss: 1.5779 - val_accuracy: 0.7097\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 1.7664 - val_accuracy: 0.7239\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3656 - accuracy: 0.8835 - val_loss: 1.2438 - val_accuracy: 0.7182\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.0789 - accuracy: 0.9730 - val_loss: 1.4948 - val_accuracy: 0.7227\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.2075 - accuracy: 0.9292 - val_loss: 1.4449 - val_accuracy: 0.7179\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 1.5028 - val_accuracy: 0.7249\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.1431 - accuracy: 0.9501 - val_loss: 1.8110 - val_accuracy: 0.6958\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.0539 - accuracy: 0.9889 - val_loss: 1.7001 - val_accuracy: 0.7188\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.3520 - accuracy: 0.8854 - val_loss: 1.2478 - val_accuracy: 0.7088\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1042 - accuracy: 0.9720 - val_loss: 1.4272 - val_accuracy: 0.7186\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3761 - accuracy: 0.8749 - val_loss: 1.1642 - val_accuracy: 0.7278\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 1.3625 - val_accuracy: 0.7241\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.2479 - accuracy: 0.9172 - val_loss: 1.2635 - val_accuracy: 0.7204\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 1.3807 - val_accuracy: 0.7350\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 1.4607 - val_accuracy: 0.7375\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 33ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 1.4943 - val_accuracy: 0.7391\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.4580 - accuracy: 0.8528 - val_loss: 1.0280 - val_accuracy: 0.7211\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.1041 - accuracy: 0.9683 - val_loss: 1.3020 - val_accuracy: 0.7279\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 0.5590 - accuracy: 0.8396 - val_loss: 1.0066 - val_accuracy: 0.7174\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 38ms/step - loss: 0.1054 - accuracy: 0.9688 - val_loss: 1.1104 - val_accuracy: 0.7247\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.2213 - accuracy: 0.9254 - val_loss: 1.3046 - val_accuracy: 0.7167\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 1.3538 - val_accuracy: 0.7302\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 38ms/step - loss: 0.0898 - accuracy: 0.9634 - val_loss: 1.3720 - val_accuracy: 0.7283\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4065 - val_accuracy: 0.7355\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.2249 - accuracy: 0.9259 - val_loss: 1.3625 - val_accuracy: 0.7208\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 1.4793 - val_accuracy: 0.7300\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.4744 - accuracy: 0.8616 - val_loss: 1.0481 - val_accuracy: 0.7157\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1316 - accuracy: 0.9522 - val_loss: 1.2397 - val_accuracy: 0.7285\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.1784 - accuracy: 0.9338 - val_loss: 1.3520 - val_accuracy: 0.7240\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 1.4052 - val_accuracy: 0.7329\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.1367 - accuracy: 0.9536 - val_loss: 1.5188 - val_accuracy: 0.7238\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 1.4972 - val_accuracy: 0.7306\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.3422 - accuracy: 0.8877 - val_loss: 1.1882 - val_accuracy: 0.7128\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0715 - accuracy: 0.9742 - val_loss: 1.3059 - val_accuracy: 0.7341\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2286 - accuracy: 0.9188 - val_loss: 1.2582 - val_accuracy: 0.7342\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0482 - accuracy: 0.9865 - val_loss: 1.4282 - val_accuracy: 0.7395\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 19ms/step - loss: 0.6181 - accuracy: 0.8116 - val_loss: 0.9655 - val_accuracy: 0.7132\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.1440 - accuracy: 0.9548 - val_loss: 1.1499 - val_accuracy: 0.7396\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.1454 - accuracy: 0.9548 - val_loss: 1.2023 - val_accuracy: 0.7331\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0172 - accuracy: 0.9977 - val_loss: 1.3040 - val_accuracy: 0.7405\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2195 - accuracy: 0.7612\n",
            "-----8---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 1.4890 - val_accuracy: 0.7464\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.0116 - accuracy: 0.9984 - val_loss: 1.6024 - val_accuracy: 0.7513\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 1.6906 - val_accuracy: 0.7461\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.6626 - val_accuracy: 0.7547\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.0923 - accuracy: 0.9692 - val_loss: 1.8020 - val_accuracy: 0.7268\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 1.6317 - val_accuracy: 0.7223\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 1.7024 - val_accuracy: 0.7328\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.7150 - val_accuracy: 0.7411\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1411 - accuracy: 0.9552 - val_loss: 1.6698 - val_accuracy: 0.7209\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0663 - accuracy: 0.9771 - val_loss: 1.8033 - val_accuracy: 0.7235\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.1546 - accuracy: 0.9474 - val_loss: 1.6877 - val_accuracy: 0.7136\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.9862 - val_loss: 1.6894 - val_accuracy: 0.7277\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1438 - accuracy: 0.9558 - val_loss: 1.6654 - val_accuracy: 0.7110\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 1.6423 - val_accuracy: 0.7246\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.1085 - accuracy: 0.9637 - val_loss: 1.6308 - val_accuracy: 0.7210\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.0644 - accuracy: 0.9795 - val_loss: 1.8843 - val_accuracy: 0.7218\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.2188 - accuracy: 0.9300 - val_loss: 1.6644 - val_accuracy: 0.7022\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.0780 - accuracy: 0.9708 - val_loss: 1.7039 - val_accuracy: 0.7087\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 2s 31ms/step - loss: 0.1024 - accuracy: 0.9649 - val_loss: 1.6776 - val_accuracy: 0.7180\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 1.7412 - val_accuracy: 0.7133\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1373 - accuracy: 0.9562 - val_loss: 1.6413 - val_accuracy: 0.7061\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0639 - accuracy: 0.9775 - val_loss: 1.6827 - val_accuracy: 0.7238\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3274 - accuracy: 0.8955 - val_loss: 1.3063 - val_accuracy: 0.7176\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.1575 - accuracy: 0.9498 - val_loss: 1.4711 - val_accuracy: 0.7085\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.1986 - accuracy: 0.9312 - val_loss: 1.4641 - val_accuracy: 0.7169\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0322 - accuracy: 0.9904 - val_loss: 1.5182 - val_accuracy: 0.7257\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.1079 - accuracy: 0.9645 - val_loss: 1.7115 - val_accuracy: 0.7219\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 1.6752 - val_accuracy: 0.7244\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.3024 - accuracy: 0.8979 - val_loss: 1.3996 - val_accuracy: 0.7100\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1017 - accuracy: 0.9640 - val_loss: 1.5541 - val_accuracy: 0.7266\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3764 - accuracy: 0.8769 - val_loss: 1.1250 - val_accuracy: 0.7223\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 1.3975 - val_accuracy: 0.7393\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 21ms/step - loss: 0.1944 - accuracy: 0.9394 - val_loss: 1.4479 - val_accuracy: 0.7144\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 20ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 1.4660 - val_accuracy: 0.7339\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 1.5924 - val_accuracy: 0.7272\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.6120 - val_accuracy: 0.7303\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.4468 - accuracy: 0.8556 - val_loss: 1.1114 - val_accuracy: 0.7017\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 16ms/step - loss: 0.1135 - accuracy: 0.9631 - val_loss: 1.3194 - val_accuracy: 0.7341\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 0.5505 - accuracy: 0.8323 - val_loss: 1.1354 - val_accuracy: 0.7086\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 0.1857 - accuracy: 0.9322 - val_loss: 1.1806 - val_accuracy: 0.7175\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.1886 - accuracy: 0.9302 - val_loss: 1.2996 - val_accuracy: 0.7195\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.0291 - accuracy: 0.9922 - val_loss: 1.4307 - val_accuracy: 0.7255\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 38ms/step - loss: 0.1123 - accuracy: 0.9585 - val_loss: 1.4251 - val_accuracy: 0.7234\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.0182 - accuracy: 0.9967 - val_loss: 1.4352 - val_accuracy: 0.7274\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 1s 31ms/step - loss: 0.2381 - accuracy: 0.9129 - val_loss: 1.4679 - val_accuracy: 0.7124\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1572 - accuracy: 0.9480 - val_loss: 1.4935 - val_accuracy: 0.7239\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.4465 - accuracy: 0.8670 - val_loss: 1.1234 - val_accuracy: 0.7121\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1181 - accuracy: 0.9628 - val_loss: 1.2219 - val_accuracy: 0.7313\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.1576 - accuracy: 0.9483 - val_loss: 1.3601 - val_accuracy: 0.7296\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 1.4172 - val_accuracy: 0.7394\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.0872 - accuracy: 0.9692 - val_loss: 1.5002 - val_accuracy: 0.7458\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 1.6611 - val_accuracy: 0.7370\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.2556 - accuracy: 0.9227 - val_loss: 1.2826 - val_accuracy: 0.7237\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0467 - accuracy: 0.9856 - val_loss: 1.4463 - val_accuracy: 0.7237\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2011 - accuracy: 0.9371 - val_loss: 1.5089 - val_accuracy: 0.7052\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.0720 - accuracy: 0.9751 - val_loss: 1.5750 - val_accuracy: 0.7276\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 19ms/step - loss: 0.6760 - accuracy: 0.7961 - val_loss: 0.9745 - val_accuracy: 0.7094\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.1699 - accuracy: 0.9474 - val_loss: 1.1598 - val_accuracy: 0.7337\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.1173 - accuracy: 0.9554 - val_loss: 1.2664 - val_accuracy: 0.7387\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 1.3428 - val_accuracy: 0.7421\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2566 - accuracy: 0.7600\n",
            "-----9---------\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.0745 - accuracy: 0.9749 - val_loss: 1.5196 - val_accuracy: 0.7516\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 1.5757 - val_accuracy: 0.7478\n",
            "Epoch 1/2\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 1.7389 - val_accuracy: 0.7424\n",
            "Epoch 2/2\n",
            "91/91 [==============================] - 2s 18ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 1.7911 - val_accuracy: 0.7430\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.0806 - accuracy: 0.9735 - val_loss: 1.7503 - val_accuracy: 0.7349\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.0523 - accuracy: 0.9818 - val_loss: 1.9138 - val_accuracy: 0.7300\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.0779 - accuracy: 0.9742 - val_loss: 1.9345 - val_accuracy: 0.7312\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 1.9999 - val_accuracy: 0.7304\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1478 - accuracy: 0.9537 - val_loss: 1.7527 - val_accuracy: 0.7162\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0864 - accuracy: 0.9731 - val_loss: 1.7907 - val_accuracy: 0.7198\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.1626 - accuracy: 0.9502 - val_loss: 1.7052 - val_accuracy: 0.7072\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9820 - val_loss: 1.7311 - val_accuracy: 0.7263\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1029 - accuracy: 0.9690 - val_loss: 1.8605 - val_accuracy: 0.7183\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 1.7846 - val_accuracy: 0.7254\n",
            "Epoch 1/2\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.0846 - accuracy: 0.9716 - val_loss: 1.8060 - val_accuracy: 0.7137\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 1.8444 - val_accuracy: 0.7249\n",
            "Epoch 1/2\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1859 - accuracy: 0.9456 - val_loss: 1.9486 - val_accuracy: 0.6871\n",
            "Epoch 2/2\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.1099 - accuracy: 0.9606 - val_loss: 1.9599 - val_accuracy: 0.7036\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 2s 31ms/step - loss: 0.1035 - accuracy: 0.9624 - val_loss: 1.8679 - val_accuracy: 0.7107\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 1s 28ms/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 1.9662 - val_accuracy: 0.7084\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1308 - accuracy: 0.9589 - val_loss: 1.7161 - val_accuracy: 0.7119\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0413 - accuracy: 0.9857 - val_loss: 1.8635 - val_accuracy: 0.7198\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3019 - accuracy: 0.9100 - val_loss: 1.2258 - val_accuracy: 0.7176\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.0659 - accuracy: 0.9769 - val_loss: 1.5142 - val_accuracy: 0.7236\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.1977 - accuracy: 0.9413 - val_loss: 1.5515 - val_accuracy: 0.7141\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.0486 - accuracy: 0.9813 - val_loss: 1.6896 - val_accuracy: 0.7233\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.1108 - accuracy: 0.9660 - val_loss: 1.9134 - val_accuracy: 0.7094\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 1.8212 - val_accuracy: 0.7275\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.2985 - accuracy: 0.8994 - val_loss: 1.4623 - val_accuracy: 0.7129\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0815 - accuracy: 0.9745 - val_loss: 1.5005 - val_accuracy: 0.7203\n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.3163 - accuracy: 0.8931 - val_loss: 1.3376 - val_accuracy: 0.7094\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0671 - accuracy: 0.9770 - val_loss: 1.5088 - val_accuracy: 0.7254\n",
            "Epoch 1/2\n",
            "83/83 [==============================] - 2s 21ms/step - loss: 0.1877 - accuracy: 0.9371 - val_loss: 1.4738 - val_accuracy: 0.7165\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 2s 19ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 1.4841 - val_accuracy: 0.7229\n",
            "Epoch 1/2\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0256 - accuracy: 0.9901 - val_loss: 1.5393 - val_accuracy: 0.7368\n",
            "Epoch 2/2\n",
            "42/42 [==============================] - 1s 33ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5757 - val_accuracy: 0.7393\n",
            "Epoch 1/2\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.3946 - accuracy: 0.8724 - val_loss: 1.1272 - val_accuracy: 0.7158\n",
            "Epoch 2/2\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1005 - accuracy: 0.9680 - val_loss: 1.3424 - val_accuracy: 0.7350\n",
            "Epoch 1/2\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 0.4977 - accuracy: 0.8405 - val_loss: 1.2699 - val_accuracy: 0.7028\n",
            "Epoch 2/2\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 0.1376 - accuracy: 0.9569 - val_loss: 1.2402 - val_accuracy: 0.7186\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.1871 - accuracy: 0.9326 - val_loss: 1.4338 - val_accuracy: 0.7179\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.0335 - accuracy: 0.9886 - val_loss: 1.3976 - val_accuracy: 0.7275\n",
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 39ms/step - loss: 0.0732 - accuracy: 0.9821 - val_loss: 1.4731 - val_accuracy: 0.7254\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 1.4899 - val_accuracy: 0.7322\n",
            "Epoch 1/2\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.1949 - accuracy: 0.9396 - val_loss: 1.5658 - val_accuracy: 0.7141\n",
            "Epoch 2/2\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.0787 - accuracy: 0.9747 - val_loss: 1.5278 - val_accuracy: 0.7294\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.4529 - accuracy: 0.8702 - val_loss: 1.0894 - val_accuracy: 0.7126\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1164 - accuracy: 0.9623 - val_loss: 1.2734 - val_accuracy: 0.7324\n",
            "Epoch 1/2\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.1581 - accuracy: 0.9447 - val_loss: 1.3888 - val_accuracy: 0.7207\n",
            "Epoch 2/2\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0309 - accuracy: 0.9931 - val_loss: 1.4551 - val_accuracy: 0.7403\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.0857 - accuracy: 0.9699 - val_loss: 1.6012 - val_accuracy: 0.7308\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 1.6644 - val_accuracy: 0.7362\n",
            "Epoch 1/2\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.2681 - accuracy: 0.9139 - val_loss: 1.2946 - val_accuracy: 0.7204\n",
            "Epoch 2/2\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0475 - accuracy: 0.9882 - val_loss: 1.3642 - val_accuracy: 0.7375\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 17ms/step - loss: 0.1859 - accuracy: 0.9336 - val_loss: 1.4610 - val_accuracy: 0.7201\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.0621 - accuracy: 0.9773 - val_loss: 1.5632 - val_accuracy: 0.7326\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 2s 19ms/step - loss: 0.6988 - accuracy: 0.7994 - val_loss: 0.9400 - val_accuracy: 0.7177\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 2s 18ms/step - loss: 0.1754 - accuracy: 0.9445 - val_loss: 1.1255 - val_accuracy: 0.7341\n",
            "Epoch 1/2\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.1402 - accuracy: 0.9537 - val_loss: 1.2313 - val_accuracy: 0.7357\n",
            "Epoch 2/2\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0312 - accuracy: 0.9936 - val_loss: 1.2806 - val_accuracy: 0.7458\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2965 - accuracy: 0.7614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGTNTS_gVYNd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "57be25e8-6ddb-4885-efbe-ed424f1649c6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot([0.9964, 0.7309, 0.7818, 0.8680, 0.9386, 0.9891, 1.0581, 1.1158, 1.1621, 1.1961], label=\"genetic loss\", color=\"#061080\")\n",
        "ax.plot([0.9583, 0.7717, 0.8708, 0.9524, 1.0223, 1.0891, 1.1617, 1.2194, 1.2565, 1.2964], label=\"loss\", color=\"#068006\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot([0.6664, 0.7616, 0.7688, 0.7725, 0.7677, 0.7646, 0.7677, 0.7659, 0.7615, 0.7623], label=\"genetic accuracy\", color=\"#061080\")\n",
        "ax.plot([0.6708, 0.7523, 0.7578, 0.7648, 0.7653, 0.7634, 0.7646, 0.7612, 0.7599, 0.7613], label=\"accuracy\", color=\"#068006\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Generic_FL.png\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbYE-LhkWzYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432cd936-e233-4853-f6d2-13831cdb788d"
      },
      "source": [
        "print(\" \\t\\t\\tGenetic CFL\\t\\t\\t\\tFL\")\n",
        "print(\"Round\\tAccuracy\\t\\tLoss\\t\\t\\tAccuracy\\t\\tLoss\")\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(str(i+1)+\"\\t\"+str(serverhist1['loss'][i])+\"\\t\"+str(serverhist1['accuracy'][i])+\"\\t\"+str(serverhist['loss'][i])+\"\\t\"+str(serverhist['accuracy'][i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \t\t\tGenetic CFL\t\t\t\tFL\n",
            "Round\tAccuracy\t\tLoss\t\t\tAccuracy\t\tLoss\n",
            "1\t0.6664000153541565\t0.996465802192688\t0.6708999872207642\t0.9583895802497864\n",
            "2\t0.7616999745368958\t0.7309398651123047\t0.7523000240325928\t0.7717142105102539\n",
            "3\t0.7688000202178955\t0.781869649887085\t0.7578999996185303\t0.8708730340003967\n",
            "4\t0.772599995136261\t0.8680950999259949\t0.7648000121116638\t0.9524703025817871\n",
            "5\t0.767799973487854\t0.9386677742004395\t0.7653999924659729\t1.0223759412765503\n",
            "6\t0.7646999955177307\t0.9891061782836914\t0.7634000182151794\t1.0891839265823364\n",
            "7\t0.767799973487854\t1.058154821395874\t0.7646999955177307\t1.1617337465286255\n",
            "8\t0.7659000158309937\t1.1158766746520996\t0.7612000107765198\t1.2194958925247192\n",
            "9\t0.7615000009536743\t1.1621036529541016\t0.7599999904632568\t1.25657320022583\n",
            "10\t0.7623999714851379\t1.1961537599563599\t0.7613999843597412\t1.2964723110198975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oSXLAq8ROUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e6bca47a-c77f-46b4-c828-47f158e57ca6"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"Generic_FL.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0eea6870-864b-4528-8988-714de07c1584\", \"Generic_FL.png\", 164034)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q569VCEa6IQP"
      },
      "source": [
        "# Normal Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HDTnmb0F-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7b3bf4-eb3d-422d-f57c-72b9383fd2e4"
      },
      "source": [
        "server_model_norm = create_server_model()\n",
        "num=0\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "n_hist = server_model_norm.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8696 - accuracy: 0.3064 - val_loss: 1.3973 - val_accuracy: 0.4902\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3594 - accuracy: 0.5095 - val_loss: 1.2043 - val_accuracy: 0.5604\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1601 - accuracy: 0.5931 - val_loss: 1.0883 - val_accuracy: 0.6133\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0369 - accuracy: 0.6346 - val_loss: 1.0070 - val_accuracy: 0.6432\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9610 - accuracy: 0.6632 - val_loss: 0.9429 - val_accuracy: 0.6672\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8630 - accuracy: 0.7017 - val_loss: 0.8814 - val_accuracy: 0.6950\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7978 - accuracy: 0.7233 - val_loss: 0.8414 - val_accuracy: 0.7075\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7334 - accuracy: 0.7474 - val_loss: 0.8206 - val_accuracy: 0.7151\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6710 - accuracy: 0.7676 - val_loss: 0.8211 - val_accuracy: 0.7134\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6121 - accuracy: 0.7889 - val_loss: 0.7870 - val_accuracy: 0.7314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-T0yr0qx5xu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "64b16146-74d9-430c-d1f9-2a0eb5be7c7e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(serverhist1['accuracy'], label=\"genetic loss\")\n",
        "ax.plot(serverhist['accuracy'], label=\"loss\")\n",
        "ax.plot(n_hist.history['val_loss'], label=\"general loss\")\n",
        "ax.legend()\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(serverhist1['loss'], label=\"genetic accuracy\")\n",
        "ax.plot(serverhist['loss'], label=\"accuracy\")\n",
        "ax.plot(n_hist.history['val_accuracy'], label=\"general accuracy\")\n",
        "ax.legend()\n",
        "plt.savefig(\"Generic FL\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l9SJcfsIBbQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}